{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sidetable\n",
    "import datetime as dt\n",
    "\n",
    "df1 = pd.read_csv('Advent_B2B_Data_Work_Experience.csv')\n",
    "df2 = pd.read_csv('Advent_B2B_Data_Edu_Experience.csv')\n",
    "df = pd.merge(df1, df2, how=\"outer\", on=[\"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assumably, those without end day is still working in the existing company. Then, the end day is 1/4/2021\n",
    "df['end_day'] = df['end_day'].fillna('1/4/2021')\n",
    "df['start_day'] = pd.to_datetime(df['start_day'])\n",
    "df['end_day'] = pd.to_datetime(df['end_day'])\n",
    "# Assumably, those without fist job started to work in the existing company. Then, the first job start is the start_day\n",
    "df['first_job_start'] = df['first_job_start'].fillna(df['start_day'])\n",
    "df['first_job_start']= pd.to_datetime(df['first_job_start'])\n",
    "df['left_after_2020'] = np.where(df['end_day'].dt.year > 2020, True, False)\n",
    "df['join_from_2015'] = np.where(df['start_day'].dt.year <= 2015, True, False)\n",
    "df['existing_work_years'] = df['end_day'].dt.year - df['start_day'].dt.year\n",
    "df['total_working_days'] = (df['end_day'] - df['first_job_start'])/np.timedelta64(1,'D')\n",
    "df['start_year'] = df['start_day'].dt.year\n",
    "df['end_year'] = df['end_day'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.stb.missing(style=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "com_a = df[df.company == 'Company_A']\n",
    "com_h = df[df.company == 'Company_H']\n",
    "com_n = df[df.company == 'Company_N']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.\tCalculate full-time employee growth for the 3 companies from 2015 to 2020 (annually)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = range(2014, 2021)\n",
    "net_growth = list()\n",
    "for y in years:\n",
    "    net_growth.append(y)\n",
    "    net_growth.append(com_a[com_a['start_year'] == y].count()['id'] - com_a[com_a['end_year'] == y].count()['id'])\n",
    "    net_growth.append(com_h[com_h['start_year'] == y].count()['id'] - com_h[com_h['end_year'] == y].count()['id'])\n",
    "    net_growth.append(com_n[com_n['start_year'] == y].count()['id'] - com_n[com_n['end_year'] == y].count()['id'])\n",
    "net_growth = np.array(net_growth).reshape(len(years), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_growth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_growth = pd.DataFrame(data=net_growth, columns=['Years', 'Company A', 'Company H', 'Company N'])\n",
    "net_growth.set_index('Years', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first row is NaN because there is no previous term to compare. The second row is the percentage change between 2015 and 2014. -0.080189 means there was a tiny loss growth in 2015 against 2014.\n",
    "\n",
    "net_growth.pct_change().to_excel('Net growth.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a.\tWhich company is growing the fastest? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This problem can be understood not only either in absolute number or percentage. To simplify it, I sum up all percentage change\n",
    "net_growth.pct_change().mean()\n",
    "net_growth.pct_change().sum().to_excel('Fastest net growth.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(net_growth.pct_change())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen that Company H is growing the fastest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quetion 3: What is the most common job type for each of the 3 companies? Please define your methodology and how you approached this question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I spend about 10 minutes to scan all titles in the file. Briefly, I can classify them into 6 groups, but it's not the best. It's better to have descriptions of all titles (no missing values) that I can fit into some Natural Language Processing model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "gp1, gp2, gp3, gp4, gp5, gp6 = [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0]\n",
    "all_titles = ['\\n'.join(com_a.title.unique()), '\\n'.join(com_h.title.unique()), '\\n'.join(com_n.title.unique())]\n",
    "for i in range(len(all_titles)):\n",
    "    g1 = re.findall(r'[Tt]echnician | [Aa]nalyst | [Pp]rogrammer | [Ee]ngineer', all_titles[i])\n",
    "    g2 = re.findall(r'[Ss]pecialist | [Cc]onsutant', all_titles[i])\n",
    "    g3 = re.findall(r'[Ii]ntern | [Ii]nternship', all_titles[i])\n",
    "    g4 = re.findall(r'[Ss]enior | [Ll]ead | [Ll]eader | [Aa]dministration | [Aa]dministrator | [Mm]anager', all_titles[i])\n",
    "    g5 = re.findall(r'[Aa]ssociate | [Cc]oordinator | [Cc]lerk', all_titles[i])\n",
    "    g6 = re.findall(r'[Dd]irector | [Vv][Pp] | [Ee][Vv][Pp] | [Vv]ice [Pp]resident', all_titles[i])\n",
    "    for g in g1:\n",
    "        gp1[i] += 1\n",
    "    for g in g2:\n",
    "        gp2[i] += 1\n",
    "    for g in g3:\n",
    "        gp3[i] += 1\n",
    "    for g in g4:\n",
    "        gp4[i] += 1\n",
    "    for g in g5:\n",
    "        gp5[i] += 1\n",
    "    for g in g6:\n",
    "        gp6[i] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_type = pd.DataFrame(data=[gp1, gp2, gp3, gp4, gp5, gp6], columns=['A', 'H', 'N'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for company in job_type.columns:\n",
    "    print(job_type[[company]].idxmax() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen that the group of Senior, Lead, Leader, Administrator, Manager is the most common job type in all three firms. It is probably due to the fact that it has the greatest number of elements against other groups."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4: Which city has the most full-time employees for each of the 3 companies? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The city with the most full-time employees for company_A is ' + str(com_a['headline_location'].value_counts().index[0]) + ' with ' + str(str(com_a['headline_location'].value_counts()[0])) + ' employees')\n",
    "print('The city with the most full-time employees for company_H is ' + str(com_h['headline_location'].value_counts().index[0]) + ' with ' + str(str(com_h['headline_location'].value_counts()[0])) + ' employees')\n",
    "print('The city with the most full-time employees for company_N is ' + str(com_n['headline_location'].value_counts().index[0]) + ' with ' + str(str(com_n['headline_location'].value_counts()[0])) + ' employees')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the different formats in names of locations, I ouput the whole names of them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5: From 2015 to 2020, how many employees left their firm every year across the 3 firms?\n",
    "#### a.\tHow would you standardize this metric for comparison’s sake?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "com_a_left_2015_2020 = com_a[(com_a['join_from_2015'] == True) & (com_a['left_after_2020'] == False)].reset_index()\n",
    "com_h_left_2015_2020 = com_h[(com_h['join_from_2015'] == True) & (com_h['left_after_2020'] == False)].reset_index()\n",
    "com_n_left_2015_2020 = com_n[(com_a['join_from_2015'] == True) & (com_n['left_after_2020'] == False)].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "com_a_left_2015_2020.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The count numbers are not uniform among columns because there are missing values in some of them (exp_location, description, school, etc.). So, I take the number of index count because index cannot be missing. Then I divide it by 5 to get the average (every year)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The average number of employees leaving company A from 2015 to 2020 is ' + str(float(max(com_a_left_2015_2020.count()) / 5)))\n",
    "print('The average number of employees leaving company H from 2015 to 2020 is ' + str(float(max(com_h_left_2015_2020.count()) / 5)))\n",
    "print('The average number of employees leaving company N from 2015 to 2020 is ' + str(float(max(com_n_left_2015_2020.count()) / 5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will standardize them by this formular: X_standardized = (X - mean) / standard_deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers_of_leaving_from_2015_to_2020 = [208.4, 86.6, 0]\n",
    "standardized = []\n",
    "mean = np.mean(numbers_of_leaving_from_2015_to_2020)\n",
    "std = np.std(numbers_of_leaving_from_2015_to_2020)\n",
    "# The standardized ratios of company A, H, and N respectively are:\n",
    "for i in numbers_of_leaving_from_2015_to_2020:\n",
    "    standardized.append((i - mean) / std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The table of before and after standardized is as following:')\n",
    "standardized = pd.DataFrame(data=[numbers_of_leaving_from_2015_to_2020, standardized], columns=['A', 'H', 'N'], index=['Before', 'After'])\n",
    "pd.options.display.float_format = '{:.2f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "standardized.to_excel('Average numbers of employees leaving from each company from 2015 to 2020 before and after standardized.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6: Calculate the # of job promotions annually for the 3 companies. Which firm promotes more of their employees and how did you define a “promotion”? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first, I think \"title\" can implies the promotion an employee receives. However, it just shows the current title. Then, I cannot find any other indicators of \"promotions\" other than \"number_of_recommendations\". In my opinion, the number_of_recommendations is directly propotional with promotions because it means how much credit the person gains from his / her friends, coworkers, and supervisors.\n",
    "To find the job promotions annually, we have to divide the total number of recommendations by their working years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annual_proms_coms = []\n",
    "annual_proms_coms.append(['Company A', com_a['number_of_recommendations'].sum() / com_a['existing_work_years'].sum()])\n",
    "annual_proms_coms.append(['Company H', com_h['number_of_recommendations'].sum() / com_h['existing_work_years'].sum()])\n",
    "annual_proms_coms.append(['Company N', com_n['number_of_recommendations'].sum() / com_n['existing_work_years'].sum()])\n",
    "# I add all into a list and then sort them in accordance with the average number of promotions in descending order\n",
    "annual_proms_coms.sort(key = lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The most promotions employees receive is from ' + str(annual_proms_coms[0][0]) + ' with the average being ' + str(annual_proms_coms[0][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7: From 2015 to 2020 annually, what was the average tenure of employees at each of the 3 firms?\n",
    "#### a.\tPlease calculate in terms of avg # of years worked at the existing company"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To simplify the problem, I assume the working year is calculated by subtracting the year of end_day and the year of start_day (I do not count specifically if it is a full year - 365 days or not)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_years = []\n",
    "avg_years.append(['Company A', com_a['existing_work_years'].sum() / com_a['existing_work_years'].count()])\n",
    "avg_years.append(['Company H', com_h['existing_work_years'].sum() / com_h['existing_work_years'].count()])\n",
    "avg_years.append(['Company N', com_n['existing_work_years'].sum() / com_n['existing_work_years'].count()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_years = pd.DataFrame(data=avg_years, columns=['Company', 'Average tenure of employees from 2015 to 2020 in years'])\n",
    "avg_years.to_excel(\"Company and average tenure of employees from 2015 to 2020 in years.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b.\tAlso compute the total work experience for each employee for the final question below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this problem, I'll show how many days each employee has worked since they started their first jobs and their ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['id', 'total_working_days']].to_excel(\"Total working days of each employee's id.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.\tHow would you score each of the firms’ culture from 1-100 using this data? Assume a score of 100 represents the highest quality and a score of 0 would be the lowest. \n",
    "#### a.\tHint: Use the aggregate employees’ tenure, total working experience, and education level (bachelor vs. masters vs. PhD) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will add all scores on 100 scale of each employee of each company, then divided by the number of employees of each company to get each company's score culture.\n",
    "<br> There are three criteria to consider calculating scores of employees individually: employees’ tenure, total working experience, and education level\n",
    "* Employees’ tenure: I'll put them into 5 bins\n",
    "* Total working experience: I'll put them into 5 bins\n",
    "* Education level: I'll put them into 7 bins\n",
    "<br>So, there are totally 7 * 5 * 5 = 175 unique sets containing the three criteria.\n",
    "<br>Then, I will count how many unique sets each company has divided by 175 and multiplied by 100 -> diversity score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_degree(d):\n",
    "    if re.search(r'[Pp]ostgraduate | [Pp]ost [Gg]raduate', d):\n",
    "         return 'PhD'\n",
    "    elif re.search(r\"[Mm]aster | [Mm]aster's | [Gg]raduate | [Mm][Bb][Aa] | [Mm][Aa] | [Gg]raduation\", d):\n",
    "        return \"Master\"\n",
    "    elif re.search(r\"[Bb]achelor | [Bb]achelor's | [Bb][Aa] | [Bb][Ss] | [Bb][Ss][Cc] | [Uu]ndergraduate\", d):\n",
    "        return 'Bachelor'\n",
    "    elif re.search(r\"[Aa]\\s?-\\s?[Ll]evel\", d):\n",
    "        return 'Associate'\n",
    "    elif re.search(r\"[Hh]igh\\s?[Ss]chool\", d):\n",
    "        return 'High school'\n",
    "    elif re.search(r\"[Cc]ertificate | [Cc]ertified | [Ll]icen[cs]e | [Dd]i[loma]\", d):\n",
    "        return 'Certificate'\n",
    "    else:\n",
    "        return \"Other\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binnings(a_list, number_of_bins=5):\n",
    "    maximum = max(a_list)\n",
    "    minimum = min(a_list)\n",
    "    distance = (maximum - minimum) / number_of_bins\n",
    "    binnings = []\n",
    "    for i in range(number_of_bins):\n",
    "        binnings.append(minimum + i*distance)\n",
    "    return binnings\n",
    "\n",
    "def assign_to_bin(score, binning_list):\n",
    "    my_bin = 0\n",
    "    for i in range(len(binning_list)):\n",
    "        if score > binning_list[i]:\n",
    "            my_bin = i + 1\n",
    "        else:\n",
    "            break\n",
    "    return my_bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "com_a_score = com_a[['existing_work_years', 'total_working_days', 'degree']]\n",
    "com_a_score.existing_work_years = com_a_score.existing_work_years.astype(float)\n",
    "com_a_score.total_working_days = com_a_score.total_working_days.astype(float)\n",
    "\n",
    "# I'll impute the most frequent degree into column 'degree'\n",
    "com_a_score['degree'].fillna(\"General Bachelor's\", inplace=True) \n",
    "com_a_score['degree_type'] = com_a_score['degree'].apply(extract_degree)\n",
    "com_a_score['existing_work_years_encoded'] = list(assign_to_bin(x, binnings(list(com_a_score['existing_work_years']))) for x in com_a_score['existing_work_years'])\n",
    "com_a_score['total_working_days_encoded'] = list(assign_to_bin(x, binnings(list(com_a_score['total_working_days']))) for x in com_a_score['total_working_days'])\n",
    "com_a_score['degree_encoded'] = le.fit_transform(com_a_score['degree_type'])\n",
    "com_a_diversity_code = list(zip(com_a_score.existing_work_years_encoded, com_a_score.total_working_days_encoded, com_a_score.degree_encoded))\n",
    "com_a_diversity_score = 0\n",
    "com_a_diversity_sets = set()\n",
    "for i in com_a_diversity_code:\n",
    "    if i not in com_a_diversity_sets:\n",
    "        com_a_diversity_sets.add(i)\n",
    "        com_a_diversity_score += 1\n",
    "com_a_diversity_score = com_a_diversity_score * 100 / 175"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "com_h_score = com_h[['existing_work_years', 'total_working_days', 'degree']]\n",
    "com_h_score.existing_work_years = com_h_score.existing_work_years.astype(float)\n",
    "com_h_score.total_working_days = com_h_score.total_working_days.astype(float)\n",
    "\n",
    "# I'll impute the most frequent degree into column 'degree'\n",
    "com_h_score['degree'].fillna(\"General Bachelor's\", inplace=True) \n",
    "com_h_score['degree_type'] = com_h_score['degree'].apply(extract_degree)\n",
    "com_h_score['existing_work_years_encoded'] = list(assign_to_bin(x, binnings(list(com_h_score['existing_work_years']))) for x in com_h_score['existing_work_years'])\n",
    "com_h_score['total_working_days_encoded'] = list(assign_to_bin(x, binnings(list(com_h_score['total_working_days']))) for x in com_h_score['total_working_days'])\n",
    "com_h_score['degree_encoded'] = le.fit_transform(com_h_score['degree_type'])\n",
    "com_h_diversity_code = list(zip(com_h_score.existing_work_years_encoded, com_h_score.total_working_days_encoded, com_h_score.degree_encoded))\n",
    "com_h_diversity_score = 0\n",
    "com_h_diversity_sets = set()\n",
    "for i in com_h_diversity_code:\n",
    "    if i not in com_h_diversity_sets:\n",
    "        com_h_diversity_sets.add(i)\n",
    "        com_h_diversity_score += 1\n",
    "com_h_diversity_score = com_h_diversity_score * 100 / 175"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "com_n_score = com_n[['existing_work_years', 'total_working_days', 'degree']]\n",
    "com_n_score.existing_work_years = com_n_score.existing_work_years.astype(float)\n",
    "com_n_score.total_working_days = com_n_score.total_working_days.astype(float)\n",
    "\n",
    "# I'll impute the most frequent degree into column 'degree'\n",
    "com_n_score['degree'].fillna(\"General Bachelor's\", inplace=True) \n",
    "com_n_score['degree_type'] = com_n_score['degree'].apply(extract_degree)\n",
    "com_n_score['existing_work_years_encoded'] = list(assign_to_bin(x, binnings(list(com_n_score['existing_work_years']))) for x in com_n_score['existing_work_years'])\n",
    "com_n_score['total_working_days_encoded'] = list(assign_to_bin(x, binnings(list(com_n_score['total_working_days']))) for x in com_n_score['total_working_days'])\n",
    "com_n_score['degree_encoded'] = le.fit_transform(com_n_score['degree_type'])\n",
    "com_n_diversity_code = list(zip(com_n_score.existing_work_years_encoded, com_n_score.total_working_days_encoded, com_n_score.degree_encoded))\n",
    "com_n_diversity_score = 0\n",
    "com_n_diversity_sets = set()\n",
    "for i in com_n_diversity_code:\n",
    "    if i not in com_n_diversity_sets:\n",
    "        com_n_diversity_sets.add(i)\n",
    "        com_n_diversity_score += 1\n",
    "com_n_diversity_score = com_n_diversity_score * 100 / 175"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "com_a_diversity_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "com_h_diversity_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "com_n_diversity_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "div_scores = pd.DataFrame(data={'A': com_a_diversity_score, 'H': com_h_diversity_score, 'N': com_n_diversity_score}, index=['Diversity scores of companies in percentage'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "div_scores.to_excel('Diversity scores.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If I have time, I can create functions to make the code look more professional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b.\tWhat additional data would you like for each individual in order to help build a better culture ranking model? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gender, Race, Locust of control, Political affiliation, Born in the US?, First generation? Individualism or Collectivism? "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
