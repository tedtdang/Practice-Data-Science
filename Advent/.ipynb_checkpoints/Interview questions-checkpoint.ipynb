{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sidetable\n",
    "import datetime as dt\n",
    "\n",
    "df1 = pd.read_csv('Advent_B2B_Data_Work_Experience.csv')\n",
    "df2 = pd.read_csv('Advent_B2B_Data_Edu_Experience.csv')\n",
    "df = pd.merge(df1, df2, how=\"outer\", on=[\"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assumably, those without end day is still working in the existing company. Then, the end day is 1/4/2021\n",
    "df['end_day'] = df['end_day'].fillna('1/4/2021')\n",
    "df['start_day'] = pd.to_datetime(df['start_day'])\n",
    "df['end_day'] = pd.to_datetime(df['end_day'])\n",
    "# Assumably, those without fist job started to work in the existing company. Then, the first job start is the start_day\n",
    "df['first_job_start'] = df['first_job_start'].fillna(df['start_day'])\n",
    "df['first_job_start']= pd.to_datetime(df['first_job_start'])\n",
    "df['left_after_2020'] = np.where(df['end_day'].dt.year > 2020, True, False)\n",
    "df['join_from_2015'] = np.where(df['start_day'].dt.year <= 2015, True, False)\n",
    "df['existing_work_years'] = df['end_day'].dt.year - df['start_day'].dt.year\n",
    "df['total_working_days'] = (df['end_day'] - df['first_job_start'])/np.timedelta64(1,'D')\n",
    "df['start_year'] = df['start_day'].dt.year\n",
    "df['end_year'] = df['end_day'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>headline_location</th>\n",
       "      <th>company</th>\n",
       "      <th>exp_location</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>start_day</th>\n",
       "      <th>end_day</th>\n",
       "      <th>first_job_start</th>\n",
       "      <th>number_of_recommendations</th>\n",
       "      <th>school</th>\n",
       "      <th>degree</th>\n",
       "      <th>time_start</th>\n",
       "      <th>time_end</th>\n",
       "      <th>left_after_2020</th>\n",
       "      <th>join_from_2015</th>\n",
       "      <th>existing_work_years</th>\n",
       "      <th>total_working_days</th>\n",
       "      <th>start_year</th>\n",
       "      <th>end_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2ff517bd-3566-481e-a289-52ce4fb4ae2e</td>\n",
       "      <td>Aliso Viejo, California, United States</td>\n",
       "      <td>Company_N</td>\n",
       "      <td>Greater Minneapolis-St. Paul Area</td>\n",
       "      <td>Spine Specialist</td>\n",
       "      <td>Company_N, Inc., is a medical device company f...</td>\n",
       "      <td>2012-11-01</td>\n",
       "      <td>2015-03-01</td>\n",
       "      <td>2004-10-01</td>\n",
       "      <td>5.3</td>\n",
       "      <td>University of Minnesota</td>\n",
       "      <td>Bachelor of Arts, Journalism</td>\n",
       "      <td>1997</td>\n",
       "      <td>2002</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>3803.0</td>\n",
       "      <td>2012</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>78a0c7be-de6e-4af6-bab7-050a436e19fe</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>Company_N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Associate Manager, SEA Market Development</td>\n",
       "      <td>Managed the product throughout the product lif...</td>\n",
       "      <td>2010-07-01</td>\n",
       "      <td>2012-05-01</td>\n",
       "      <td>2005-09-01</td>\n",
       "      <td>3.6</td>\n",
       "      <td>Marketing Institute of Singapore</td>\n",
       "      <td>Graduate Diploma in Marketing</td>\n",
       "      <td>2008</td>\n",
       "      <td>2008</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>2434.0</td>\n",
       "      <td>2010</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>78a0c7be-de6e-4af6-bab7-050a436e19fe</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>Company_N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Associate Manager, SEA Market Development</td>\n",
       "      <td>Managed the product throughout the product lif...</td>\n",
       "      <td>2010-07-01</td>\n",
       "      <td>2012-05-01</td>\n",
       "      <td>2005-09-01</td>\n",
       "      <td>3.6</td>\n",
       "      <td>National University of Singapore</td>\n",
       "      <td>Bachelor of Engineering (B.Eng.), Electrical a...</td>\n",
       "      <td>2001</td>\n",
       "      <td>2005</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>2434.0</td>\n",
       "      <td>2010</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>78a0c7be-de6e-4af6-bab7-050a436e19fe</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>Company_N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Senior Spine Specialist</td>\n",
       "      <td>Discussed clinically and provided technical su...</td>\n",
       "      <td>2009-12-01</td>\n",
       "      <td>2010-07-01</td>\n",
       "      <td>2005-09-01</td>\n",
       "      <td>3.6</td>\n",
       "      <td>Marketing Institute of Singapore</td>\n",
       "      <td>Graduate Diploma in Marketing</td>\n",
       "      <td>2008</td>\n",
       "      <td>2008</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1764.0</td>\n",
       "      <td>2009</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>78a0c7be-de6e-4af6-bab7-050a436e19fe</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>Company_N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Senior Spine Specialist</td>\n",
       "      <td>Discussed clinically and provided technical su...</td>\n",
       "      <td>2009-12-01</td>\n",
       "      <td>2010-07-01</td>\n",
       "      <td>2005-09-01</td>\n",
       "      <td>3.6</td>\n",
       "      <td>National University of Singapore</td>\n",
       "      <td>Bachelor of Engineering (B.Eng.), Electrical a...</td>\n",
       "      <td>2001</td>\n",
       "      <td>2005</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1764.0</td>\n",
       "      <td>2009</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id  \\\n",
       "0  2ff517bd-3566-481e-a289-52ce4fb4ae2e   \n",
       "1  78a0c7be-de6e-4af6-bab7-050a436e19fe   \n",
       "2  78a0c7be-de6e-4af6-bab7-050a436e19fe   \n",
       "3  78a0c7be-de6e-4af6-bab7-050a436e19fe   \n",
       "4  78a0c7be-de6e-4af6-bab7-050a436e19fe   \n",
       "\n",
       "                        headline_location    company  \\\n",
       "0  Aliso Viejo, California, United States  Company_N   \n",
       "1                               Singapore  Company_N   \n",
       "2                               Singapore  Company_N   \n",
       "3                               Singapore  Company_N   \n",
       "4                               Singapore  Company_N   \n",
       "\n",
       "                        exp_location  \\\n",
       "0  Greater Minneapolis-St. Paul Area   \n",
       "1                                NaN   \n",
       "2                                NaN   \n",
       "3                                NaN   \n",
       "4                                NaN   \n",
       "\n",
       "                                       title  \\\n",
       "0                           Spine Specialist   \n",
       "1  Associate Manager, SEA Market Development   \n",
       "2  Associate Manager, SEA Market Development   \n",
       "3                    Senior Spine Specialist   \n",
       "4                    Senior Spine Specialist   \n",
       "\n",
       "                                         description  start_day    end_day  \\\n",
       "0  Company_N, Inc., is a medical device company f... 2012-11-01 2015-03-01   \n",
       "1  Managed the product throughout the product lif... 2010-07-01 2012-05-01   \n",
       "2  Managed the product throughout the product lif... 2010-07-01 2012-05-01   \n",
       "3  Discussed clinically and provided technical su... 2009-12-01 2010-07-01   \n",
       "4  Discussed clinically and provided technical su... 2009-12-01 2010-07-01   \n",
       "\n",
       "  first_job_start  number_of_recommendations  \\\n",
       "0      2004-10-01                        5.3   \n",
       "1      2005-09-01                        3.6   \n",
       "2      2005-09-01                        3.6   \n",
       "3      2005-09-01                        3.6   \n",
       "4      2005-09-01                        3.6   \n",
       "\n",
       "                             school  \\\n",
       "0           University of Minnesota   \n",
       "1  Marketing Institute of Singapore   \n",
       "2  National University of Singapore   \n",
       "3  Marketing Institute of Singapore   \n",
       "4  National University of Singapore   \n",
       "\n",
       "                                              degree time_start time_end  \\\n",
       "0                       Bachelor of Arts, Journalism       1997     2002   \n",
       "1                      Graduate Diploma in Marketing       2008     2008   \n",
       "2  Bachelor of Engineering (B.Eng.), Electrical a...       2001     2005   \n",
       "3                      Graduate Diploma in Marketing       2008     2008   \n",
       "4  Bachelor of Engineering (B.Eng.), Electrical a...       2001     2005   \n",
       "\n",
       "   left_after_2020  join_from_2015  existing_work_years  total_working_days  \\\n",
       "0            False            True                    3              3803.0   \n",
       "1            False            True                    2              2434.0   \n",
       "2            False            True                    2              2434.0   \n",
       "3            False            True                    1              1764.0   \n",
       "4            False            True                    1              1764.0   \n",
       "\n",
       "   start_year  end_year  \n",
       "0        2012      2015  \n",
       "1        2010      2012  \n",
       "2        2010      2012  \n",
       "3        2009      2010  \n",
       "4        2009      2010  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_e520c1ba_4efc_11eb_8edc_9848271e970b\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >missing</th>        <th class=\"col_heading level0 col1\" >total</th>        <th class=\"col_heading level0 col2\" >percent</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_e520c1ba_4efc_11eb_8edc_9848271e970blevel0_row0\" class=\"row_heading level0 row0\" >description</th>\n",
       "                        <td id=\"T_e520c1ba_4efc_11eb_8edc_9848271e970brow0_col0\" class=\"data row0 col0\" >21709</td>\n",
       "                        <td id=\"T_e520c1ba_4efc_11eb_8edc_9848271e970brow0_col1\" class=\"data row0 col1\" >32,952</td>\n",
       "                        <td id=\"T_e520c1ba_4efc_11eb_8edc_9848271e970brow0_col2\" class=\"data row0 col2\" >65.88%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_e520c1ba_4efc_11eb_8edc_9848271e970blevel0_row1\" class=\"row_heading level0 row1\" >time_end</th>\n",
       "                        <td id=\"T_e520c1ba_4efc_11eb_8edc_9848271e970brow1_col0\" class=\"data row1 col0\" >9076</td>\n",
       "                        <td id=\"T_e520c1ba_4efc_11eb_8edc_9848271e970brow1_col1\" class=\"data row1 col1\" >32,952</td>\n",
       "                        <td id=\"T_e520c1ba_4efc_11eb_8edc_9848271e970brow1_col2\" class=\"data row1 col2\" >27.54%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_e520c1ba_4efc_11eb_8edc_9848271e970blevel0_row2\" class=\"row_heading level0 row2\" >exp_location</th>\n",
       "                        <td id=\"T_e520c1ba_4efc_11eb_8edc_9848271e970brow2_col0\" class=\"data row2 col0\" >8201</td>\n",
       "                        <td id=\"T_e520c1ba_4efc_11eb_8edc_9848271e970brow2_col1\" class=\"data row2 col1\" >32,952</td>\n",
       "                        <td id=\"T_e520c1ba_4efc_11eb_8edc_9848271e970brow2_col2\" class=\"data row2 col2\" >24.89%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_e520c1ba_4efc_11eb_8edc_9848271e970blevel0_row3\" class=\"row_heading level0 row3\" >time_start</th>\n",
       "                        <td id=\"T_e520c1ba_4efc_11eb_8edc_9848271e970brow3_col0\" class=\"data row3 col0\" >5661</td>\n",
       "                        <td id=\"T_e520c1ba_4efc_11eb_8edc_9848271e970brow3_col1\" class=\"data row3 col1\" >32,952</td>\n",
       "                        <td id=\"T_e520c1ba_4efc_11eb_8edc_9848271e970brow3_col2\" class=\"data row3 col2\" >17.18%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_e520c1ba_4efc_11eb_8edc_9848271e970blevel0_row4\" class=\"row_heading level0 row4\" >degree</th>\n",
       "                        <td id=\"T_e520c1ba_4efc_11eb_8edc_9848271e970brow4_col0\" class=\"data row4 col0\" >4754</td>\n",
       "                        <td id=\"T_e520c1ba_4efc_11eb_8edc_9848271e970brow4_col1\" class=\"data row4 col1\" >32,952</td>\n",
       "                        <td id=\"T_e520c1ba_4efc_11eb_8edc_9848271e970brow4_col2\" class=\"data row4 col2\" >14.43%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_e520c1ba_4efc_11eb_8edc_9848271e970blevel0_row5\" class=\"row_heading level0 row5\" >school</th>\n",
       "                        <td id=\"T_e520c1ba_4efc_11eb_8edc_9848271e970brow5_col0\" class=\"data row5 col0\" >893</td>\n",
       "                        <td id=\"T_e520c1ba_4efc_11eb_8edc_9848271e970brow5_col1\" class=\"data row5 col1\" >32,952</td>\n",
       "                        <td id=\"T_e520c1ba_4efc_11eb_8edc_9848271e970brow5_col2\" class=\"data row5 col2\" >2.71%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_e520c1ba_4efc_11eb_8edc_9848271e970blevel0_row6\" class=\"row_heading level0 row6\" >number_of_recommendations</th>\n",
       "                        <td id=\"T_e520c1ba_4efc_11eb_8edc_9848271e970brow6_col0\" class=\"data row6 col0\" >12</td>\n",
       "                        <td id=\"T_e520c1ba_4efc_11eb_8edc_9848271e970brow6_col1\" class=\"data row6 col1\" >32,952</td>\n",
       "                        <td id=\"T_e520c1ba_4efc_11eb_8edc_9848271e970brow6_col2\" class=\"data row6 col2\" >0.04%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_e520c1ba_4efc_11eb_8edc_9848271e970blevel0_row7\" class=\"row_heading level0 row7\" >start_year</th>\n",
       "                        <td id=\"T_e520c1ba_4efc_11eb_8edc_9848271e970brow7_col0\" class=\"data row7 col0\" >0</td>\n",
       "                        <td id=\"T_e520c1ba_4efc_11eb_8edc_9848271e970brow7_col1\" class=\"data row7 col1\" >32,952</td>\n",
       "                        <td id=\"T_e520c1ba_4efc_11eb_8edc_9848271e970brow7_col2\" class=\"data row7 col2\" >0.00%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_e520c1ba_4efc_11eb_8edc_9848271e970blevel0_row8\" class=\"row_heading level0 row8\" >total_working_days</th>\n",
       "                        <td id=\"T_e520c1ba_4efc_11eb_8edc_9848271e970brow8_col0\" class=\"data row8 col0\" >0</td>\n",
       "                        <td id=\"T_e520c1ba_4efc_11eb_8edc_9848271e970brow8_col1\" class=\"data row8 col1\" >32,952</td>\n",
       "                        <td id=\"T_e520c1ba_4efc_11eb_8edc_9848271e970brow8_col2\" class=\"data row8 col2\" >0.00%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_e520c1ba_4efc_11eb_8edc_9848271e970blevel0_row9\" class=\"row_heading level0 row9\" >existing_work_years</th>\n",
       "                        <td id=\"T_e520c1ba_4efc_11eb_8edc_9848271e970brow9_col0\" class=\"data row9 col0\" >0</td>\n",
       "                        <td id=\"T_e520c1ba_4efc_11eb_8edc_9848271e970brow9_col1\" class=\"data row9 col1\" >32,952</td>\n",
       "                        <td id=\"T_e520c1ba_4efc_11eb_8edc_9848271e970brow9_col2\" class=\"data row9 col2\" >0.00%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_e520c1ba_4efc_11eb_8edc_9848271e970blevel0_row10\" class=\"row_heading level0 row10\" >join_from_2015</th>\n",
       "                        <td id=\"T_e520c1ba_4efc_11eb_8edc_9848271e970brow10_col0\" class=\"data row10 col0\" >0</td>\n",
       "                        <td id=\"T_e520c1ba_4efc_11eb_8edc_9848271e970brow10_col1\" class=\"data row10 col1\" >32,952</td>\n",
       "                        <td id=\"T_e520c1ba_4efc_11eb_8edc_9848271e970brow10_col2\" class=\"data row10 col2\" >0.00%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_e520c1ba_4efc_11eb_8edc_9848271e970blevel0_row11\" class=\"row_heading level0 row11\" >left_after_2020</th>\n",
       "                        <td id=\"T_e520c1ba_4efc_11eb_8edc_9848271e970brow11_col0\" class=\"data row11 col0\" >0</td>\n",
       "                        <td id=\"T_e520c1ba_4efc_11eb_8edc_9848271e970brow11_col1\" class=\"data row11 col1\" >32,952</td>\n",
       "                        <td id=\"T_e520c1ba_4efc_11eb_8edc_9848271e970brow11_col2\" class=\"data row11 col2\" >0.00%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_e520c1ba_4efc_11eb_8edc_9848271e970blevel0_row12\" class=\"row_heading level0 row12\" >id</th>\n",
       "                        <td id=\"T_e520c1ba_4efc_11eb_8edc_9848271e970brow12_col0\" class=\"data row12 col0\" >0</td>\n",
       "                        <td id=\"T_e520c1ba_4efc_11eb_8edc_9848271e970brow12_col1\" class=\"data row12 col1\" >32,952</td>\n",
       "                        <td id=\"T_e520c1ba_4efc_11eb_8edc_9848271e970brow12_col2\" class=\"data row12 col2\" >0.00%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_e520c1ba_4efc_11eb_8edc_9848271e970blevel0_row13\" class=\"row_heading level0 row13\" >headline_location</th>\n",
       "                        <td id=\"T_e520c1ba_4efc_11eb_8edc_9848271e970brow13_col0\" class=\"data row13 col0\" >0</td>\n",
       "                        <td id=\"T_e520c1ba_4efc_11eb_8edc_9848271e970brow13_col1\" class=\"data row13 col1\" >32,952</td>\n",
       "                        <td id=\"T_e520c1ba_4efc_11eb_8edc_9848271e970brow13_col2\" class=\"data row13 col2\" >0.00%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_e520c1ba_4efc_11eb_8edc_9848271e970blevel0_row14\" class=\"row_heading level0 row14\" >first_job_start</th>\n",
       "                        <td id=\"T_e520c1ba_4efc_11eb_8edc_9848271e970brow14_col0\" class=\"data row14 col0\" >0</td>\n",
       "                        <td id=\"T_e520c1ba_4efc_11eb_8edc_9848271e970brow14_col1\" class=\"data row14 col1\" >32,952</td>\n",
       "                        <td id=\"T_e520c1ba_4efc_11eb_8edc_9848271e970brow14_col2\" class=\"data row14 col2\" >0.00%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_e520c1ba_4efc_11eb_8edc_9848271e970blevel0_row15\" class=\"row_heading level0 row15\" >end_day</th>\n",
       "                        <td id=\"T_e520c1ba_4efc_11eb_8edc_9848271e970brow15_col0\" class=\"data row15 col0\" >0</td>\n",
       "                        <td id=\"T_e520c1ba_4efc_11eb_8edc_9848271e970brow15_col1\" class=\"data row15 col1\" >32,952</td>\n",
       "                        <td id=\"T_e520c1ba_4efc_11eb_8edc_9848271e970brow15_col2\" class=\"data row15 col2\" >0.00%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_e520c1ba_4efc_11eb_8edc_9848271e970blevel0_row16\" class=\"row_heading level0 row16\" >start_day</th>\n",
       "                        <td id=\"T_e520c1ba_4efc_11eb_8edc_9848271e970brow16_col0\" class=\"data row16 col0\" >0</td>\n",
       "                        <td id=\"T_e520c1ba_4efc_11eb_8edc_9848271e970brow16_col1\" class=\"data row16 col1\" >32,952</td>\n",
       "                        <td id=\"T_e520c1ba_4efc_11eb_8edc_9848271e970brow16_col2\" class=\"data row16 col2\" >0.00%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_e520c1ba_4efc_11eb_8edc_9848271e970blevel0_row17\" class=\"row_heading level0 row17\" >title</th>\n",
       "                        <td id=\"T_e520c1ba_4efc_11eb_8edc_9848271e970brow17_col0\" class=\"data row17 col0\" >0</td>\n",
       "                        <td id=\"T_e520c1ba_4efc_11eb_8edc_9848271e970brow17_col1\" class=\"data row17 col1\" >32,952</td>\n",
       "                        <td id=\"T_e520c1ba_4efc_11eb_8edc_9848271e970brow17_col2\" class=\"data row17 col2\" >0.00%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_e520c1ba_4efc_11eb_8edc_9848271e970blevel0_row18\" class=\"row_heading level0 row18\" >company</th>\n",
       "                        <td id=\"T_e520c1ba_4efc_11eb_8edc_9848271e970brow18_col0\" class=\"data row18 col0\" >0</td>\n",
       "                        <td id=\"T_e520c1ba_4efc_11eb_8edc_9848271e970brow18_col1\" class=\"data row18 col1\" >32,952</td>\n",
       "                        <td id=\"T_e520c1ba_4efc_11eb_8edc_9848271e970brow18_col2\" class=\"data row18 col2\" >0.00%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_e520c1ba_4efc_11eb_8edc_9848271e970blevel0_row19\" class=\"row_heading level0 row19\" >end_year</th>\n",
       "                        <td id=\"T_e520c1ba_4efc_11eb_8edc_9848271e970brow19_col0\" class=\"data row19 col0\" >0</td>\n",
       "                        <td id=\"T_e520c1ba_4efc_11eb_8edc_9848271e970brow19_col1\" class=\"data row19 col1\" >32,952</td>\n",
       "                        <td id=\"T_e520c1ba_4efc_11eb_8edc_9848271e970brow19_col2\" class=\"data row19 col2\" >0.00%</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1f6e15b8648>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.stb.missing(style=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "com_a = df[df.company == 'Company_A']\n",
    "com_h = df[df.company == 'Company_H']\n",
    "com_n = df[df.company == 'Company_N']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.\tCalculate full-time employee growth for the 3 companies from 2015 to 2020 (annually)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = range(2014, 2021)\n",
    "net_growth = list()\n",
    "for y in years:\n",
    "    net_growth.append(y)\n",
    "    net_growth.append(com_a[com_a['start_year'] == y].count()['id'] - com_a[com_a['end_year'] == y].count()['id'])\n",
    "    net_growth.append(com_h[com_h['start_year'] == y].count()['id'] - com_h[com_h['end_year'] == y].count()['id'])\n",
    "    net_growth.append(com_n[com_n['start_year'] == y].count()['id'] - com_n[com_n['end_year'] == y].count()['id'])\n",
    "net_growth = np.array(net_growth).reshape(len(years), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_growth = pd.DataFrame(data=net_growth, columns=['Years', 'Company A', 'Company H', 'Company N'])\n",
    "net_growth.set_index('Years', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first row is NaN because there is no previous term to compare. The second row is the percentage change between 2015 and 2014. -0.080189 means there was a tiny loss growth in 2015 against 2014.\n",
    "net_growth.pct_change()\n",
    "net_growth.pct_change().to_excel('Net growth.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a.\tWhich company is growing the fastest? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This problem can be understood not only either in absolute number or percentage. To simplify it, I sum up all percentage change\n",
    "net_growth.pct_change().sum()\n",
    "net_growth.pct_change().sum().to_excel('Fastest net growth.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen that Company H is growing the fastest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quetion 3: What is the most common job type for each of the 3 companies? Please define your methodology and how you approached this question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I spend about 10 minutes to scan all titles in the file. Briefly, I can classify them into 6 groups, but it's not the best. It's better to have descriptions of all titles (no missing values) that I can fit into some Natural Language Processing model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "gp1, gp2, gp3, gp4, gp5, gp6 = [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0]\n",
    "all_titles = ['\\n'.join(com_a.title.unique()), '\\n'.join(com_h.title.unique()), '\\n'.join(com_n.title.unique())]\n",
    "for i in range(len(all_titles)):\n",
    "    g1 = re.findall(r'[Tt]echnician | [Aa]nalyst | [Pp]rogrammer | [Ee]ngineer', all_titles[i])\n",
    "    g2 = re.findall(r'[Ss]pecialist | [Cc]onsutant', all_titles[i])\n",
    "    g3 = re.findall(r'[Ii]ntern | [Ii]nternship', all_titles[i])\n",
    "    g4 = re.findall(r'[Ss]enior | [Ll]ead | [Ll]eader | [Aa]dministration | [Aa]dministrator | [Mm]anager', all_titles[i])\n",
    "    g5 = re.findall(r'[Aa]ssociate | [Cc]oordinator | [Cc]lerk', all_titles[i])\n",
    "    g6 = re.findall(r'[Dd]irector | [Vv][Pp] | [Ee][Vv][Pp] | [Vv]ice [Pp]resident', all_titles[i])\n",
    "    for g in g1:\n",
    "        gp1[i] += 1\n",
    "    for g in g2:\n",
    "        gp2[i] += 1\n",
    "    for g in g3:\n",
    "        gp3[i] += 1\n",
    "    for g in g4:\n",
    "        gp4[i] += 1\n",
    "    for g in g5:\n",
    "        gp5[i] += 1\n",
    "    for g in g6:\n",
    "        gp6[i] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_type = pd.DataFrame(data=[gp1, gp2, gp3, gp4, gp5, gp6], columns=['A', 'H', 'N'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>H</th>\n",
       "      <th>N</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>238</td>\n",
       "      <td>134</td>\n",
       "      <td>1377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18</td>\n",
       "      <td>25</td>\n",
       "      <td>294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>22</td>\n",
       "      <td>39</td>\n",
       "      <td>193</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     A    H     N\n",
       "0    2   16   375\n",
       "1    2    1    47\n",
       "2    2    2    17\n",
       "3  238  134  1377\n",
       "4   18   25   294\n",
       "5   22   39   193"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A    3\n",
      "dtype: int64\n",
      "H    3\n",
      "dtype: int64\n",
      "N    3\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for company in job_type.columns:\n",
    "    print(job_type[[company]].idxmax() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen that the group of Senior, Lead, Leader, Administrator, Manager is the most common job type in all three firms. It is probably due to the fact that it has the greatest number of elements against other groups."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4: Which city has the most full-time employees for each of the 3 companies? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The city with the most full-time employees for company_A is Luxembourg with 1377 employees\n",
      "The city with the most full-time employees for company_H is United Arab Emirates with 761 employees\n",
      "The city with the most full-time employees for company_N is San Diego, California, United States with 6627 employees\n"
     ]
    }
   ],
   "source": [
    "print('The city with the most full-time employees for company_A is ' + str(com_a['headline_location'].value_counts().index[0]) + ' with ' + str(str(com_a['headline_location'].value_counts()[0])) + ' employees')\n",
    "print('The city with the most full-time employees for company_H is ' + str(com_h['headline_location'].value_counts().index[0]) + ' with ' + str(str(com_h['headline_location'].value_counts()[0])) + ' employees')\n",
    "print('The city with the most full-time employees for company_N is ' + str(com_n['headline_location'].value_counts().index[0]) + ' with ' + str(str(com_n['headline_location'].value_counts()[0])) + ' employees')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the different formats in names of locations, I ouput the whole names of them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5: From 2015 to 2020, how many employees left their firm every year across the 3 firms?\n",
    "#### a.\tHow would you standardize this metric for comparison’s sake?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "com_a_left_2015_2020 = com_a[(com_a['join_from_2015'] == True) & (com_a['left_after_2020'] == False)].reset_index()\n",
    "com_h_left_2015_2020 = com_h[(com_h['join_from_2015'] == True) & (com_h['left_after_2020'] == False)].reset_index()\n",
    "com_n_left_2015_2020 = com_n[(com_a['join_from_2015'] == True) & (com_n['left_after_2020'] == False)].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index                        1042\n",
       "id                           1042\n",
       "headline_location            1042\n",
       "company                      1042\n",
       "exp_location                  769\n",
       "title                        1042\n",
       "description                   394\n",
       "start_day                    1042\n",
       "end_day                      1042\n",
       "first_job_start              1042\n",
       "number_of_recommendations    1042\n",
       "school                        988\n",
       "degree                        819\n",
       "time_start                    895\n",
       "time_end                      737\n",
       "left_after_2020              1042\n",
       "join_from_2015               1042\n",
       "existing_work_years          1042\n",
       "total_working_days           1042\n",
       "start_year                   1042\n",
       "end_year                     1042\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "com_a_left_2015_2020.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The count numbers are not uniform among columns because there are missing values in some of them (exp_location, description, school, etc.). So, I take the number of index count because index cannot be missing. Then I divide it by 5 to get the average (every year)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average number of employees leaving company A from 2015 to 2020 is 208.4\n",
      "The average number of employees leaving company H from 2015 to 2020 is 86.6\n",
      "The average number of employees leaving company N from 2015 to 2020 is 0.0\n"
     ]
    }
   ],
   "source": [
    "print('The average number of employees leaving company A from 2015 to 2020 is ' + str(float(max(com_a_left_2015_2020.count()) / 5)))\n",
    "print('The average number of employees leaving company H from 2015 to 2020 is ' + str(float(max(com_h_left_2015_2020.count()) / 5)))\n",
    "print('The average number of employees leaving company N from 2015 to 2020 is ' + str(float(max(com_n_left_2015_2020.count()) / 5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will standardize them by this formular: X_standardized = (X - mean) / standard_deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers_of_leaving_from_2015_to_2020 = [208.4, 86.6, 0]\n",
    "standardized = []\n",
    "mean = np.mean(numbers_of_leaving_from_2015_to_2020)\n",
    "std = np.std(numbers_of_leaving_from_2015_to_2020)\n",
    "# The standardized ratios of company A, H, and N respectively are:\n",
    "for i in numbers_of_leaving_from_2015_to_2020:\n",
    "    standardized.append((i - mean) / std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The table of before and after standardized is as following:\n"
     ]
    }
   ],
   "source": [
    "print('The table of before and after standardized is as following:')\n",
    "standardized = pd.DataFrame(data=[numbers_of_leaving_from_2015_to_2020, standardized], columns=['A', 'H', 'N'], index=['Before', 'After'])\n",
    "pd.options.display.float_format = '{:.2f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "standardized.to_excel('Average numbers of employees leaving from each company from 2015 to 2020 before and after standardized.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6: Calculate the # of job promotions annually for the 3 companies. Which firm promotes more of their employees and how did you define a “promotion”? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first, I think \"title\" can implies the promotion an employee receives. However, it just shows the current title. Then, I cannot find any other indicators of \"promotions\" other than \"number_of_recommendations\". In my opinion, the number_of_recommendations is directly propotional with promotions because it means how much credit the person gains from his / her friends, coworkers, and supervisors.\n",
    "To find the job promotions annually, we have to divide the total number of recommendations by their working years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "annual_proms_coms = []\n",
    "annual_proms_coms.append(['Company A', com_a['number_of_recommendations'].sum() / com_a['existing_work_years'].sum()])\n",
    "annual_proms_coms.append(['Company H', com_h['number_of_recommendations'].sum() / com_h['existing_work_years'].sum()])\n",
    "annual_proms_coms.append(['Company N', com_n['number_of_recommendations'].sum() / com_n['existing_work_years'].sum()])\n",
    "# I add all into a list and then sort them in accordance with the average number of promotions in descending order\n",
    "annual_proms_coms.sort(key = lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most promotions employees receive is from Company A with the average being 2.566266257225433\n"
     ]
    }
   ],
   "source": [
    "print('The most promotions employees receive is from ' + str(annual_proms_coms[0][0]) + ' with the average being ' + str(annual_proms_coms[0][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7: From 2015 to 2020 annually, what was the average tenure of employees at each of the 3 firms?\n",
    "#### a.\tPlease calculate in terms of avg # of years worked at the existing company"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To simplify the problem, I assume the working year is calculated by subtracting the year of end_day and the year of start_day (I do not count specifically if it is a full year - 365 days or not)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_years = []\n",
    "avg_years.append(['Company A', com_a['existing_work_years'].sum() / com_a['existing_work_years'].count()])\n",
    "avg_years.append(['Company H', com_h['existing_work_years'].sum() / com_h['existing_work_years'].count()])\n",
    "avg_years.append(['Company N', com_n['existing_work_years'].sum() / com_n['existing_work_years'].count()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_years = pd.DataFrame(data=avg_years, columns=['Company', 'Average tenure of employees from 2015 to 2020 in years'])\n",
    "avg_years.to_excel(\"Company and average tenure of employees from 2015 to 2020 in years.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b.\tAlso compute the total work experience for each employee for the final question below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this problem, I'll show how many days each employee has worked since they started their first jobs and their ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['id', 'total_working_days']].to_excel(\"Total working days of each employee's id.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.\tHow would you score each of the firms’ culture from 1-100 using this data? Assume a score of 100 represents the highest quality and a score of 0 would be the lowest. \n",
    "#### a.\tHint: Use the aggregate employees’ tenure, total working experience, and education level (bachelor vs. masters vs. PhD) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will add all scores on 100 scale of each employee of each company, then divided by the number of employees of each company to get each company's score culture.\n",
    "<br> There are three criteria to consider calculating scores of employees individually: employees’ tenure, total working experience, and education level\n",
    "* Employees’ tenure: I'll put them into 5 bins\n",
    "* Total working experience: I'll put them into 5 bins\n",
    "* Education level: I'll put them into 7 bins\n",
    "<br>So, there are totally 7*5*5 = 175 unique sets containing the three criteria.\n",
    "<br>Then, I will count how many unique sets each company has divided by 175 and multiplied by 100 -> diversity score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_degree(d):\n",
    "    if re.search(r'[Pp]ostgraduate | [Pp]ost [Gg]raduate', d):\n",
    "         return 'PhD'\n",
    "    elif re.search(r\"[Mm]aster | [Mm]aster's | [Gg]raduate | [Mm][Bb][Aa] | [Mm][Aa] | [Gg]raduation\", d):\n",
    "        return \"Master\"\n",
    "    elif re.search(r\"[Bb]achelor | [Bb]achelor's | [Bb][Aa] | [Bb][Ss] | [Bb][Ss][Cc] | [Uu]ndergraduate\", d):\n",
    "        return 'Bachelor'\n",
    "    elif re.search(r\"[Aa]\\s?-\\s?[Ll]evel\", d):\n",
    "        return 'Associate'\n",
    "    elif re.search(r\"[Hh]igh\\s?[Ss]chool\", d):\n",
    "        return 'High school'\n",
    "    elif re.search(r\"[Cc]ertificate | [Cc]ertified | [Ll]icen[cs]e | [Dd]i[loma]\", d):\n",
    "        return 'Certificate'\n",
    "    else:\n",
    "        return \"Other\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binnings(a_list, number_of_bins=5):\n",
    "    maximum = max(a_list)\n",
    "    minimum = min(a_list)\n",
    "    distance = (maximum - minimum) / number_of_bins\n",
    "    binnings = []\n",
    "    for i in range(number_of_bins):\n",
    "        binnings.append(minimum + i*distance)\n",
    "    return binnings\n",
    "\n",
    "def assign_to_bin(score, binning_list):\n",
    "    my_bin = 0\n",
    "    for i in range(len(binning_list)):\n",
    "        if score > binning_list[i]:\n",
    "            my_bin = i + 1\n",
    "        else:\n",
    "            break\n",
    "    return my_bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:5170: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[name] = value\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py:4536: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  downcast=downcast,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "com_a_score = com_a[['existing_work_years', 'total_working_days', 'degree']]\n",
    "com_a_score.existing_work_years = com_a_score.existing_work_years.astype(float)\n",
    "com_a_score.total_working_days = com_a_score.total_working_days.astype(float)\n",
    "\n",
    "# I'll impute the most frequent degree into column 'degree'\n",
    "com_a_score['degree'].fillna(\"General Bachelor's\", inplace=True) \n",
    "com_a_score['degree_type'] = com_a_score['degree'].apply(extract_degree)\n",
    "com_a_score['existing_work_years_encoded'] = list(assign_to_bin(x, binnings(list(com_a_score['existing_work_years']))) for x in com_a_score['existing_work_years'])\n",
    "com_a_score['total_working_days_encoded'] = list(assign_to_bin(x, binnings(list(com_a_score['total_working_days']))) for x in com_a_score['total_working_days'])\n",
    "com_a_score['degree_encoded'] = le.fit_transform(com_a_score['degree_type'])\n",
    "com_a_diversity_code = list(zip(com_a_score.existing_work_years_encoded, com_a_score.total_working_days_encoded, com_a_score.degree_encoded))\n",
    "com_a_diversity_score = 0\n",
    "com_a_diversity_sets = set()\n",
    "for i in com_a_diversity_code:\n",
    "    if i not in com_a_diversity_sets:\n",
    "        com_a_diversity_sets.add(i)\n",
    "        com_a_diversity_score += 1\n",
    "com_a_diversity_score = com_a_diversity_score * 100 / 175"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "com_h_score = com_h[['existing_work_years', 'total_working_days', 'degree']]\n",
    "com_h_score.existing_work_years = com_h_score.existing_work_years.astype(float)\n",
    "com_h_score.total_working_days = com_h_score.total_working_days.astype(float)\n",
    "\n",
    "# I'll impute the most frequent degree into column 'degree'\n",
    "com_h_score['degree'].fillna(\"General Bachelor's\", inplace=True) \n",
    "com_h_score['degree_type'] = com_h_score['degree'].apply(extract_degree)\n",
    "com_h_score['existing_work_years_encoded'] = list(assign_to_bin(x, binnings(list(com_h_score['existing_work_years']))) for x in com_h_score['existing_work_years'])\n",
    "com_h_score['total_working_days_encoded'] = list(assign_to_bin(x, binnings(list(com_h_score['total_working_days']))) for x in com_h_score['total_working_days'])\n",
    "com_h_score['degree_encoded'] = le.fit_transform(com_h_score['degree_type'])\n",
    "com_h_diversity_code = list(zip(com_h_score.existing_work_years_encoded, com_h_score.total_working_days_encoded, com_h_score.degree_encoded))\n",
    "com_h_diversity_score = 0\n",
    "com_h_diversity_sets = set()\n",
    "for i in com_h_diversity_code:\n",
    "    if i not in com_h_diversity_sets:\n",
    "        com_h_diversity_sets.add(i)\n",
    "        com_h_diversity_score += 1\n",
    "com_h_diversity_score = com_h_diversity_score * 100 / 175"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "com_n_score = com_n[['existing_work_years', 'total_working_days', 'degree']]\n",
    "com_n_score.existing_work_years = com_n_score.existing_work_years.astype(float)\n",
    "com_n_score.total_working_days = com_n_score.total_working_days.astype(float)\n",
    "\n",
    "# I'll impute the most frequent degree into column 'degree'\n",
    "com_n_score['degree'].fillna(\"General Bachelor's\", inplace=True) \n",
    "com_n_score['degree_type'] = com_n_score['degree'].apply(extract_degree)\n",
    "com_n_score['existing_work_years_encoded'] = list(assign_to_bin(x, binnings(list(com_n_score['existing_work_years']))) for x in com_n_score['existing_work_years'])\n",
    "com_n_score['total_working_days_encoded'] = list(assign_to_bin(x, binnings(list(com_n_score['total_working_days']))) for x in com_n_score['total_working_days'])\n",
    "com_n_score['degree_encoded'] = le.fit_transform(com_n_score['degree_type'])\n",
    "com_n_diversity_code = list(zip(com_n_score.existing_work_years_encoded, com_n_score.total_working_days_encoded, com_n_score.degree_encoded))\n",
    "com_n_diversity_score = 0\n",
    "com_n_diversity_sets = set()\n",
    "for i in com_n_diversity_code:\n",
    "    if i not in com_n_diversity_sets:\n",
    "        com_n_diversity_sets.add(i)\n",
    "        com_n_diversity_score += 1\n",
    "com_n_diversity_score = com_n_diversity_score * 100 / 175"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49.714285714285715"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "com_a_diversity_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.428571428571429"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "com_h_diversity_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26.285714285714285"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "com_n_diversity_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "div_scores = pd.DataFrame(data={'A': com_a_diversity_score, 'H': com_h_diversity_score, 'N': com_n_diversity_score}, index=['Diversity scores of companies in percentage'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "div_scores.to_excel('Diversity scores.xlxs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If I have time, I can create functions to make the code look more professional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b.\tWhat additional data would you like for each individual in order to help build a better culture ranking model? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gender, Race, Locust of control, Political affiliation, Born in the US?, First generation? Individualism or Collectivism? "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
