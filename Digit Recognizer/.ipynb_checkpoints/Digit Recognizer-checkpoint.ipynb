{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The data sets are from Kaggle competition: https://www.kaggle.com/c/digit-recognizer/data?select=test.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "train = np.asarray(pd.read_csv('train.csv'))\n",
    "test = np.asarray(pd.read_csv('test.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert X to 28 x 28 and y to a vector\n",
    "X_train = train[:, 1:].reshape(-1, 28, 28)\n",
    "y_train = train[:,0].reshape(-1,)\n",
    "X_test = test.reshape(-1, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x18cd5080808>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show an image example\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.gray()\n",
    "plt.matshow(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, stratify=y_train, test_size=0.03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode y_train and y_test\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "y_train = to_categorical(y_train, 10).astype(int)\n",
    "y_val = to_categorical(y_val, 10).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, BatchNormalization, Dropout\n",
    "from keras.layers import LeakyReLU\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "input_shape = (X_train.shape[1], )\n",
    "# Create the keras tuner model.\n",
    "def build_model(learning_rate = 0.01, activation = tf.nn.leaky_relu):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(16, activation=tf.nn.leaky_relu))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(32, activation=tf.nn.leaky_relu))\n",
    "    model.add(Dense(64, activation=tf.nn.leaky_relu))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    opt = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4000\n",
      "1247/1247 [==============================] - 6s 4ms/step - loss: 0.3666 - accuracy: 0.8874 - val_loss: 0.1940 - val_accuracy: 0.9381\n",
      "Epoch 2/4000\n",
      "1247/1247 [==============================] - 4s 3ms/step - loss: 0.1921 - accuracy: 0.9438 - val_loss: 0.1774 - val_accuracy: 0.9448\n",
      "Epoch 3/4000\n",
      "1247/1247 [==============================] - 3s 2ms/step - loss: 0.1805 - accuracy: 0.9455 - val_loss: 0.2053 - val_accuracy: 0.9419\n",
      "Epoch 4/4000\n",
      "1247/1247 [==============================] - 3s 2ms/step - loss: 0.1702 - accuracy: 0.9488 - val_loss: 0.1812 - val_accuracy: 0.9424\n",
      "Epoch 5/4000\n",
      "1247/1247 [==============================] - 3s 2ms/step - loss: 0.1659 - accuracy: 0.9516 - val_loss: 0.2371 - val_accuracy: 0.9376\n",
      "Epoch 6/4000\n",
      "1247/1247 [==============================] - 3s 2ms/step - loss: 0.1695 - accuracy: 0.9494 - val_loss: 0.1991 - val_accuracy: 0.9486\n",
      "Epoch 7/4000\n",
      "1247/1247 [==============================] - 3s 2ms/step - loss: 0.1649 - accuracy: 0.9506 - val_loss: 0.2063 - val_accuracy: 0.9452\n",
      "Epoch 8/4000\n",
      "1247/1247 [==============================] - 3s 2ms/step - loss: 0.1628 - accuracy: 0.9524 - val_loss: 0.1951 - val_accuracy: 0.9457\n",
      "Epoch 9/4000\n",
      "1247/1247 [==============================] - 3s 2ms/step - loss: 0.1516 - accuracy: 0.9546 - val_loss: 0.1702 - val_accuracy: 0.9481\n",
      "Epoch 10/4000\n",
      "1247/1247 [==============================] - 3s 2ms/step - loss: 0.1532 - accuracy: 0.9566 - val_loss: 0.2002 - val_accuracy: 0.9419\n",
      "Epoch 11/4000\n",
      "1247/1247 [==============================] - 3s 2ms/step - loss: 0.1535 - accuracy: 0.9560 - val_loss: 0.2387 - val_accuracy: 0.9386\n",
      "Epoch 12/4000\n",
      "1247/1247 [==============================] - 3s 2ms/step - loss: 0.1599 - accuracy: 0.9530 - val_loss: 0.2623 - val_accuracy: 0.9233\n",
      "Epoch 13/4000\n",
      "1247/1247 [==============================] - 3s 2ms/step - loss: 0.1570 - accuracy: 0.9545 - val_loss: 0.1910 - val_accuracy: 0.9548\n",
      "Epoch 14/4000\n",
      "1247/1247 [==============================] - 3s 2ms/step - loss: 0.1587 - accuracy: 0.9537 - val_loss: 0.2259 - val_accuracy: 0.9395\n",
      "Epoch 15/4000\n",
      "1247/1247 [==============================] - 3s 2ms/step - loss: 0.1447 - accuracy: 0.9570 - val_loss: 0.2277 - val_accuracy: 0.9481\n",
      "Epoch 16/4000\n",
      "1247/1247 [==============================] - 3s 2ms/step - loss: 0.1580 - accuracy: 0.9555 - val_loss: 0.2017 - val_accuracy: 0.9467\n",
      "Epoch 17/4000\n",
      "1247/1247 [==============================] - 3s 2ms/step - loss: 0.1462 - accuracy: 0.9577 - val_loss: 0.1627 - val_accuracy: 0.9590\n",
      "Epoch 18/4000\n",
      "1247/1247 [==============================] - 3s 2ms/step - loss: 0.1481 - accuracy: 0.9569 - val_loss: 0.1725 - val_accuracy: 0.9595\n",
      "Epoch 19/4000\n",
      "1247/1247 [==============================] - 3s 2ms/step - loss: 0.1616 - accuracy: 0.9542 - val_loss: 0.1836 - val_accuracy: 0.9548\n",
      "Epoch 20/4000\n",
      "1247/1247 [==============================] - 3s 2ms/step - loss: 0.1397 - accuracy: 0.9588 - val_loss: 0.2143 - val_accuracy: 0.9457\n",
      "Epoch 21/4000\n",
      "1247/1247 [==============================] - 3s 2ms/step - loss: 0.1451 - accuracy: 0.9573 - val_loss: 0.1982 - val_accuracy: 0.9457\n",
      "Epoch 22/4000\n",
      "1247/1247 [==============================] - 3s 2ms/step - loss: 0.1504 - accuracy: 0.9563 - val_loss: 0.1735 - val_accuracy: 0.9533\n",
      "Epoch 23/4000\n",
      "1247/1247 [==============================] - 3s 2ms/step - loss: 0.1484 - accuracy: 0.9575 - val_loss: 0.1923 - val_accuracy: 0.9552\n",
      "Epoch 24/4000\n",
      "1247/1247 [==============================] - 3s 2ms/step - loss: 0.1477 - accuracy: 0.9563 - val_loss: 0.2001 - val_accuracy: 0.9562\n",
      "Epoch 25/4000\n",
      "1247/1247 [==============================] - 3s 2ms/step - loss: 0.1398 - accuracy: 0.9596 - val_loss: 0.2138 - val_accuracy: 0.9348\n",
      "Epoch 26/4000\n",
      "1247/1247 [==============================] - 3s 2ms/step - loss: 0.1420 - accuracy: 0.9596 - val_loss: 0.2259 - val_accuracy: 0.9476\n",
      "Epoch 27/4000\n",
      "1247/1247 [==============================] - 3s 2ms/step - loss: 0.1469 - accuracy: 0.9580 - val_loss: 0.2056 - val_accuracy: 0.9443\n",
      "Epoch 28/4000\n",
      "1247/1247 [==============================] - 3s 2ms/step - loss: 0.1489 - accuracy: 0.9575 - val_loss: 0.1728 - val_accuracy: 0.9548\n",
      "Epoch 29/4000\n",
      "1247/1247 [==============================] - 3s 2ms/step - loss: 0.1406 - accuracy: 0.9584 - val_loss: 0.2172 - val_accuracy: 0.9510\n",
      "Epoch 30/4000\n",
      "1247/1247 [==============================] - 3s 2ms/step - loss: 0.1482 - accuracy: 0.9561 - val_loss: 0.2101 - val_accuracy: 0.9495\n",
      "Epoch 31/4000\n",
      "1247/1247 [==============================] - 3s 2ms/step - loss: 0.1459 - accuracy: 0.9593 - val_loss: 0.2227 - val_accuracy: 0.9414\n",
      "Epoch 32/4000\n",
      "1247/1247 [==============================] - 3s 2ms/step - loss: 0.1397 - accuracy: 0.9602 - val_loss: 0.1992 - val_accuracy: 0.9562\n",
      "Epoch 33/4000\n",
      "1247/1247 [==============================] - 3s 2ms/step - loss: 0.1532 - accuracy: 0.9568 - val_loss: 0.2258 - val_accuracy: 0.9462\n",
      "Epoch 34/4000\n",
      "1247/1247 [==============================] - 3s 2ms/step - loss: 0.1629 - accuracy: 0.9549 - val_loss: 0.2141 - val_accuracy: 0.9519\n",
      "Epoch 35/4000\n",
      "1247/1247 [==============================] - 3s 2ms/step - loss: 0.1462 - accuracy: 0.9597 - val_loss: 0.2198 - val_accuracy: 0.9490\n",
      "Epoch 36/4000\n",
      "1247/1247 [==============================] - 3s 2ms/step - loss: 0.1438 - accuracy: 0.9584 - val_loss: 0.2036 - val_accuracy: 0.9490\n",
      "Epoch 37/4000\n",
      "1247/1247 [==============================] - 3s 2ms/step - loss: 0.1465 - accuracy: 0.9571 - val_loss: 0.2576 - val_accuracy: 0.9500\n",
      "Epoch 38/4000\n",
      "1247/1247 [==============================] - 3s 2ms/step - loss: 0.1605 - accuracy: 0.9577 - val_loss: 0.2273 - val_accuracy: 0.9471\n",
      "Epoch 39/4000\n",
      "1247/1247 [==============================] - 3s 2ms/step - loss: 0.1589 - accuracy: 0.9571 - val_loss: 0.2128 - val_accuracy: 0.9529\n",
      "Epoch 40/4000\n",
      "1247/1247 [==============================] - 3s 2ms/step - loss: 0.1331 - accuracy: 0.9622 - val_loss: 0.3078 - val_accuracy: 0.9229\n",
      "Epoch 41/4000\n",
      "1247/1247 [==============================] - 3s 2ms/step - loss: 0.1562 - accuracy: 0.9541 - val_loss: 0.2318 - val_accuracy: 0.9457\n",
      "Epoch 42/4000\n",
      "1247/1247 [==============================] - 3s 2ms/step - loss: 0.1473 - accuracy: 0.9588 - val_loss: 0.2836 - val_accuracy: 0.9462\n",
      "Epoch 43/4000\n",
      "1247/1247 [==============================] - 3s 2ms/step - loss: 0.1570 - accuracy: 0.9591 - val_loss: 0.1761 - val_accuracy: 0.9538\n",
      "Epoch 44/4000\n",
      "1247/1247 [==============================] - 3s 2ms/step - loss: 0.1302 - accuracy: 0.9608 - val_loss: 0.2200 - val_accuracy: 0.9533\n",
      "Epoch 45/4000\n",
      "1247/1247 [==============================] - 3s 2ms/step - loss: 0.1472 - accuracy: 0.9592 - val_loss: 0.2516 - val_accuracy: 0.9471\n",
      "Epoch 46/4000\n",
      "1247/1247 [==============================] - 3s 2ms/step - loss: 0.1442 - accuracy: 0.9601 - val_loss: 0.2737 - val_accuracy: 0.9405\n",
      "Epoch 47/4000\n",
      "1247/1247 [==============================] - 3s 2ms/step - loss: 0.1445 - accuracy: 0.9589 - val_loss: 0.2258 - val_accuracy: 0.9519\n",
      "Epoch 48/4000\n",
      "1247/1247 [==============================] - 3s 2ms/step - loss: 0.1422 - accuracy: 0.9593 - val_loss: 0.2207 - val_accuracy: 0.9495\n",
      "Epoch 49/4000\n",
      "1247/1247 [==============================] - 3s 2ms/step - loss: 0.1440 - accuracy: 0.9589 - val_loss: 0.2686 - val_accuracy: 0.9438\n",
      "Epoch 50/4000\n",
      "1247/1247 [==============================] - 3s 2ms/step - loss: 0.1513 - accuracy: 0.9576 - val_loss: 0.2590 - val_accuracy: 0.9443\n",
      "Epoch 51/4000\n",
      "1247/1247 [==============================] - 3s 2ms/step - loss: 0.1441 - accuracy: 0.9606 - val_loss: 0.3258 - val_accuracy: 0.9233\n",
      "Epoch 52/4000\n",
      "1247/1247 [==============================] - 3s 2ms/step - loss: 0.1496 - accuracy: 0.9572 - val_loss: 0.2673 - val_accuracy: 0.9362\n",
      "Epoch 53/4000\n",
      "1247/1247 [==============================] - 3s 2ms/step - loss: 0.1362 - accuracy: 0.9606 - val_loss: 0.2405 - val_accuracy: 0.9395\n",
      "Epoch 54/4000\n",
      "1247/1247 [==============================] - 3s 2ms/step - loss: 0.1359 - accuracy: 0.9607 - val_loss: 0.1885 - val_accuracy: 0.9581\n",
      "Epoch 55/4000\n",
      "1247/1247 [==============================] - 3s 2ms/step - loss: 0.1383 - accuracy: 0.9613 - val_loss: 0.2774 - val_accuracy: 0.9343\n",
      "Epoch 56/4000\n",
      "1247/1247 [==============================] - 3s 2ms/step - loss: 0.1333 - accuracy: 0.9614 - val_loss: 0.2276 - val_accuracy: 0.9510\n",
      "Epoch 57/4000\n",
      "1247/1247 [==============================] - 3s 2ms/step - loss: 0.1391 - accuracy: 0.9610 - val_loss: 0.2408 - val_accuracy: 0.9462\n",
      "Epoch 58/4000\n",
      "1247/1247 [==============================] - 3s 2ms/step - loss: 0.1431 - accuracy: 0.9595 - val_loss: 0.2389 - val_accuracy: 0.9476\n",
      "Epoch 59/4000\n",
      "1247/1247 [==============================] - 3s 2ms/step - loss: 0.1424 - accuracy: 0.9604 - val_loss: 0.2487 - val_accuracy: 0.9400\n",
      "Epoch 60/4000\n",
      "1247/1247 [==============================] - 3s 2ms/step - loss: 0.1351 - accuracy: 0.9610 - val_loss: 0.3114 - val_accuracy: 0.9314\n",
      "Epoch 61/4000\n",
      "1247/1247 [==============================] - 3s 2ms/step - loss: 0.1506 - accuracy: 0.9590 - val_loss: 0.2484 - val_accuracy: 0.9433\n",
      "Epoch 62/4000\n",
      "1247/1247 [==============================] - 3s 2ms/step - loss: 0.1460 - accuracy: 0.9577 - val_loss: 0.2677 - val_accuracy: 0.9414\n",
      "Epoch 63/4000\n",
      "1247/1247 [==============================] - 3s 2ms/step - loss: 0.1504 - accuracy: 0.9568 - val_loss: 0.2503 - val_accuracy: 0.9481\n",
      "Epoch 64/4000\n",
      "1247/1247 [==============================] - 3s 2ms/step - loss: 0.1367 - accuracy: 0.9621 - val_loss: 0.2463 - val_accuracy: 0.9481\n",
      "Epoch 65/4000\n",
      "1247/1247 [==============================] - 3s 2ms/step - loss: 0.1307 - accuracy: 0.9635 - val_loss: 0.3141 - val_accuracy: 0.9352\n",
      "Epoch 66/4000\n",
      "1247/1247 [==============================] - 3s 2ms/step - loss: 0.1475 - accuracy: 0.9584 - val_loss: 0.2673 - val_accuracy: 0.9471\n",
      "Epoch 67/4000\n",
      "1247/1247 [==============================] - 3s 2ms/step - loss: 0.1271 - accuracy: 0.9619 - val_loss: 0.2557 - val_accuracy: 0.9414\n",
      "Epoch 68/4000\n",
      "1247/1247 [==============================] - 3s 3ms/step - loss: 0.1448 - accuracy: 0.9590 - val_loss: 0.2033 - val_accuracy: 0.9510\n",
      "Epoch 00068: early stopping\n",
      "Train: 0.963, Test: 0.960\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.models import load_model\n",
    "# simple early stopping\n",
    "es = EarlyStopping(monitor='val_accuracy', verbose=1, patience=50)\n",
    "mc = ModelCheckpoint('best_model.h5', monitor='val_accuracy',verbose=0, save_best_only=True)\n",
    "model = build_model()\n",
    "# fit model\n",
    "history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=4000, verbose=1, callbacks=[es, mc])\n",
    "# load the saved model\n",
    "saved_model = load_model('best_model.h5', custom_objects={'leaky_relu': tf.nn.leaky_relu})\n",
    "# evaluate the model\n",
    "_, train_acc = saved_model.evaluate(X_train, y_train, verbose=0)\n",
    "_, test_acc = saved_model.evaluate(X_val, y_val, verbose=0)\n",
    "print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict target vector\n",
    "y_pred = saved_model.predict(X_test)\n",
    "# Return the column of max probabilities\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "y_pred = pd.DataFrame(y_pred, columns=['Label'])\n",
    "y_pred.index += 1\n",
    "y_pred.index.name='ImageId'\n",
    "y_pred.to_csv('prediction.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.system(\"shutdown /s\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:gputest] *",
   "language": "python",
   "name": "conda-env-gputest-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
