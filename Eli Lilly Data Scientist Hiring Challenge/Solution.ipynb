{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "https://assessment.hackerearth.com/challenges/hiring/eli-lilly-data-scientist-hiring-challenge-2021/problems/e0ba253fe5e44ea0b9965e78d6915d5e/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .time    { background: #40CC40; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tbody td { text-align: left; }\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .sp {  opacity: 0.25;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       ".datatable .frame thead tr.colnames {  background-image: url('data:image/png;base64,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');  background-repeat: repeat-x;  background-size: 14px;  height: 28px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import datatable as dt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "\n",
    "def clean_data(url, train=True):\n",
    "    df = dt.fread(url).to_pandas()\n",
    "    df.set_index('instance_id', inplace=True, drop=True)\n",
    "    df.drop(columns='track_name', inplace=True)\n",
    "    # Get the column's name if the column is of string type\n",
    "    for col in df.iloc[:, :-1].select_dtypes(exclude=[np.number]).columns:\n",
    "        if col != 'music_genre':\n",
    "            df[col] = pd.Categorical(df[col]).codes\n",
    "\n",
    "    if train:\n",
    "        oe = LabelEncoder()\n",
    "        target_col = df.columns[-1]\n",
    "        y = df[target_col]\n",
    "        X = df.drop(columns=[target_col])\n",
    "        oe.fit(y)\n",
    "        y = pd.Series(index=y.index, data=oe.transform(y))\n",
    "        return X, y, oe\n",
    "    else:\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_train, y_train, label_encoder = clean_data('train.csv', train=True)\n",
    "X_test = clean_data('test.csv', train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Credit: https://johaupt.github.io/scikit-learn/tutorial/python/data%20processing/ml%20pipeline/model%20interpretation/columnTransformer_feature_names.html\n",
    "def get_feature_names(column_transformer):\n",
    "    \"\"\"Get feature names from all transformers.\n",
    "    Returns\n",
    "    -------\n",
    "    feature_names : list of strings\n",
    "        Names of the features produced by transform.\n",
    "    \"\"\"\n",
    "\n",
    "    # Remove the internal helper function\n",
    "    #check_is_fitted(column_transformer)\n",
    "\n",
    "    # Turn loopkup into function for better handling with pipeline later\n",
    "    def get_names(trans):\n",
    "        # >> Original get_feature_names() method\n",
    "        if trans == 'drop' or (\n",
    "                hasattr(column, '__len__') and not len(column)):\n",
    "            return []\n",
    "        if trans == 'passthrough':\n",
    "            if hasattr(column_transformer, '_df_columns'):\n",
    "                if ((not isinstance(column, slice))\n",
    "                        and all(isinstance(col, str) for col in column)):\n",
    "                    return column\n",
    "                else:\n",
    "                    return column_transformer._df_columns[column]\n",
    "            else:\n",
    "                indices = np.arange(column_transformer._n_features)\n",
    "                return ['x%d' % i for i in indices[column]]\n",
    "        if not hasattr(trans, 'get_feature_names'):\n",
    "            # >>> Change: Return input column names if no method avaiable\n",
    "            # Turn error into a warning\n",
    "            warnings.warn(\"Transformer %s (type %s) does not \"\n",
    "                          \"provide get_feature_names. \"\n",
    "                          \"Will return input column names if available\"\n",
    "                          % (str(name), type(trans).__name__))\n",
    "            # For transformers without a get_features_names method, use the input\n",
    "            # names to the column transformer\n",
    "            if column is None:\n",
    "                return []\n",
    "            else:\n",
    "                return [f for f in column]\n",
    "\n",
    "        return [f for f in trans.get_feature_names()]\n",
    "\n",
    "    ### Start of processing\n",
    "    feature_names = []\n",
    "\n",
    "    # Allow transformers to be pipelines. Pipeline steps are named differently, so preprocessing is needed\n",
    "    if type(column_transformer) == Pipeline:\n",
    "        l_transformers = [(name, trans, None, None) for step, name, trans in column_transformer._iter()]\n",
    "    else:\n",
    "        # For column transformers, follow the original method\n",
    "        l_transformers = list(column_transformer._iter(fitted=True))\n",
    "\n",
    "    for name, trans, column, _ in l_transformers:\n",
    "        if type(trans) == Pipeline:\n",
    "            # Recursive call on pipeline\n",
    "            _names = get_feature_names(trans)\n",
    "            # if pipeline has no transformer that returns names\n",
    "            if len(_names) == 0:\n",
    "                _names = [f for f in column]\n",
    "            feature_names.extend(_names)\n",
    "        else:\n",
    "            feature_names.extend(get_names(trans))\n",
    "\n",
    "    return feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import pickle\n",
    "\n",
    "\n",
    "# Credit: https://stackoverflow.com/questions/60273501/column-specific-processing-in-an-sklearn-pipeline\n",
    "def process_data(X: pd.DataFrame, y: Union[None, pd.Series], train=True):\n",
    "    impute_transformer = Pipeline([('impute', IterativeImputer())])\n",
    "    scale_transformer = Pipeline([('standard_scale', StandardScaler())])\n",
    "\n",
    "    null_cols = X.columns[X.isnull().any()]\n",
    "    to_be_scaled_cols = []\n",
    "    for col in X.columns:\n",
    "        if X[col].nunique() < 3:\n",
    "            continue\n",
    "        else:\n",
    "            to_be_scaled_cols.append(col)\n",
    "    if train:\n",
    "        processor = ColumnTransformer([\n",
    "            ('imputed', impute_transformer, null_cols),\n",
    "            ('scaled', scale_transformer, to_be_scaled_cols),\n",
    "        ], remainder='passthrough')\n",
    "        processor.fit(X)\n",
    "        # Save to file in the current working directory\n",
    "        with open('processor.pkl', 'wb') as file:\n",
    "            pickle.dump(processor, file)\n",
    "        X = pd.DataFrame(processor.transform(X), columns=get_feature_names(processor), index=X.index)\n",
    "        return X, y\n",
    "    else:\n",
    "        # Load from file\n",
    "        with open('processor.pkl', 'rb') as file:\n",
    "            processor = pickle.load(file)\n",
    "        X = pd.DataFrame(processor.transform(X), columns=get_feature_names(processor), index=X.index)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_train, y_train = process_data(X_train, y_train, train=True)\n",
    "X_test = process_data(X_test, None, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_train.to_csv('X_train.csv', header=True)\n",
    "y_train.to_csv('y_train.csv', header=True)\n",
    "X_test.to_csv('X_test.csv', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "X_train = dt.fread(\"X_train.csv\").to_pandas().set_index(keys='instance_id', drop=True)\n",
    "y_train = dt.fread(\"y_train.csv\", header=True).to_pandas().set_index(keys='instance_id', drop=True)\n",
    "X_test = dt.fread(\"X_test.csv\").to_pandas().set_index(keys='instance_id', drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import optuna\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "\n",
    "\n",
    "# Credit: https://medium.com/analytics-vidhya/hyperparameters-optimization-for-lightgbm-catboost-and-xgboost-regressors-using-bayesian-6e7c495947a9\n",
    "# Define an objective function to be maximized.\n",
    "def objective(trial, X_train, y_train, cv, scoring):\n",
    "    classifier = trial.suggest_categorical('classifier', ['lightgbm', 'catboost', 'xgboost'])\n",
    "    model = LGBMClassifier()\n",
    "    # Setup values for the hyperparameters:\n",
    "    if classifier == 'lightgbm':\n",
    "        params = {\n",
    "            \"num_leaves\": trial.suggest_int('num_leaves', 45, 60),\n",
    "            'min_child_samples': trial.suggest_uniform('min_child_samples', 100, 500),\n",
    "            'min_child_weight': trial.suggest_int('min_child_weight', 30, 50, 5),\n",
    "            'subsample': trial.suggest_uniform('subsample', 0.2, 0.8),\n",
    "            'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.4, 0.6),\n",
    "            'reg_alpha': trial.suggest_categorical('reg_alpha', [0, 1e-1, 1, 2, 5, 7, 10, 50, 100]),\n",
    "            'reg_lambda': trial.suggest_categorical('reg_lambda', [0, 1e-1, 1, 5, 10, 20, 50, 100]),\n",
    "        }\n",
    "        model = LGBMClassifier(**params)\n",
    "\n",
    "    elif classifier == 'catboost':\n",
    "        params = {\n",
    "            \"depth\": trial.suggest_int('depth', 1, 10),\n",
    "            'iterations': trial.suggest_categorical('iterations', [250, 100, 500, 1000]),\n",
    "            'learning_rate': trial.suggest_categorical('learning_rate', [0.03, 0.001, 0.01, 0.1, 0.2, 0.3]),\n",
    "            'l2_leaf_reg': trial.suggest_categorical('l2_leaf_reg', [3, 1, 5, 10, 100]),\n",
    "            'border_count': trial.suggest_categorical('border_count', [32, 5, 10, 20, 50, 100, 200]),\n",
    "            'bagging_temperature': trial.suggest_categorical('bagging_temperature', [0.03, 0.09, 0.25, 0.75]),\n",
    "            'random_strength': trial.suggest_categorical('random_strength', [0.2, 0.5, 0.8]),\n",
    "            'max_ctr_complexity': trial.suggest_categorical('max_ctr_complexity', [1, 2, 3, 4, 5])\n",
    "        }\n",
    "        model = CatBoostClassifier(**params)\n",
    "\n",
    "    else:\n",
    "        params = {\n",
    "            \"min_child_weight\": trial.suggest_int('min_child_weight', 14, 20),\n",
    "            'gamma': trial.suggest_int('gamma', 0, 5),\n",
    "            \"max_depth\": trial.suggest_int('max_depth', 5, 10),\n",
    "            'subsample': trial.suggest_uniform('subsample', 0.5, 1.0),\n",
    "            \"colsample_bytree\": trial.suggest_uniform('colsample_bytree', 0.1, 1.0),\n",
    "\n",
    "        }\n",
    "        model = XGBClassifier(**params)\n",
    "\n",
    "    # Scoring method:\n",
    "    score = cross_val_score(model, X_train, y_train, n_jobs=-1, cv=cv, scoring=scoring)\n",
    "    return score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-14 16:01:45,382]\u001b[0m A new study created in memory with name: no-name-5907870d-e5d1-4b15-b7f2-5dc3b8c173b1\u001b[0m\n",
      "\u001b[32m[I 2021-12-14 16:01:56,583]\u001b[0m Trial 0 finished with value: 0.6032451473334677 and parameters: {'classifier': 'xgboost', 'min_child_weight': 18, 'gamma': 0, 'max_depth': 5, 'subsample': 0.566482012209103, 'colsample_bytree': 0.1096541505413382}. Best is trial 0 with value: 0.6032451473334677.\u001b[0m\n",
      "\u001b[32m[I 2021-12-14 16:02:22,959]\u001b[0m Trial 1 finished with value: 0.6123840334489298 and parameters: {'classifier': 'xgboost', 'min_child_weight': 19, 'gamma': 2, 'max_depth': 7, 'subsample': 0.8368097305642075, 'colsample_bytree': 0.46773610748539207}. Best is trial 1 with value: 0.6123840334489298.\u001b[0m\n",
      "\u001b[33m[W 2021-12-14 16:02:23,428]\u001b[0m Trial 2 failed, because the objective function returned nan.\u001b[0m\n",
      "\u001b[32m[I 2021-12-14 16:02:54,248]\u001b[0m Trial 3 finished with value: 0.6169462896869758 and parameters: {'classifier': 'xgboost', 'min_child_weight': 17, 'gamma': 2, 'max_depth': 10, 'subsample': 0.7709131012254264, 'colsample_bytree': 0.446131202588806}. Best is trial 3 with value: 0.6169462896869758.\u001b[0m\n",
      "\u001b[32m[I 2021-12-14 16:03:32,340]\u001b[0m Trial 4 finished with value: 0.6181791788398555 and parameters: {'classifier': 'xgboost', 'min_child_weight': 18, 'gamma': 0, 'max_depth': 5, 'subsample': 0.9204538551754038, 'colsample_bytree': 0.9532056047734623}. Best is trial 4 with value: 0.6181791788398555.\u001b[0m\n",
      "\u001b[33m[W 2021-12-14 16:03:32,543]\u001b[0m Trial 5 failed, because the objective function returned nan.\u001b[0m\n",
      "\u001b[32m[I 2021-12-14 16:15:53,883]\u001b[0m Trial 6 finished with value: 0.6172819193512945 and parameters: {'classifier': 'catboost', 'depth': 9, 'iterations': 1000, 'learning_rate': 0.2, 'l2_leaf_reg': 10, 'border_count': 200, 'bagging_temperature': 0.09, 'random_strength': 0.5, 'max_ctr_complexity': 1}. Best is trial 4 with value: 0.6181791788398555.\u001b[0m\n",
      "\u001b[32m[I 2021-12-14 16:16:40,224]\u001b[0m Trial 7 finished with value: 0.6149051434733989 and parameters: {'classifier': 'xgboost', 'min_child_weight': 17, 'gamma': 0, 'max_depth': 7, 'subsample': 0.9692087799303746, 'colsample_bytree': 0.8583705995740112}. Best is trial 4 with value: 0.6181791788398555.\u001b[0m\n",
      "\u001b[32m[I 2021-12-14 16:17:03,106]\u001b[0m Trial 8 finished with value: 0.6103732725105049 and parameters: {'classifier': 'xgboost', 'min_child_weight': 18, 'gamma': 5, 'max_depth': 9, 'subsample': 0.7036917597641208, 'colsample_bytree': 0.34290836365757915}. Best is trial 4 with value: 0.6181791788398555.\u001b[0m\n",
      "\u001b[33m[W 2021-12-14 16:17:03,326]\u001b[0m Trial 9 failed, because the objective function returned nan.\u001b[0m\n",
      "\u001b[33m[W 2021-12-14 16:17:03,544]\u001b[0m Trial 10 failed, because the objective function returned nan.\u001b[0m\n",
      "\u001b[33m[W 2021-12-14 16:17:03,763]\u001b[0m Trial 11 failed, because the objective function returned nan.\u001b[0m\n",
      "\u001b[32m[I 2021-12-14 16:17:23,072]\u001b[0m Trial 12 finished with value: 0.6151028809078369 and parameters: {'classifier': 'xgboost', 'min_child_weight': 20, 'gamma': 0, 'max_depth': 5, 'subsample': 0.509567849198451, 'colsample_bytree': 0.5772882506015541}. Best is trial 4 with value: 0.6181791788398555.\u001b[0m\n",
      "\u001b[32m[I 2021-12-14 16:22:08,308]\u001b[0m Trial 13 finished with value: 0.48193550253062145 and parameters: {'classifier': 'catboost', 'depth': 10, 'iterations': 1000, 'learning_rate': 0.001, 'l2_leaf_reg': 100, 'border_count': 32, 'bagging_temperature': 0.09, 'random_strength': 0.8, 'max_ctr_complexity': 3}. Best is trial 4 with value: 0.6181791788398555.\u001b[0m\n",
      "\u001b[32m[I 2021-12-14 16:29:10,514]\u001b[0m Trial 14 finished with value: 0.6149968279383177 and parameters: {'classifier': 'catboost', 'depth': 10, 'iterations': 1000, 'learning_rate': 0.1, 'l2_leaf_reg': 3, 'border_count': 50, 'bagging_temperature': 0.09, 'random_strength': 0.2, 'max_ctr_complexity': 1}. Best is trial 4 with value: 0.6181791788398555.\u001b[0m\n",
      "\u001b[33m[W 2021-12-14 16:29:10,749]\u001b[0m Trial 15 failed, because the objective function returned nan.\u001b[0m\n",
      "\u001b[33m[W 2021-12-14 16:29:10,983]\u001b[0m Trial 16 failed, because the objective function returned nan.\u001b[0m\n",
      "\u001b[33m[W 2021-12-14 16:29:11,217]\u001b[0m Trial 17 failed, because the objective function returned nan.\u001b[0m\n",
      "\u001b[33m[W 2021-12-14 16:29:11,452]\u001b[0m Trial 18 failed, because the objective function returned nan.\u001b[0m\n",
      "\u001b[33m[W 2021-12-14 16:29:11,686]\u001b[0m Trial 19 failed, because the objective function returned nan.\u001b[0m\n",
      "\u001b[33m[W 2021-12-14 16:29:11,921]\u001b[0m Trial 20 failed, because the objective function returned nan.\u001b[0m\n",
      "\u001b[33m[W 2021-12-14 16:29:12,155]\u001b[0m Trial 21 failed, because the objective function returned nan.\u001b[0m\n",
      "\u001b[33m[W 2021-12-14 16:29:12,390]\u001b[0m Trial 22 failed, because the objective function returned nan.\u001b[0m\n",
      "\u001b[33m[W 2021-12-14 16:29:12,624]\u001b[0m Trial 23 failed, because the objective function returned nan.\u001b[0m\n",
      "\u001b[33m[W 2021-12-14 16:29:12,858]\u001b[0m Trial 24 failed, because the objective function returned nan.\u001b[0m\n",
      "\u001b[33m[W 2021-12-14 16:29:13,108]\u001b[0m Trial 25 failed, because the objective function returned nan.\u001b[0m\n",
      "\u001b[33m[W 2021-12-14 16:29:13,343]\u001b[0m Trial 26 failed, because the objective function returned nan.\u001b[0m\n",
      "\u001b[33m[W 2021-12-14 16:29:13,561]\u001b[0m Trial 27 failed, because the objective function returned nan.\u001b[0m\n",
      "\u001b[33m[W 2021-12-14 16:29:13,796]\u001b[0m Trial 28 failed, because the objective function returned nan.\u001b[0m\n",
      "\u001b[33m[W 2021-12-14 16:29:14,046]\u001b[0m Trial 29 failed, because the objective function returned nan.\u001b[0m\n",
      "\u001b[33m[W 2021-12-14 16:29:14,280]\u001b[0m Trial 30 failed, because the objective function returned nan.\u001b[0m\n",
      "\u001b[33m[W 2021-12-14 16:29:14,530]\u001b[0m Trial 31 failed, because the objective function returned nan.\u001b[0m\n",
      "\u001b[33m[W 2021-12-14 16:29:14,780]\u001b[0m Trial 32 failed, because the objective function returned nan.\u001b[0m\n",
      "\u001b[33m[W 2021-12-14 16:29:15,015]\u001b[0m Trial 33 failed, because the objective function returned nan.\u001b[0m\n",
      "\u001b[33m[W 2021-12-14 16:29:15,249]\u001b[0m Trial 34 failed, because the objective function returned nan.\u001b[0m\n",
      "\u001b[33m[W 2021-12-14 16:29:15,483]\u001b[0m Trial 35 failed, because the objective function returned nan.\u001b[0m\n",
      "\u001b[33m[W 2021-12-14 16:29:15,718]\u001b[0m Trial 36 failed, because the objective function returned nan.\u001b[0m\n",
      "\u001b[33m[W 2021-12-14 16:29:15,952]\u001b[0m Trial 37 failed, because the objective function returned nan.\u001b[0m\n",
      "\u001b[33m[W 2021-12-14 16:29:16,187]\u001b[0m Trial 38 failed, because the objective function returned nan.\u001b[0m\n",
      "\u001b[33m[W 2021-12-14 16:29:16,421]\u001b[0m Trial 39 failed, because the objective function returned nan.\u001b[0m\n",
      "\u001b[33m[W 2021-12-14 16:29:16,656]\u001b[0m Trial 40 failed, because the objective function returned nan.\u001b[0m\n",
      "\u001b[33m[W 2021-12-14 16:29:16,890]\u001b[0m Trial 41 failed, because the objective function returned nan.\u001b[0m\n",
      "\u001b[33m[W 2021-12-14 16:29:17,140]\u001b[0m Trial 42 failed, because the objective function returned nan.\u001b[0m\n",
      "\u001b[33m[W 2021-12-14 16:29:17,375]\u001b[0m Trial 43 failed, because the objective function returned nan.\u001b[0m\n",
      "\u001b[33m[W 2021-12-14 16:29:17,609]\u001b[0m Trial 44 failed, because the objective function returned nan.\u001b[0m\n",
      "\u001b[33m[W 2021-12-14 16:29:17,844]\u001b[0m Trial 45 failed, because the objective function returned nan.\u001b[0m\n",
      "\u001b[33m[W 2021-12-14 16:29:18,078]\u001b[0m Trial 46 failed, because the objective function returned nan.\u001b[0m\n",
      "\u001b[33m[W 2021-12-14 16:29:18,312]\u001b[0m Trial 47 failed, because the objective function returned nan.\u001b[0m\n",
      "\u001b[33m[W 2021-12-14 16:29:18,549]\u001b[0m Trial 48 failed, because the objective function returned nan.\u001b[0m\n",
      "\u001b[33m[W 2021-12-14 16:29:18,799]\u001b[0m Trial 49 failed, because the objective function returned nan.\u001b[0m\n",
      "\u001b[33m[W 2021-12-14 16:29:19,034]\u001b[0m Trial 50 failed, because the objective function returned nan.\u001b[0m\n",
      "\u001b[33m[W 2021-12-14 16:29:19,268]\u001b[0m Trial 51 failed, because the objective function returned nan.\u001b[0m\n",
      "\u001b[33m[W 2021-12-14 16:29:19,502]\u001b[0m Trial 52 failed, because the objective function returned nan.\u001b[0m\n",
      "\u001b[33m[W 2021-12-14 16:29:19,736]\u001b[0m Trial 53 failed, because the objective function returned nan.\u001b[0m\n",
      "\u001b[33m[W 2021-12-14 16:29:19,971]\u001b[0m Trial 54 failed, because the objective function returned nan.\u001b[0m\n",
      "\u001b[33m[W 2021-12-14 16:29:20,205]\u001b[0m Trial 55 failed, because the objective function returned nan.\u001b[0m\n",
      "\u001b[33m[W 2021-12-14 16:29:20,440]\u001b[0m Trial 56 failed, because the objective function returned nan.\u001b[0m\n",
      "\u001b[33m[W 2021-12-14 16:29:20,675]\u001b[0m Trial 57 failed, because the objective function returned nan.\u001b[0m\n",
      "\u001b[33m[W 2021-12-14 16:29:20,909]\u001b[0m Trial 58 failed, because the objective function returned nan.\u001b[0m\n",
      "\u001b[33m[W 2021-12-14 16:29:21,143]\u001b[0m Trial 59 failed, because the objective function returned nan.\u001b[0m\n",
      "\u001b[33m[W 2021-12-14 16:29:21,362]\u001b[0m Trial 60 failed, because the objective function returned nan.\u001b[0m\n",
      "\u001b[33m[W 2021-12-14 16:29:21,597]\u001b[0m Trial 61 failed, because the objective function returned nan.\u001b[0m\n",
      "\u001b[33m[W 2021-12-14 16:29:21,831]\u001b[0m Trial 62 failed, because the objective function returned nan.\u001b[0m\n",
      "\u001b[33m[W 2021-12-14 16:29:22,065]\u001b[0m Trial 63 failed, because the objective function returned nan.\u001b[0m\n",
      "\u001b[33m[W 2021-12-14 16:29:22,300]\u001b[0m Trial 64 failed, because the objective function returned nan.\u001b[0m\n",
      "\u001b[33m[W 2021-12-14 16:29:22,534]\u001b[0m Trial 65 failed, because the objective function returned nan.\u001b[0m\n",
      "\u001b[33m[W 2021-12-14 16:29:22,769]\u001b[0m Trial 66 failed, because the objective function returned nan.\u001b[0m\n",
      "\u001b[33m[W 2021-12-14 16:29:23,003]\u001b[0m Trial 67 failed, because the objective function returned nan.\u001b[0m\n",
      "\u001b[33m[W 2021-12-14 16:29:23,237]\u001b[0m Trial 68 failed, because the objective function returned nan.\u001b[0m\n",
      "\u001b[33m[W 2021-12-14 16:29:23,472]\u001b[0m Trial 69 failed, because the objective function returned nan.\u001b[0m\n",
      "\u001b[33m[W 2021-12-14 16:29:23,707]\u001b[0m Trial 70 failed, because the objective function returned nan.\u001b[0m\n",
      "\u001b[33m[W 2021-12-14 16:29:23,941]\u001b[0m Trial 71 failed, because the objective function returned nan.\u001b[0m\n",
      "\u001b[33m[W 2021-12-14 16:29:24,175]\u001b[0m Trial 72 failed, because the objective function returned nan.\u001b[0m\n",
      "\u001b[33m[W 2021-12-14 16:29:24,410]\u001b[0m Trial 73 failed, because the objective function returned nan.\u001b[0m\n",
      "\u001b[33m[W 2021-12-14 16:29:24,644]\u001b[0m Trial 74 failed, because the objective function returned nan.\u001b[0m\n",
      "\u001b[33m[W 2021-12-14 16:29:24,878]\u001b[0m Trial 75 failed, because the objective function returned nan.\u001b[0m\n",
      "\u001b[33m[W 2021-12-14 16:29:25,129]\u001b[0m Trial 76 failed, because the objective function returned nan.\u001b[0m\n",
      "\u001b[33m[W 2021-12-14 16:29:25,363]\u001b[0m Trial 77 failed, because the objective function returned nan.\u001b[0m\n",
      "\u001b[33m[W 2021-12-14 16:29:25,582]\u001b[0m Trial 78 failed, because the objective function returned nan.\u001b[0m\n",
      "\u001b[33m[W 2021-12-14 16:29:25,816]\u001b[0m Trial 79 failed, because the objective function returned nan.\u001b[0m\n",
      "\u001b[33m[W 2021-12-14 16:29:26,051]\u001b[0m Trial 80 failed, because the objective function returned nan.\u001b[0m\n",
      "\u001b[33m[W 2021-12-14 16:29:26,285]\u001b[0m Trial 81 failed, because the objective function returned nan.\u001b[0m\n",
      "\u001b[33m[W 2021-12-14 16:29:26,535]\u001b[0m Trial 82 failed, because the objective function returned nan.\u001b[0m\n",
      "\u001b[33m[W 2021-12-14 16:29:26,770]\u001b[0m Trial 83 failed, because the objective function returned nan.\u001b[0m\n",
      "\u001b[33m[W 2021-12-14 16:29:27,004]\u001b[0m Trial 84 failed, because the objective function returned nan.\u001b[0m\n",
      "\u001b[33m[W 2021-12-14 16:29:27,238]\u001b[0m Trial 85 failed, because the objective function returned nan.\u001b[0m\n",
      "\u001b[33m[W 2021-12-14 16:29:27,473]\u001b[0m Trial 86 failed, because the objective function returned nan.\u001b[0m\n",
      "\u001b[33m[W 2021-12-14 16:29:27,723]\u001b[0m Trial 87 failed, because the objective function returned nan.\u001b[0m\n",
      "\u001b[33m[W 2021-12-14 16:29:27,973]\u001b[0m Trial 88 failed, because the objective function returned nan.\u001b[0m\n",
      "\u001b[33m[W 2021-12-14 16:29:28,207]\u001b[0m Trial 89 failed, because the objective function returned nan.\u001b[0m\n",
      "\u001b[33m[W 2021-12-14 16:29:28,457]\u001b[0m Trial 90 failed, because the objective function returned nan.\u001b[0m\n",
      "\u001b[33m[W 2021-12-14 16:29:28,692]\u001b[0m Trial 91 failed, because the objective function returned nan.\u001b[0m\n",
      "\u001b[33m[W 2021-12-14 16:29:28,926]\u001b[0m Trial 92 failed, because the objective function returned nan.\u001b[0m\n",
      "\u001b[33m[W 2021-12-14 16:29:29,161]\u001b[0m Trial 93 failed, because the objective function returned nan.\u001b[0m\n",
      "\u001b[33m[W 2021-12-14 16:29:29,411]\u001b[0m Trial 94 failed, because the objective function returned nan.\u001b[0m\n",
      "\u001b[33m[W 2021-12-14 16:29:29,645]\u001b[0m Trial 95 failed, because the objective function returned nan.\u001b[0m\n",
      "\u001b[33m[W 2021-12-14 16:29:29,895]\u001b[0m Trial 96 failed, because the objective function returned nan.\u001b[0m\n",
      "\u001b[33m[W 2021-12-14 16:29:30,129]\u001b[0m Trial 97 failed, because the objective function returned nan.\u001b[0m\n",
      "\u001b[33m[W 2021-12-14 16:29:30,379]\u001b[0m Trial 98 failed, because the objective function returned nan.\u001b[0m\n",
      "\u001b[33m[W 2021-12-14 16:29:30,614]\u001b[0m Trial 99 failed, because the objective function returned nan.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "ss = StratifiedKFold(n_splits=5)\n",
    "\n",
    "# Create study that minimizes\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(lambda trial: objective(trial, X_train, y_train, cv=ss, scoring='f1_macro'),\n",
    "               n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Five best values\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>value</th>\n",
       "      <th>datetime_start</th>\n",
       "      <th>datetime_complete</th>\n",
       "      <th>duration</th>\n",
       "      <th>params_bagging_temperature</th>\n",
       "      <th>params_border_count</th>\n",
       "      <th>params_classifier</th>\n",
       "      <th>params_colsample_bytree</th>\n",
       "      <th>params_depth</th>\n",
       "      <th>...</th>\n",
       "      <th>params_max_ctr_complexity</th>\n",
       "      <th>params_max_depth</th>\n",
       "      <th>params_min_child_samples</th>\n",
       "      <th>params_min_child_weight</th>\n",
       "      <th>params_num_leaves</th>\n",
       "      <th>params_random_strength</th>\n",
       "      <th>params_reg_alpha</th>\n",
       "      <th>params_reg_lambda</th>\n",
       "      <th>params_subsample</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.62</td>\n",
       "      <td>2021-12-14 16:02:54.248519</td>\n",
       "      <td>2021-12-14 16:03:32.340402</td>\n",
       "      <td>0 days 00:00:38.091883</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>xgboost</td>\n",
       "      <td>0.95</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.92</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.62</td>\n",
       "      <td>2021-12-14 16:03:32.543867</td>\n",
       "      <td>2021-12-14 16:15:53.883322</td>\n",
       "      <td>0 days 00:12:21.339455</td>\n",
       "      <td>0.09</td>\n",
       "      <td>200.00</td>\n",
       "      <td>catboost</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.62</td>\n",
       "      <td>2021-12-14 16:02:23.428408</td>\n",
       "      <td>2021-12-14 16:02:54.248519</td>\n",
       "      <td>0 days 00:00:30.820111</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>xgboost</td>\n",
       "      <td>0.45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.77</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>0.62</td>\n",
       "      <td>2021-12-14 16:17:03.763490</td>\n",
       "      <td>2021-12-14 16:17:23.072920</td>\n",
       "      <td>0 days 00:00:19.309430</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>xgboost</td>\n",
       "      <td>0.58</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.51</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>0.61</td>\n",
       "      <td>2021-12-14 16:22:08.308988</td>\n",
       "      <td>2021-12-14 16:29:10.514406</td>\n",
       "      <td>0 days 00:07:02.205418</td>\n",
       "      <td>0.09</td>\n",
       "      <td>50.00</td>\n",
       "      <td>catboost</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    number  value             datetime_start          datetime_complete  \\\n",
       "4        4   0.62 2021-12-14 16:02:54.248519 2021-12-14 16:03:32.340402   \n",
       "6        6   0.62 2021-12-14 16:03:32.543867 2021-12-14 16:15:53.883322   \n",
       "3        3   0.62 2021-12-14 16:02:23.428408 2021-12-14 16:02:54.248519   \n",
       "12      12   0.62 2021-12-14 16:17:03.763490 2021-12-14 16:17:23.072920   \n",
       "14      14   0.61 2021-12-14 16:22:08.308988 2021-12-14 16:29:10.514406   \n",
       "\n",
       "                 duration  params_bagging_temperature  params_border_count  \\\n",
       "4  0 days 00:00:38.091883                         NaN                  NaN   \n",
       "6  0 days 00:12:21.339455                        0.09               200.00   \n",
       "3  0 days 00:00:30.820111                         NaN                  NaN   \n",
       "12 0 days 00:00:19.309430                         NaN                  NaN   \n",
       "14 0 days 00:07:02.205418                        0.09                50.00   \n",
       "\n",
       "   params_classifier  params_colsample_bytree  params_depth  ...  \\\n",
       "4            xgboost                     0.95           NaN  ...   \n",
       "6           catboost                      NaN          9.00  ...   \n",
       "3            xgboost                     0.45           NaN  ...   \n",
       "12           xgboost                     0.58           NaN  ...   \n",
       "14          catboost                      NaN         10.00  ...   \n",
       "\n",
       "    params_max_ctr_complexity  params_max_depth  params_min_child_samples  \\\n",
       "4                         NaN              5.00                       NaN   \n",
       "6                        1.00               NaN                       NaN   \n",
       "3                         NaN             10.00                       NaN   \n",
       "12                        NaN              5.00                       NaN   \n",
       "14                       1.00               NaN                       NaN   \n",
       "\n",
       "    params_min_child_weight  params_num_leaves  params_random_strength  \\\n",
       "4                     18.00                NaN                     NaN   \n",
       "6                       NaN                NaN                    0.50   \n",
       "3                     17.00                NaN                     NaN   \n",
       "12                    20.00                NaN                     NaN   \n",
       "14                      NaN                NaN                    0.20   \n",
       "\n",
       "    params_reg_alpha  params_reg_lambda  params_subsample     state  \n",
       "4                NaN                NaN              0.92  COMPLETE  \n",
       "6                NaN                NaN               NaN  COMPLETE  \n",
       "3                NaN                NaN              0.77  COMPLETE  \n",
       "12               NaN                NaN              0.51  COMPLETE  \n",
       "14               NaN                NaN               NaN  COMPLETE  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Five best values')\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "study.trials_dataframe().sort_values('value', ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss : FrozenTrial(number=4, values=[0.6181791788398555], datetime_start=datetime.datetime(2021, 12, 14, 16, 2, 54, 248519), datetime_complete=datetime.datetime(2021, 12, 14, 16, 3, 32, 340402), params={'classifier': 'xgboost', 'min_child_weight': 18, 'gamma': 0, 'max_depth': 5, 'subsample': 0.9204538551754038, 'colsample_bytree': 0.9532056047734623}, distributions={'classifier': CategoricalDistribution(choices=('lightgbm', 'catboost', 'xgboost')), 'min_child_weight': IntUniformDistribution(high=20, low=14, step=1), 'gamma': IntUniformDistribution(high=5, low=0, step=1), 'max_depth': IntUniformDistribution(high=10, low=5, step=1), 'subsample': UniformDistribution(high=1.0, low=0.5), 'colsample_bytree': UniformDistribution(high=1.0, low=0.1)}, user_attrs={}, system_attrs={}, intermediate_values={}, trial_id=4, state=TrialState.COMPLETE, value=None)\n",
      "Best hyperparameters: {'classifier': 'xgboost', 'min_child_weight': 18, 'gamma': 0, 'max_depth': 5, 'subsample': 0.9204538551754038, 'colsample_bytree': 0.9532056047734623}\n"
     ]
    }
   ],
   "source": [
    "trial = study.best_trial\n",
    "print(f'Loss : {trial}')\n",
    "print(f\"Best hyperparameters: {trial.params}\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "source": [
    "# plot the optimization history of the study\n",
    "from optuna.visualization.matplotlib import plot_optimization_history\n",
    "\n",
    "plot_optimization_history(study);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier': 'xgboost',\n",
       " 'min_child_weight': 18,\n",
       " 'gamma': 0,\n",
       " 'max_depth': 5,\n",
       " 'subsample': 0.9204538551754038,\n",
       " 'colsample_bytree': 0.9532056047734623}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:29:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.9532056047734623,\n",
       "              enable_categorical=False, gamma=0, gpu_id=-1,\n",
       "              importance_type=None, interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=5,\n",
       "              min_child_weight=18, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=4, num_parallel_tree=1,\n",
       "              objective='multi:softprob', predictor='auto', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=None,\n",
       "              subsample=0.9204538551754038, tree_method='exact',\n",
       "              validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params = {key: value for key, value in study.best_params.items() if key != 'classifier'}\n",
    "if study.best_params['classifier'] == 'lightgbm':\n",
    "    best_model = LGBMClassifier(**best_params)\n",
    "elif study.best_params['classifier'] == 'catboost':\n",
    "    best_model = CatBoostClassifier(**best_params)\n",
    "else:\n",
    "    best_model = XGBClassifier(**best_params)\n",
    "best_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y_pred = best_model.predict(X_test)\n",
    "y_pred = label_encoder.inverse_transform(y_pred)\n",
    "y_pred = pd.DataFrame(data=y_pred, columns=['music_genre'], index=X_test.index)\n",
    "y_pred.index = X_test.index\n",
    "y_pred.to_csv('Predicted value from Optuna.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import webbrowser\n",
    "webbrowser.open('https://youtu.be/5dwxGvmUG90?t=53')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
