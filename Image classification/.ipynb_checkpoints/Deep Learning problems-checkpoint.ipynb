{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://machinelearningmastery.com/how-to-get-started-with-deep-learning-for-computer-vision-7-day-mini-course/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert from integers to floats\n",
    "pixels = pixels.astype('float32')\n",
    "# normalize to the range 0-1\n",
    "pixels /= 255.0\n",
    "# confirm the normalization\n",
    "print('Min: %.1f, Max: %.1f' % (pixels.min(), pixels.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnn with single convolutional, pooling and output layer\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "# create model and add convolutional layer\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), input_shape=(256, 256, 1)),\n",
    "    MaxPooling2D(),\n",
    "    Flatten(),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### example of using a pre-trained model as a classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load an image from file\n",
    "image = load_img('dog1.jpg', target_size=(224, 224))\n",
    "# convert the image pixels to a numpy array\n",
    "image = img_to_array(image)\n",
    "# reshape data for the model\n",
    "image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
    "# prepare the image for the VGG model\n",
    "image = preprocess_input(image)\n",
    "# load the model\n",
    "model = VGG16()\n",
    "# predict the probability across all output classes\n",
    "yhat = model.predict(image)\n",
    "# convert the probabilities to class labels\n",
    "label = decode_predictions(yhat)\n",
    "# retrieve the most likely result, e.g. highest probability\n",
    "label = label[0][0]\n",
    "# print the classification\n",
    "print('%s (%.2f%%)' % (label[1], label[2]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.applications.vgg16 import decode_predictions\n",
    "from keras.applications.vgg16 import VGG16\n",
    "\n",
    "directory = r'D:\\GitHub\\Practice-Data-Science\\Image classification'\n",
    "# load the model\n",
    "model = VGG16()\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.startswith('mon'):\n",
    "        # load an image from file filename.endswith(\".jpg\") or filename.endswith(\".png\") and \n",
    "        image = load_img(filename, target_size=(224, 224))\n",
    "        # convert the image pixels to a numpy array\n",
    "        image = img_to_array(image)\n",
    "        # reshape data for the model\n",
    "        image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
    "        # prepare the image for the VGG model\n",
    "        image = preprocess_input(image)\n",
    "        # predict the probability across all output classes\n",
    "        yhat = model.predict(image)\n",
    "        # convert the probabilities to class labels\n",
    "        label = decode_predictions(yhat)\n",
    "        # retrieve the most likely result, e.g. highest probability\n",
    "#         label = label[0][0]\n",
    "        # print the classification\n",
    "#         print('%s (%.2f%%)' % (label[1], label[2]*100))\n",
    "        print(label)\n",
    "    else:\n",
    "        continue\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiclass classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit a cnn on the fashion mnist dataset\n",
    "from keras.datasets import fashion_mnist\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "# load dataset\n",
    "(trainX, trainY), (testX, testY) = fashion_mnist.load_data()\n",
    "trainX = trainX.reshape((trainX.shape[0], 28, 28, 1))\n",
    "testX = testX.reshape((testX.shape[0], 28, 28, 1))\n",
    "# reshape dataset to have a single channel\n",
    "trainX = trainX.reshape((trainX.shape[0], 28, 28, 1))\n",
    "testX = testX.reshape((testX.shape[0], 28, 28, 1))\n",
    "# convert from integers to floats\n",
    "trainX, testX = trainX.astype('float32'), testX.astype('float32')\n",
    "# normalize to range 0-1\n",
    "trainX,testX  = trainX / 255.0, testX / 255.0\n",
    "# one hot encode target values\n",
    "trainY, testY = to_categorical(trainY), to_categorical(testY)\n",
    "\n",
    "# define model\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=(28, 28, 1)),\n",
    "    MaxPooling2D(),\n",
    "    Flatten(),\n",
    "    Dense(100, activation='relu', kernel_initializer='he_uniform'),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# fit model\n",
    "model.fit(trainX, trainY, epochs=10, batch_size=32, verbose=2)\n",
    "# evaluate model\n",
    "loss, acc = model.evaluate(testX, testY, verbose=0)\n",
    "print(loss, acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example using image augmentation\n",
    "from numpy import expand_dims\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from matplotlib import pyplot\n",
    "# load the image\n",
    "img = load_img('bird.jpg')\n",
    "# convert to numpy array\n",
    "data = img_to_array(img)\n",
    "# expand dimension to one sample\n",
    "samples = expand_dims(data, 0)\n",
    "# create image data augmentation generator\n",
    "datagen = ImageDataGenerator(horizontal_flip=True, vertical_flip=True, rotation_range=90)\n",
    "# prepare iterator\n",
    "it = datagen.flow(samples, batch_size=1)\n",
    "# generate samples and plot\n",
    "for i in range(9):\n",
    "     # define subplot\n",
    "     pyplot.subplot(330 + 1 + i)\n",
    "     # generate batch of images\n",
    "     batch = it.next()\n",
    "     # convert to unsigned integers for viewing\n",
    "     image = batch[0].astype('uint32')\n",
    "     # plot raw pixel data\n",
    "     pyplot.imshow(image)\n",
    "# show the figure\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Face detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# face detection with mtcnn on a photograph\n",
    "from matplotlib import pyplot\n",
    "from matplotlib.patches import Rectangle\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "\n",
    "# load image from file\n",
    "pixels = pyplot.imread('person.jpg')\n",
    "# create the detector, using default weights\n",
    "detector = MTCNN()\n",
    "# detect faces in the image\n",
    "faces = detector.detect_faces(pixels)\n",
    "# plot the image\n",
    "pyplot.imshow(pixels)\n",
    "# get the context for drawing boxes\n",
    "ax = pyplot.gca()\n",
    "# get coordinates from the first face\n",
    "x, y, width, height = faces[0]['box']\n",
    "# create the shape\n",
    "rect = Rectangle((x, y), width, height, fill=False, color='red')\n",
    "# draw the box\n",
    "ax.add_patch(rect)\n",
    "# show the plot\n",
    "pyplot.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
