{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import datatable as dt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "\n",
    "# Problem: https://www.hackerearth.com/challenges/competitive/amexpert-code-lab/machine-learning/credit-card-default-risk-5-95cbc85f/\n",
    "def clean_data(url, y=None, train=True):\n",
    "    df = dt.fread(url).to_pandas()\n",
    "    df.set_index('customer_id', inplace=True)\n",
    "    df.drop(columns='name', inplace=True)\n",
    "    # Replace weird values of a column by the most frequent ones\n",
    "    df = df.replace({'gender': 'XNA'}, 'F').replace({'owns_car': ''}, 'N')\n",
    "    if train:\n",
    "        target_col = df.columns[-1]\n",
    "        y = df[target_col]\n",
    "        y = pd.Series(map(int, y), index=y.index)\n",
    "        X = df.drop(columns=[target_col])\n",
    "        return X, y\n",
    "    else:\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_train, y_train = clean_data('train.csv', train=True)\n",
    "X_test = clean_data('test.csv', train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Credit: https://johaupt.github.io/scikit-learn/tutorial/python/data%20processing/ml%20pipeline/model%20interpretation/columnTransformer_feature_names.html\n",
    "def get_feature_names(column_transformer):\n",
    "    \"\"\"Get feature names from all transformers.\n",
    "    Returns\n",
    "    -------\n",
    "    feature_names : list of strings\n",
    "        Names of the features produced by transform.\n",
    "    \"\"\"\n",
    "\n",
    "    # Remove the internal helper function\n",
    "    #check_is_fitted(column_transformer)\n",
    "\n",
    "    # Turn loopkup into function for better handling with pipeline later\n",
    "    def get_names(trans):\n",
    "        # >> Original get_feature_names() method\n",
    "        if trans == 'drop' or (\n",
    "                hasattr(column, '__len__') and not len(column)):\n",
    "            return []\n",
    "        if trans == 'passthrough':\n",
    "            if hasattr(column_transformer, '_df_columns'):\n",
    "                if ((not isinstance(column, slice))\n",
    "                        and all(isinstance(col, str) for col in column)):\n",
    "                    return column\n",
    "                else:\n",
    "                    return column_transformer._df_columns[column]\n",
    "            else:\n",
    "                indices = np.arange(column_transformer._n_features)\n",
    "                return ['x%d' % i for i in indices[column]]\n",
    "        if not hasattr(trans, 'get_feature_names'):\n",
    "            # >>> Change: Return input column names if no method avaiable\n",
    "            # Turn error into a warning\n",
    "            warnings.warn(\"Transformer %s (type %s) does not \"\n",
    "                          \"provide get_feature_names. \"\n",
    "                          \"Will return input column names if available\"\n",
    "                          % (str(name), type(trans).__name__))\n",
    "            # For transformers without a get_features_names method, use the input\n",
    "            # names to the column transformer\n",
    "            if column is None:\n",
    "                return []\n",
    "            else:\n",
    "                return [f for f in column]\n",
    "\n",
    "        return [f for f in trans.get_feature_names()]\n",
    "\n",
    "    ### Start of processing\n",
    "    feature_names = []\n",
    "\n",
    "    # Allow transformers to be pipelines. Pipeline steps are named differently, so preprocessing is needed\n",
    "    if type(column_transformer) == Pipeline:\n",
    "        l_transformers = [(name, trans, None, None) for step, name, trans in column_transformer._iter()]\n",
    "    else:\n",
    "        # For column transformers, follow the original method\n",
    "        l_transformers = list(column_transformer._iter(fitted=True))\n",
    "\n",
    "    for name, trans, column, _ in l_transformers:\n",
    "        if type(trans) == Pipeline:\n",
    "            # Recursive call on pipeline\n",
    "            _names = get_feature_names(trans)\n",
    "            # if pipeline has no transformer that returns names\n",
    "            if len(_names) == 0:\n",
    "                _names = [f for f in column]\n",
    "            feature_names.extend(_names)\n",
    "        else:\n",
    "            feature_names.extend(get_names(trans))\n",
    "\n",
    "    return feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import pickle\n",
    "\n",
    "\n",
    "# Credit: https://stackoverflow.com/questions/60273501/column-specific-processing-in-an-sklearn-pipeline\n",
    "def process_data(X: pd.DataFrame, y=None, train=True):\n",
    "    impute_transformer = Pipeline([('impute', IterativeImputer())])\n",
    "    one_hot_transformer = Pipeline([('one_hot', OneHotEncoder(drop='first'))])\n",
    "    scale_transformer = Pipeline([('standard_scale', StandardScaler())])\n",
    "\n",
    "    null_cols = X.columns[X.isnull().any()]\n",
    "    oh_cols, to_be_scaled_cols = [], []\n",
    "    for col in X.columns:\n",
    "        if np.issubdtype(X[col].dtype, np.number) and X[col].nunique() < 3:\n",
    "            continue\n",
    "        if not np.issubdtype(X[col].dtype, np.number):\n",
    "            oh_cols.append(col)\n",
    "        else:\n",
    "            to_be_scaled_cols.append(col)\n",
    "\n",
    "    if train:\n",
    "        processor = ColumnTransformer([\n",
    "            ('imputed', impute_transformer, null_cols),\n",
    "            ('encoded', one_hot_transformer, oh_cols),\n",
    "            ('scaled', scale_transformer, to_be_scaled_cols),\n",
    "        ], remainder='passthrough')\n",
    "        processor.fit(X)\n",
    "        # Save to file in the current working directory\n",
    "        with open('processor.pkl', 'wb') as file:\n",
    "            pickle.dump(processor, file)\n",
    "        X = pd.DataFrame(processor.transform(X), columns=get_feature_names(processor), index=X.index)\n",
    "        return X, y\n",
    "    else:\n",
    "        # Load from file\n",
    "        with open('processor.pkl', 'rb') as file:\n",
    "            processor = pickle.load(file)\n",
    "        X = pd.DataFrame(processor.transform(X), columns=get_feature_names(processor), index=X.index)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_train, y_train = process_data(X_train, y_train, train=True)\n",
    "X_test = process_data(X_test, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_train.to_csv('X_train.csv')\n",
    "y_train.to_csv('y_train.csv', header=False)\n",
    "X_test.to_csv('X_test.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}