{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<style type='text/css'>\n.datatable table.frame { margin-bottom: 0; }\n.datatable table.frame thead { border-bottom: none; }\n.datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n.datatable .bool    { background: #DDDD99; }\n.datatable .object  { background: #565656; }\n.datatable .int     { background: #5D9E5D; }\n.datatable .float   { background: #4040CC; }\n.datatable .str     { background: #CC4040; }\n.datatable .time    { background: #40CC40; }\n.datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n.datatable .frame tbody td { text-align: left; }\n.datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n.datatable th:nth-child(2) { padding-left: 12px; }\n.datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n.datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n.datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n.datatable .sp {  opacity: 0.25;}\n.datatable .footer { font-size: 9px; }\n.datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n.datatable .frame thead tr.colnames {  background-image: url('data:image/png;base64,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');  background-repeat: repeat-x;  background-size: 14px;  height: 28px;}\n</style>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import datatable as dt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "\n",
    "# Problem: https://www.hackerearth.com/challenges/competitive/amexpert-code-lab/machine-learning/credit-card-default-risk-5-95cbc85f/\n",
    "def clean_data(url, y=None, train=True):\n",
    "    df = dt.fread(url).to_pandas()\n",
    "    df.set_index('customer_id', inplace=True)\n",
    "    df.drop(columns='name', inplace=True)\n",
    "    # Replace weird values of a column by the most frequent ones\n",
    "    df = df.replace({'gender': 'XNA'}, 'F').replace({'owns_car': ''}, 'N')\n",
    "    if train:\n",
    "        target_col = df.columns[-1]\n",
    "        y = df[target_col]\n",
    "        y = pd.Series(map(int, y), index=y.index)\n",
    "        X = df.drop(columns=[target_col])\n",
    "        return X, y\n",
    "    else:\n",
    "        return df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "X_train, y_train = clean_data('train.csv', train=True)\n",
    "X_test = clean_data('test.csv', train=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Credit: https://johaupt.github.io/scikit-learn/tutorial/python/data%20processing/ml%20pipeline/model%20interpretation/columnTransformer_feature_names.html\n",
    "def get_feature_names(column_transformer):\n",
    "    \"\"\"Get feature names from all transformers.\n",
    "    Returns\n",
    "    -------\n",
    "    feature_names : list of strings\n",
    "        Names of the features produced by transform.\n",
    "    \"\"\"\n",
    "\n",
    "    # Remove the internal helper function\n",
    "    #check_is_fitted(column_transformer)\n",
    "\n",
    "    # Turn loopkup into function for better handling with pipeline later\n",
    "    def get_names(trans):\n",
    "        # >> Original get_feature_names() method\n",
    "        if trans == 'drop' or (\n",
    "                hasattr(column, '__len__') and not len(column)):\n",
    "            return []\n",
    "        if trans == 'passthrough':\n",
    "            if hasattr(column_transformer, '_df_columns'):\n",
    "                if ((not isinstance(column, slice))\n",
    "                        and all(isinstance(col, str) for col in column)):\n",
    "                    return column\n",
    "                else:\n",
    "                    return column_transformer._df_columns[column]\n",
    "            else:\n",
    "                indices = np.arange(column_transformer._n_features)\n",
    "                return ['x%d' % i for i in indices[column]]\n",
    "        if not hasattr(trans, 'get_feature_names'):\n",
    "            # >>> Change: Return input column names if no method avaiable\n",
    "            # Turn error into a warning\n",
    "            warnings.warn(\"Transformer %s (type %s) does not \"\n",
    "                          \"provide get_feature_names. \"\n",
    "                          \"Will return input column names if available\"\n",
    "                          % (str(name), type(trans).__name__))\n",
    "            # For transformers without a get_features_names method, use the input\n",
    "            # names to the column transformer\n",
    "            if column is None:\n",
    "                return []\n",
    "            else:\n",
    "                return [f for f in column]\n",
    "\n",
    "        return [f for f in trans.get_feature_names()]\n",
    "\n",
    "    ### Start of processing\n",
    "    feature_names = []\n",
    "\n",
    "    # Allow transformers to be pipelines. Pipeline steps are named differently, so preprocessing is needed\n",
    "    if type(column_transformer) == Pipeline:\n",
    "        l_transformers = [(name, trans, None, None) for step, name, trans in column_transformer._iter()]\n",
    "    else:\n",
    "        # For column transformers, follow the original method\n",
    "        l_transformers = list(column_transformer._iter(fitted=True))\n",
    "\n",
    "    for name, trans, column, _ in l_transformers:\n",
    "        if type(trans) == Pipeline:\n",
    "            # Recursive call on pipeline\n",
    "            _names = get_feature_names(trans)\n",
    "            # if pipeline has no transformer that returns names\n",
    "            if len(_names) == 0:\n",
    "                _names = [f for f in column]\n",
    "            feature_names.extend(_names)\n",
    "        else:\n",
    "            feature_names.extend(get_names(trans))\n",
    "\n",
    "    return feature_names"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import pickle\n",
    "\n",
    "\n",
    "# Credit: https://stackoverflow.com/questions/60273501/column-specific-processing-in-an-sklearn-pipeline\n",
    "def process_data(X: pd.DataFrame, y=None, train=True):\n",
    "    impute_transformer = Pipeline([('impute', IterativeImputer())])\n",
    "    one_hot_transformer = Pipeline([('one_hot', OneHotEncoder(drop='first'))])\n",
    "    scale_transformer = Pipeline([('standard_scale', StandardScaler())])\n",
    "\n",
    "    null_cols = X.columns[X.isnull().any()]\n",
    "    oh_cols, to_be_scaled_cols = [], []\n",
    "    for col in X.columns:\n",
    "        if np.issubdtype(X[col].dtype, np.number) and X[col].nunique() < 3:\n",
    "            continue\n",
    "        if not np.issubdtype(X[col].dtype, np.number):\n",
    "            oh_cols.append(col)\n",
    "        else:\n",
    "            to_be_scaled_cols.append(col)\n",
    "\n",
    "    if train:\n",
    "        processor = ColumnTransformer([\n",
    "            ('imputed', impute_transformer, null_cols),\n",
    "            ('encoded', one_hot_transformer, oh_cols),\n",
    "            ('scaled', scale_transformer, to_be_scaled_cols),\n",
    "        ], remainder='passthrough')\n",
    "        processor.fit(X)\n",
    "        # Save to file in the current working directory\n",
    "        with open('processor.pkl', 'wb') as file:\n",
    "            pickle.dump(processor, file)\n",
    "        X = pd.DataFrame(processor.transform(X), columns=get_feature_names(processor), index=y.index)\n",
    "        return X, y\n",
    "    else:\n",
    "        # Load from file\n",
    "        with open('processor.pkl', 'rb') as file:\n",
    "            processor = pickle.load(file)\n",
    "        X = pd.DataFrame(processor.transform(X), columns=get_feature_names(processor), index=X.index)\n",
    "        return X"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "X_train, y_train = process_data(X_train, y_train, train=True)\n",
    "X_test = process_data(X_test, train=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "X_train.to_csv('X_train.csv')\n",
    "y_train.to_csv('y_train.csv', header=False)\n",
    "X_test.to_csv('X_test.csv')"
   ],
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "X_train = dt.fread(\"X_train.csv\").to_pandas().set_index(keys='customer_id', drop=True)\n",
    "y_train = dt.fread(\"y_train.csv\").to_pandas().iloc[:, 1]\n",
    "y_train.index = X_train.index\n",
    "X_test = dt.fread(\"X_test.csv\").to_pandas().set_index(keys='customer_id', drop=True)"
   ],
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "import optuna\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "\n",
    "\n",
    "# Credit: https://medium.com/analytics-vidhya/hyperparameters-optimization-for-lightgbm-catboost-and-xgboost-regressors-using-bayesian-6e7c495947a9\n",
    "# Define an objective function to be maximized.\n",
    "def objective(trial, X_train, y_train, cv, scoring):\n",
    "    classifier = trial.suggest_categorical('classifier', ['lightgbm', 'catboost', 'xgboost'])\n",
    "    model = LGBMClassifier()\n",
    "    # Setup values for the hyperparameters:\n",
    "    if classifier == 'lightgbm':\n",
    "        params = {\n",
    "            \"num_leaves\": trial.suggest_int('num_leaves', 45, 60),\n",
    "            'min_child_samples': trial.suggest_uniform('min_child_samples', 100, 500),\n",
    "            'min_child_weight': trial.suggest_int('min_child_weight', 30, 50, 5),\n",
    "            'subsample': trial.suggest_uniform('subsample', 0.2, 0.8),\n",
    "            'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.4, 0.6),\n",
    "            'reg_alpha': trial.suggest_categorical('reg_alpha', [0, 1e-1, 1, 2, 5, 7, 10, 50, 100]),\n",
    "            'reg_lambda': trial.suggest_categorical('reg_lambda', [0, 1e-1, 1, 5, 10, 20, 50, 100]),\n",
    "        }\n",
    "        model = LGBMClassifier(**params)\n",
    "\n",
    "    elif classifier == 'catboost':\n",
    "        params = {\n",
    "            \"depth\": trial.suggest_int('depth', 1, 10),\n",
    "            'iterations': trial.suggest_categorical('iterations', [250, 100, 500, 1000]),\n",
    "            'learning_rate': trial.suggest_categorical('learning_rate', [0.03, 0.001, 0.01, 0.1, 0.2, 0.3]),\n",
    "            'l2_leaf_reg': trial.suggest_categorical('l2_leaf_reg', [3, 1, 5, 10, 100]),\n",
    "            'border_count': trial.suggest_categorical('border_count', [32, 5, 10, 20, 50, 100, 200]),\n",
    "            'bagging_temperature': trial.suggest_categorical('bagging_temperature', [0.03, 0.09, 0.25, 0.75]),\n",
    "            'random_strength': trial.suggest_categorical('random_strength', [0.2, 0.5, 0.8]),\n",
    "            'max_ctr_complexity': trial.suggest_categorical('max_ctr_complexity', [1, 2, 3, 4, 5])\n",
    "        }\n",
    "        model = CatBoostClassifier(**params)\n",
    "\n",
    "    else:\n",
    "        params = {\n",
    "            \"min_child_weight\": trial.suggest_int('min_child_weight', 14, 20),\n",
    "            'gamma': trial.suggest_int('gamma', 0, 5),\n",
    "            \"max_depth\": trial.suggest_int('max_depth', 5, 10),\n",
    "            'subsample': trial.suggest_uniform('subsample', 0.5, 1.0),\n",
    "            \"colsample_bytree\": trial.suggest_uniform('colsample_bytree', 0.1, 1.0),\n",
    "\n",
    "        }\n",
    "        model = XGBClassifier(**params)\n",
    "\n",
    "    # Scoring method:\n",
    "    score = cross_val_score(model, X_train, y_train, n_jobs=-1, cv=cv, scoring=scoring)\n",
    "    return score.mean()"
   ],
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "ss = StratifiedKFold(n_splits=5)\n",
    "\n",
    "# Create study that minimizes\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(lambda trial: objective(trial, X_train, y_train, cv=ss, scoring='f1_macro'),\n",
    "               n_trials=100)"
   ],
   "execution_count": 9,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2021-12-09 23:16:29,728]\u001B[0m A new study created in memory with name: no-name-e077e0df-0e26-450a-9505-0bcaf64c58c9\u001B[0m\n",
      "\u001B[33m[W 2021-12-09 23:16:34,705]\u001B[0m Trial 0 failed, because the objective function returned nan.\u001B[0m\n",
      "\u001B[33m[W 2021-12-09 23:16:35,112]\u001B[0m Trial 1 failed, because the objective function returned nan.\u001B[0m\n",
      "\u001B[33m[W 2021-12-09 23:16:54,509]\u001B[0m Trial 2 failed, because the objective function returned nan.\u001B[0m\n",
      "\u001B[33m[W 2021-12-09 23:16:55,035]\u001B[0m Trial 3 failed, because the objective function returned nan.\u001B[0m\n",
      "\u001B[33m[W 2021-12-09 23:16:55,464]\u001B[0m Trial 4 failed, because the objective function returned nan.\u001B[0m\n",
      "\u001B[33m[W 2021-12-09 23:17:00,444]\u001B[0m Trial 5 failed, because the objective function returned nan.\u001B[0m\n",
      "\u001B[33m[W 2021-12-09 23:17:11,973]\u001B[0m Trial 6 failed, because the objective function returned nan.\u001B[0m\n",
      "\u001B[33m[W 2021-12-09 23:17:14,725]\u001B[0m Trial 7 failed, because the objective function returned nan.\u001B[0m\n",
      "\u001B[33m[W 2021-12-09 23:17:19,319]\u001B[0m Trial 8 failed, because the objective function returned nan.\u001B[0m\n",
      "\u001B[32m[I 2021-12-09 23:17:27,664]\u001B[0m Trial 9 finished with value: 0.921501882407442 and parameters: {'classifier': 'xgboost', 'min_child_weight': 15, 'gamma': 4, 'max_depth': 5, 'subsample': 0.5077030141972413, 'colsample_bytree': 0.6189826657288978}. Best is trial 9 with value: 0.921501882407442.\u001B[0m\n",
      "\u001B[32m[I 2021-12-09 23:17:37,023]\u001B[0m Trial 10 finished with value: 0.9206647670489417 and parameters: {'classifier': 'xgboost', 'min_child_weight': 19, 'gamma': 0, 'max_depth': 7, 'subsample': 0.9743859395632294, 'colsample_bytree': 0.565487024786736}. Best is trial 9 with value: 0.921501882407442.\u001B[0m\n",
      "\u001B[33m[W 2021-12-09 23:17:37,437]\u001B[0m Trial 11 failed, because the objective function returned nan.\u001B[0m\n",
      "\u001B[33m[W 2021-12-09 23:17:53,114]\u001B[0m Trial 12 failed, because the objective function returned nan.\u001B[0m\n",
      "\u001B[33m[W 2021-12-09 23:17:53,497]\u001B[0m Trial 13 failed, because the objective function returned nan.\u001B[0m\n",
      "\u001B[33m[W 2021-12-09 23:18:14,549]\u001B[0m Trial 14 failed, because the objective function returned nan.\u001B[0m\n",
      "\u001B[33m[W 2021-12-09 23:18:15,033]\u001B[0m Trial 15 failed, because the objective function returned nan.\u001B[0m\n",
      "\u001B[32m[I 2021-12-09 23:18:19,735]\u001B[0m Trial 16 finished with value: 0.9237318161819783 and parameters: {'classifier': 'xgboost', 'min_child_weight': 18, 'gamma': 0, 'max_depth': 8, 'subsample': 0.5993495781209559, 'colsample_bytree': 0.11631754891289292}. Best is trial 16 with value: 0.9237318161819783.\u001B[0m\n",
      "\u001B[32m[I 2021-12-09 23:18:26,418]\u001B[0m Trial 17 finished with value: 0.9222959718556301 and parameters: {'classifier': 'xgboost', 'min_child_weight': 20, 'gamma': 2, 'max_depth': 6, 'subsample': 0.6876411376196394, 'colsample_bytree': 0.39081028203267176}. Best is trial 16 with value: 0.9237318161819783.\u001B[0m\n",
      "\u001B[33m[W 2021-12-09 23:18:34,827]\u001B[0m Trial 18 failed, because the objective function returned nan.\u001B[0m\n",
      "\u001B[33m[W 2021-12-09 23:18:50,525]\u001B[0m Trial 19 failed, because the objective function returned nan.\u001B[0m\n",
      "\u001B[32m[I 2021-12-09 23:19:06,030]\u001B[0m Trial 20 finished with value: 0.923264507723635 and parameters: {'classifier': 'xgboost', 'min_child_weight': 16, 'gamma': 5, 'max_depth': 8, 'subsample': 0.5212649256818425, 'colsample_bytree': 0.8363330500947552}. Best is trial 16 with value: 0.9237318161819783.\u001B[0m\n",
      "\u001B[32m[I 2021-12-09 23:19:13,766]\u001B[0m Trial 21 finished with value: 0.9234076238757705 and parameters: {'classifier': 'xgboost', 'min_child_weight': 18, 'gamma': 0, 'max_depth': 10, 'subsample': 0.9773919068225727, 'colsample_bytree': 0.19928276789811034}. Best is trial 16 with value: 0.9237318161819783.\u001B[0m\n",
      "\u001B[33m[W 2021-12-09 23:19:13,953]\u001B[0m Trial 22 failed, because the objective function returned nan.\u001B[0m\n",
      "\u001B[33m[W 2021-12-09 23:19:26,584]\u001B[0m Trial 23 failed, because the objective function returned nan.\u001B[0m\n",
      "\u001B[33m[W 2021-12-09 23:19:40,594]\u001B[0m Trial 24 failed, because the objective function returned nan.\u001B[0m\n",
      "\u001B[32m[I 2021-12-09 23:19:50,111]\u001B[0m Trial 25 finished with value: 0.9222907825724812 and parameters: {'classifier': 'xgboost', 'min_child_weight': 20, 'gamma': 2, 'max_depth': 10, 'subsample': 0.6264647114329851, 'colsample_bytree': 0.43428012188871357}. Best is trial 16 with value: 0.9237318161819783.\u001B[0m\n",
      "\u001B[33m[W 2021-12-09 23:19:50,545]\u001B[0m Trial 26 failed, because the objective function returned nan.\u001B[0m\n",
      "\u001B[33m[W 2021-12-09 23:19:50,938]\u001B[0m Trial 27 failed, because the objective function returned nan.\u001B[0m\n",
      "\u001B[33m[W 2021-12-09 23:19:58,403]\u001B[0m Trial 28 failed, because the objective function returned nan.\u001B[0m\n",
      "\u001B[33m[W 2021-12-09 23:20:04,466]\u001B[0m Trial 29 failed, because the objective function returned nan.\u001B[0m\n",
      "\u001B[32m[I 2021-12-09 23:20:14,406]\u001B[0m Trial 30 finished with value: 0.9222809178152982 and parameters: {'classifier': 'xgboost', 'min_child_weight': 18, 'gamma': 2, 'max_depth': 8, 'subsample': 0.8565181525745302, 'colsample_bytree': 0.43495814343520556}. Best is trial 16 with value: 0.9237318161819783.\u001B[0m\n",
      "\u001B[33m[W 2021-12-09 23:20:14,800]\u001B[0m Trial 31 failed, because the objective function returned nan.\u001B[0m\n",
      "\u001B[33m[W 2021-12-09 23:20:15,182]\u001B[0m Trial 32 failed, because the objective function returned nan.\u001B[0m\n",
      "\u001B[32m[I 2021-12-09 23:20:23,009]\u001B[0m Trial 33 finished with value: 0.9227933757332117 and parameters: {'classifier': 'xgboost', 'min_child_weight': 17, 'gamma': 0, 'max_depth': 5, 'subsample': 0.6443079038012942, 'colsample_bytree': 0.4922721025221428}. Best is trial 16 with value: 0.9237318161819783.\u001B[0m\n",
      "\u001B[33m[W 2021-12-09 23:20:48,147]\u001B[0m Trial 34 failed, because the objective function returned nan.\u001B[0m\n",
      "\u001B[33m[W 2021-12-09 23:20:54,122]\u001B[0m Trial 35 failed, because the objective function returned nan.\u001B[0m\n",
      "\u001B[33m[W 2021-12-09 23:20:56,535]\u001B[0m Trial 36 failed, because the objective function returned nan.\u001B[0m\n",
      "\u001B[32m[I 2021-12-09 23:21:02,642]\u001B[0m Trial 37 finished with value: 0.9231528709340469 and parameters: {'classifier': 'xgboost', 'min_child_weight': 14, 'gamma': 2, 'max_depth': 5, 'subsample': 0.6551566043095995, 'colsample_bytree': 0.35319066155451595}. Best is trial 16 with value: 0.9237318161819783.\u001B[0m\n",
      "\u001B[33m[W 2021-12-09 23:21:03,042]\u001B[0m Trial 38 failed, because the objective function returned nan.\u001B[0m\n",
      "\u001B[33m[W 2021-12-09 23:21:09,970]\u001B[0m Trial 39 failed, because the objective function returned nan.\u001B[0m\n",
      "\u001B[33m[W 2021-12-09 23:21:10,466]\u001B[0m Trial 40 failed, because the objective function returned nan.\u001B[0m\n",
      "\u001B[33m[W 2021-12-09 23:21:10,866]\u001B[0m Trial 41 failed, because the objective function returned nan.\u001B[0m\n",
      "\u001B[33m[W 2021-12-09 23:21:11,262]\u001B[0m Trial 42 failed, because the objective function returned nan.\u001B[0m\n",
      "\u001B[33m[W 2021-12-09 23:21:14,929]\u001B[0m Trial 43 failed, because the objective function returned nan.\u001B[0m\n",
      "\u001B[33m[W 2021-12-09 23:21:19,498]\u001B[0m Trial 44 failed, because the objective function returned nan.\u001B[0m\n",
      "\u001B[33m[W 2021-12-09 23:21:19,897]\u001B[0m Trial 45 failed, because the objective function returned nan.\u001B[0m\n",
      "\u001B[33m[W 2021-12-09 23:21:20,393]\u001B[0m Trial 46 failed, because the objective function returned nan.\u001B[0m\n",
      "\u001B[33m[W 2021-12-09 23:21:42,039]\u001B[0m Trial 47 failed, because the objective function returned nan.\u001B[0m\n",
      "\u001B[33m[W 2021-12-09 23:21:42,420]\u001B[0m Trial 48 failed, because the objective function returned nan.\u001B[0m\n",
      "\u001B[33m[W 2021-12-09 23:21:52,773]\u001B[0m Trial 49 failed, because the objective function returned nan.\u001B[0m\n",
      "\u001B[33m[W 2021-12-09 23:21:53,163]\u001B[0m Trial 50 failed, because the objective function returned nan.\u001B[0m\n",
      "\u001B[33m[W 2021-12-09 23:21:53,570]\u001B[0m Trial 51 failed, because the objective function returned nan.\u001B[0m\n",
      "\u001B[33m[W 2021-12-09 23:22:54,059]\u001B[0m Trial 52 failed, because the objective function returned nan.\u001B[0m\n",
      "\u001B[33m[W 2021-12-09 23:22:57,770]\u001B[0m Trial 53 failed, because the objective function returned nan.\u001B[0m\n",
      "\u001B[33m[W 2021-12-09 23:22:58,145]\u001B[0m Trial 54 failed, because the objective function returned nan.\u001B[0m\n",
      "\u001B[33m[W 2021-12-09 23:23:13,871]\u001B[0m Trial 55 failed, because the objective function returned nan.\u001B[0m\n",
      "\u001B[33m[W 2021-12-09 23:23:24,428]\u001B[0m Trial 56 failed, because the objective function returned nan.\u001B[0m\n",
      "\u001B[33m[W 2021-12-09 23:23:45,373]\u001B[0m Trial 57 failed, because the objective function returned nan.\u001B[0m\n",
      "\u001B[33m[W 2021-12-09 23:23:54,518]\u001B[0m Trial 58 failed, because the objective function returned nan.\u001B[0m\n",
      "\u001B[33m[W 2021-12-09 23:23:55,003]\u001B[0m Trial 59 failed, because the objective function returned nan.\u001B[0m\n",
      "\u001B[33m[W 2021-12-09 23:24:05,828]\u001B[0m Trial 60 failed, because the objective function returned nan.\u001B[0m\n",
      "\u001B[33m[W 2021-12-09 23:24:11,186]\u001B[0m Trial 61 failed, because the objective function returned nan.\u001B[0m\n",
      "\u001B[33m[W 2021-12-09 23:24:24,630]\u001B[0m Trial 62 failed, because the objective function returned nan.\u001B[0m\n",
      "\u001B[33m[W 2021-12-09 23:24:28,834]\u001B[0m Trial 63 failed, because the objective function returned nan.\u001B[0m\n",
      "\u001B[33m[W 2021-12-09 23:24:29,225]\u001B[0m Trial 64 failed, because the objective function returned nan.\u001B[0m\n",
      "\u001B[33m[W 2021-12-09 23:24:29,615]\u001B[0m Trial 65 failed, because the objective function returned nan.\u001B[0m\n",
      "\u001B[33m[W 2021-12-09 23:24:29,990]\u001B[0m Trial 66 failed, because the objective function returned nan.\u001B[0m\n",
      "\u001B[33m[W 2021-12-09 23:24:34,127]\u001B[0m Trial 67 failed, because the objective function returned nan.\u001B[0m\n",
      "\u001B[33m[W 2021-12-09 23:24:34,533]\u001B[0m Trial 68 failed, because the objective function returned nan.\u001B[0m\n",
      "\u001B[33m[W 2021-12-09 23:24:34,940]\u001B[0m Trial 69 failed, because the objective function returned nan.\u001B[0m\n",
      "\u001B[33m[W 2021-12-09 23:24:48,522]\u001B[0m Trial 70 failed, because the objective function returned nan.\u001B[0m\n",
      "\u001B[33m[W 2021-12-09 23:24:48,913]\u001B[0m Trial 71 failed, because the objective function returned nan.\u001B[0m\n",
      "\u001B[33m[W 2021-12-09 23:24:49,304]\u001B[0m Trial 72 failed, because the objective function returned nan.\u001B[0m\n",
      "\u001B[33m[W 2021-12-09 23:24:49,694]\u001B[0m Trial 73 failed, because the objective function returned nan.\u001B[0m\n",
      "\u001B[33m[W 2021-12-09 23:24:50,085]\u001B[0m Trial 74 failed, because the objective function returned nan.\u001B[0m\n",
      "\u001B[33m[W 2021-12-09 23:24:50,475]\u001B[0m Trial 75 failed, because the objective function returned nan.\u001B[0m\n",
      "\u001B[33m[W 2021-12-09 23:24:52,945]\u001B[0m Trial 76 failed, because the objective function returned nan.\u001B[0m\n",
      "\u001B[33m[W 2021-12-09 23:24:53,335]\u001B[0m Trial 77 failed, because the objective function returned nan.\u001B[0m\n",
      "\u001B[33m[W 2021-12-09 23:24:53,742]\u001B[0m Trial 78 failed, because the objective function returned nan.\u001B[0m\n",
      "\u001B[33m[W 2021-12-09 23:24:54,164]\u001B[0m Trial 79 failed, because the objective function returned nan.\u001B[0m\n",
      "\u001B[33m[W 2021-12-09 23:25:02,786]\u001B[0m Trial 80 failed, because the objective function returned nan.\u001B[0m\n",
      "\u001B[33m[W 2021-12-09 23:25:20,126]\u001B[0m Trial 81 failed, because the objective function returned nan.\u001B[0m\n",
      "\u001B[33m[W 2021-12-09 23:25:20,501]\u001B[0m Trial 82 failed, because the objective function returned nan.\u001B[0m\n",
      "\u001B[33m[W 2021-12-09 23:25:20,891]\u001B[0m Trial 83 failed, because the objective function returned nan.\u001B[0m\n",
      "\u001B[33m[W 2021-12-09 23:25:38,223]\u001B[0m Trial 84 failed, because the objective function returned nan.\u001B[0m\n",
      "\u001B[33m[W 2021-12-09 23:25:38,614]\u001B[0m Trial 85 failed, because the objective function returned nan.\u001B[0m\n",
      "\u001B[33m[W 2021-12-09 23:25:39,036]\u001B[0m Trial 86 failed, because the objective function returned nan.\u001B[0m\n",
      "\u001B[33m[W 2021-12-09 23:25:44,152]\u001B[0m Trial 87 failed, because the objective function returned nan.\u001B[0m\n",
      "\u001B[33m[W 2021-12-09 23:25:44,543]\u001B[0m Trial 88 failed, because the objective function returned nan.\u001B[0m\n",
      "\u001B[33m[W 2021-12-09 23:25:44,933]\u001B[0m Trial 89 failed, because the objective function returned nan.\u001B[0m\n",
      "\u001B[33m[W 2021-12-09 23:25:45,425]\u001B[0m Trial 90 failed, because the objective function returned nan.\u001B[0m\n",
      "\u001B[33m[W 2021-12-09 23:26:17,488]\u001B[0m Trial 91 failed, because the objective function returned nan.\u001B[0m\n",
      "\u001B[33m[W 2021-12-09 23:26:26,417]\u001B[0m Trial 92 failed, because the objective function returned nan.\u001B[0m\n",
      "\u001B[33m[W 2021-12-09 23:26:26,808]\u001B[0m Trial 93 failed, because the objective function returned nan.\u001B[0m\n",
      "\u001B[33m[W 2021-12-09 23:26:27,198]\u001B[0m Trial 94 failed, because the objective function returned nan.\u001B[0m\n",
      "\u001B[33m[W 2021-12-09 23:26:38,048]\u001B[0m Trial 95 failed, because the objective function returned nan.\u001B[0m\n",
      "\u001B[33m[W 2021-12-09 23:26:38,439]\u001B[0m Trial 96 failed, because the objective function returned nan.\u001B[0m\n",
      "\u001B[33m[W 2021-12-09 23:26:38,830]\u001B[0m Trial 97 failed, because the objective function returned nan.\u001B[0m\n",
      "\u001B[33m[W 2021-12-09 23:26:39,236]\u001B[0m Trial 98 failed, because the objective function returned nan.\u001B[0m\n",
      "\u001B[33m[W 2021-12-09 23:27:04,259]\u001B[0m Trial 99 failed, because the objective function returned nan.\u001B[0m\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "print('Five best values')\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "study.trials_dataframe().sort_values('value', ascending=True).head(5)"
   ],
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Five best values\n"
     ]
    },
    {
     "data": {
      "text/plain": "    number  value             datetime_start          datetime_complete  \\\n10      10   0.92 2021-12-09 23:17:27.665201 2021-12-09 23:17:37.022554   \n9        9   0.92 2021-12-09 23:17:19.320343 2021-12-09 23:17:27.663196   \n30      30   0.92 2021-12-09 23:20:04.466760 2021-12-09 23:20:14.406157   \n25      25   0.92 2021-12-09 23:19:40.595996 2021-12-09 23:19:50.111601   \n17      17   0.92 2021-12-09 23:18:19.736725 2021-12-09 23:18:26.417593   \n\n                 duration  params_bagging_temperature  params_border_count  \\\n10 0 days 00:00:09.357353                         NaN                  NaN   \n9  0 days 00:00:08.342853                         NaN                  NaN   \n30 0 days 00:00:09.939397                         NaN                  NaN   \n25 0 days 00:00:09.515605                         NaN                  NaN   \n17 0 days 00:00:06.680868                         NaN                  NaN   \n\n   params_classifier  params_colsample_bytree  params_depth  ...  \\\n10           xgboost                     0.57           NaN  ...   \n9            xgboost                     0.62           NaN  ...   \n30           xgboost                     0.43           NaN  ...   \n25           xgboost                     0.43           NaN  ...   \n17           xgboost                     0.39           NaN  ...   \n\n    params_max_ctr_complexity  params_max_depth  params_min_child_samples  \\\n10                        NaN              7.00                       NaN   \n9                         NaN              5.00                       NaN   \n30                        NaN              8.00                       NaN   \n25                        NaN             10.00                       NaN   \n17                        NaN              6.00                       NaN   \n\n    params_min_child_weight  params_num_leaves  params_random_strength  \\\n10                    19.00                NaN                     NaN   \n9                     15.00                NaN                     NaN   \n30                    18.00                NaN                     NaN   \n25                    20.00                NaN                     NaN   \n17                    20.00                NaN                     NaN   \n\n    params_reg_alpha  params_reg_lambda  params_subsample     state  \n10               NaN                NaN              0.97  COMPLETE  \n9                NaN                NaN              0.51  COMPLETE  \n30               NaN                NaN              0.86  COMPLETE  \n25               NaN                NaN              0.63  COMPLETE  \n17               NaN                NaN              0.69  COMPLETE  \n\n[5 rows x 24 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>number</th>\n      <th>value</th>\n      <th>datetime_start</th>\n      <th>datetime_complete</th>\n      <th>duration</th>\n      <th>params_bagging_temperature</th>\n      <th>params_border_count</th>\n      <th>params_classifier</th>\n      <th>params_colsample_bytree</th>\n      <th>params_depth</th>\n      <th>...</th>\n      <th>params_max_ctr_complexity</th>\n      <th>params_max_depth</th>\n      <th>params_min_child_samples</th>\n      <th>params_min_child_weight</th>\n      <th>params_num_leaves</th>\n      <th>params_random_strength</th>\n      <th>params_reg_alpha</th>\n      <th>params_reg_lambda</th>\n      <th>params_subsample</th>\n      <th>state</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>10</th>\n      <td>10</td>\n      <td>0.92</td>\n      <td>2021-12-09 23:17:27.665201</td>\n      <td>2021-12-09 23:17:37.022554</td>\n      <td>0 days 00:00:09.357353</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>xgboost</td>\n      <td>0.57</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>7.00</td>\n      <td>NaN</td>\n      <td>19.00</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.97</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>9</td>\n      <td>0.92</td>\n      <td>2021-12-09 23:17:19.320343</td>\n      <td>2021-12-09 23:17:27.663196</td>\n      <td>0 days 00:00:08.342853</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>xgboost</td>\n      <td>0.62</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>5.00</td>\n      <td>NaN</td>\n      <td>15.00</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.51</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>30</td>\n      <td>0.92</td>\n      <td>2021-12-09 23:20:04.466760</td>\n      <td>2021-12-09 23:20:14.406157</td>\n      <td>0 days 00:00:09.939397</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>xgboost</td>\n      <td>0.43</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>8.00</td>\n      <td>NaN</td>\n      <td>18.00</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.86</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>25</td>\n      <td>0.92</td>\n      <td>2021-12-09 23:19:40.595996</td>\n      <td>2021-12-09 23:19:50.111601</td>\n      <td>0 days 00:00:09.515605</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>xgboost</td>\n      <td>0.43</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>10.00</td>\n      <td>NaN</td>\n      <td>20.00</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.63</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>17</td>\n      <td>0.92</td>\n      <td>2021-12-09 23:18:19.736725</td>\n      <td>2021-12-09 23:18:26.417593</td>\n      <td>0 days 00:00:06.680868</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>xgboost</td>\n      <td>0.39</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>6.00</td>\n      <td>NaN</td>\n      <td>20.00</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.69</td>\n      <td>COMPLETE</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 24 columns</p>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "trial = study.best_trial\n",
    "print(f'Loss : {trial}')\n",
    "print(f\"Best hyperparameters: {trial.params}\")"
   ],
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss : FrozenTrial(number=16, values=[0.9237318161819783], datetime_start=datetime.datetime(2021, 12, 9, 23, 18, 15, 35271), datetime_complete=datetime.datetime(2021, 12, 9, 23, 18, 19, 735724), params={'classifier': 'xgboost', 'min_child_weight': 18, 'gamma': 0, 'max_depth': 8, 'subsample': 0.5993495781209559, 'colsample_bytree': 0.11631754891289292}, distributions={'classifier': CategoricalDistribution(choices=('lightgbm', 'catboost', 'xgboost')), 'min_child_weight': IntUniformDistribution(high=20, low=14, step=1), 'gamma': IntUniformDistribution(high=5, low=0, step=1), 'max_depth': IntUniformDistribution(high=10, low=5, step=1), 'subsample': UniformDistribution(high=1.0, low=0.5), 'colsample_bytree': UniformDistribution(high=1.0, low=0.1)}, user_attrs={}, system_attrs={}, intermediate_values={}, trial_id=16, state=TrialState.COMPLETE, value=None)\n",
      "Best hyperparameters: {'classifier': 'xgboost', 'min_child_weight': 18, 'gamma': 0, 'max_depth': 8, 'subsample': 0.5993495781209559, 'colsample_bytree': 0.11631754891289292}\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# plot the optimization history of the study\n",
    "from optuna.visualization.matplotlib import plot_optimization_history\n",
    "\n",
    "plot_optimization_history(study);"
   ],
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "study.best_params"
   ],
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "{'classifier': 'xgboost',\n 'min_child_weight': 18,\n 'gamma': 0,\n 'max_depth': 8,\n 'subsample': 0.5993495781209559,\n 'colsample_bytree': 0.11631754891289292}"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "best_params = {key: value for key, value in study.best_params.items() if key != 'classifier'}\n",
    "if study.best_params['classifier'] == 'lightgbm':\n",
    "    best_model = LGBMClassifier(**best_params)\n",
    "elif study.best_params['classifier'] == 'catboost':\n",
    "    best_model = CatBoostClassifier(**best_params)\n",
    "else:\n",
    "    best_model = XGBClassifier(**best_params)\n",
    "best_model.fit(X_train, y_train)"
   ],
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:30:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n              colsample_bynode=1, colsample_bytree=0.11631754891289292,\n              enable_categorical=False, gamma=0, gpu_id=-1,\n              importance_type=None, interaction_constraints='',\n              learning_rate=0.300000012, max_delta_step=0, max_depth=8,\n              min_child_weight=18, missing=nan, monotone_constraints='()',\n              n_estimators=100, n_jobs=4, num_parallel_tree=1, predictor='auto',\n              random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n              subsample=0.5993495781209559, tree_method='exact',\n              validate_parameters=1, verbosity=None)"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "y_pred = best_model.predict(X_test)\n",
    "y_pred = pd.DataFrame(data=y_pred, columns=['credit_card_default'])\n",
    "y_pred.index = X_test.index\n",
    "y_pred['credit_card_default'] = np.where(y_pred['credit_card_default'] == True, 1, 0)"
   ],
   "execution_count": 29,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "y_pred.to_csv('Predicted value from Optuna.csv', index=True)"
   ],
   "execution_count": 30,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}