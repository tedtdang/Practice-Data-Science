{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "df = pd.read_csv('NBA players.csv', index_col='Player_ID')\n",
    "df.drop(columns = ['Player.x', 'Tm', 'Pos2', 'Season', 'Conference'], inplace=True)\n",
    "df = df[df['Salary'].notna()]\n",
    "X = df.drop(columns='Salary')\n",
    "y = df.Salary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select categorical and continuous columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = X._get_numeric_data().columns\n",
    "categorical_features = list(set(X.columns) - set(numeric_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a pipeline of both Continuous and Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from fancyimpute import IterativeImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "mice_imputer = IterativeImputer()\n",
    "simple_imputer = SimpleImputer(strategy='constant', fill_value='missing')\n",
    "scaler = StandardScaler()\n",
    "ohc = OneHotEncoder(handle_unknown='ignore')\n",
    "le = LabelEncoder()\n",
    "\n",
    "X[numeric_features] = mice_imputer.fit_transform(X[numeric_features])\n",
    "X[numeric_features] = scaler.fit_transform(X[numeric_features])\n",
    "X[categorical_features] = simple_imputer.fit_transform(X[categorical_features])\n",
    "for feature in categorical_features:\n",
    "    X[feature] = le.fit_transform(X[feature])\n",
    "    \n",
    "# # Scale numeric values\n",
    "# num_transformer = Pipeline(steps=[\n",
    "#     ('mice imputer', mice_imputer),\n",
    "#     ('standard_scaler', scaler)])\n",
    "\n",
    "# # One-hot encode categorical values\n",
    "# cat_transformer = Pipeline(steps=[\n",
    "#     ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "#     ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "# # Combine numeric and categorical imputers\n",
    "# preprocessor = ColumnTransformer(\n",
    "#     transformers=[\n",
    "#         ('num', num_transformer, numeric_features),\n",
    "#         ('cat', cat_transformer, categorical_features)])\n",
    "# X = preprocessor.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split into train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use GridSearch to look for the best parameters for XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "gbm = XGBRegressor()\n",
    "parameters = {'min_child_weight':[4,5], 'gamma':[i/10.0 for i in range(3,6)],  'subsample':[i/10.0 for i in range(6,11)],\n",
    "'colsample_bytree':[i/10.0 for i in range(6,11)], 'max_depth': [2,3,4]}\n",
    "\n",
    "xgb_grid = GridSearchCV(gbm,\n",
    "                        parameters,\n",
    "                        cv = 2,\n",
    "                        n_jobs = 5,\n",
    "                        verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 450 candidates, totalling 900 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done  70 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=5)]: Done 370 tasks      | elapsed:   11.4s\n",
      "[Parallel(n_jobs=5)]: Done 870 tasks      | elapsed:   29.1s\n",
      "[Parallel(n_jobs=5)]: Done 900 out of 900 | elapsed:   30.4s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2,\n",
       "             estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                    colsample_bylevel=None,\n",
       "                                    colsample_bynode=None,\n",
       "                                    colsample_bytree=None, gamma=None,\n",
       "                                    gpu_id=None, importance_type='gain',\n",
       "                                    interaction_constraints=None,\n",
       "                                    learning_rate=None, max_delta_step=None,\n",
       "                                    max_depth=None, min_child_weight=None,\n",
       "                                    missing=nan, monotone_constraints=None,\n",
       "                                    n_estimators=100, n_jobs=None,\n",
       "                                    num_parallel_tree=None, random_state=None,\n",
       "                                    reg_alpha=None, reg_lambda=None,\n",
       "                                    scale_pos_weight=None, subsample=None,\n",
       "                                    tree_method=None, validate_parameters=None,\n",
       "                                    verbosity=None),\n",
       "             n_jobs=5,\n",
       "             param_grid={'colsample_bytree': [0.6, 0.7, 0.8, 0.9, 1.0],\n",
       "                         'gamma': [0.3, 0.4, 0.5], 'max_depth': [2, 3, 4],\n",
       "                         'min_child_weight': [4, 5],\n",
       "                         'subsample': [0.6, 0.7, 0.8, 0.9, 1.0]},\n",
       "             verbose=True)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'colsample_bytree': 1.0, 'gamma': 0.3, 'max_depth': 2, 'min_child_weight': 5, 'subsample': 1.0}\n"
     ]
    }
   ],
   "source": [
    "print(xgb_grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print the best score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5855530923136254\n"
     ]
    }
   ],
   "source": [
    "print(xgb_grid.best_score_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
