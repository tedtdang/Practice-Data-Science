{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data sets were acquired from https://www.kaggle.com/c/titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sidetable\n",
    "import numpy as np\n",
    "import sidetable\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "df_train = pd.read_csv('train.csv', index_col=['PassengerId'])\n",
    "df_test = pd.read_csv('test.csv', index_col=['PassengerId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Survived  Pclass  \\\n",
       "PassengerId                     \n",
       "1                   0       3   \n",
       "2                   1       1   \n",
       "3                   1       3   \n",
       "4                   1       1   \n",
       "5                   0       3   \n",
       "\n",
       "                                                          Name     Sex   Age  \\\n",
       "PassengerId                                                                    \n",
       "1                                      Braund, Mr. Owen Harris    male  22.0   \n",
       "2            Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0   \n",
       "3                                       Heikkinen, Miss. Laina  female  26.0   \n",
       "4                 Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0   \n",
       "5                                     Allen, Mr. William Henry    male  35.0   \n",
       "\n",
       "             SibSp  Parch            Ticket     Fare Cabin Embarked  \n",
       "PassengerId                                                          \n",
       "1                1      0         A/5 21171   7.2500   NaN        S  \n",
       "2                1      0          PC 17599  71.2833   C85        C  \n",
       "3                0      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "4                1      0            113803  53.1000  C123        S  \n",
       "5                0      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Have a look at the first five rows\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_88ac6_\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >missing</th>        <th class=\"col_heading level0 col1\" >total</th>        <th class=\"col_heading level0 col2\" >percent</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_88ac6_level0_row0\" class=\"row_heading level0 row0\" >Age</th>\n",
       "                        <td id=\"T_88ac6_row0_col0\" class=\"data row0 col0\" >177</td>\n",
       "                        <td id=\"T_88ac6_row0_col1\" class=\"data row0 col1\" >891</td>\n",
       "                        <td id=\"T_88ac6_row0_col2\" class=\"data row0 col2\" >19.87%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_88ac6_level0_row1\" class=\"row_heading level0 row1\" >Embarked</th>\n",
       "                        <td id=\"T_88ac6_row1_col0\" class=\"data row1 col0\" >2</td>\n",
       "                        <td id=\"T_88ac6_row1_col1\" class=\"data row1 col1\" >891</td>\n",
       "                        <td id=\"T_88ac6_row1_col2\" class=\"data row1 col2\" >0.22%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_88ac6_level0_row2\" class=\"row_heading level0 row2\" >Survived</th>\n",
       "                        <td id=\"T_88ac6_row2_col0\" class=\"data row2 col0\" >0</td>\n",
       "                        <td id=\"T_88ac6_row2_col1\" class=\"data row2 col1\" >891</td>\n",
       "                        <td id=\"T_88ac6_row2_col2\" class=\"data row2 col2\" >0.00%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_88ac6_level0_row3\" class=\"row_heading level0 row3\" >Pclass</th>\n",
       "                        <td id=\"T_88ac6_row3_col0\" class=\"data row3 col0\" >0</td>\n",
       "                        <td id=\"T_88ac6_row3_col1\" class=\"data row3 col1\" >891</td>\n",
       "                        <td id=\"T_88ac6_row3_col2\" class=\"data row3 col2\" >0.00%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_88ac6_level0_row4\" class=\"row_heading level0 row4\" >Sex</th>\n",
       "                        <td id=\"T_88ac6_row4_col0\" class=\"data row4 col0\" >0</td>\n",
       "                        <td id=\"T_88ac6_row4_col1\" class=\"data row4 col1\" >891</td>\n",
       "                        <td id=\"T_88ac6_row4_col2\" class=\"data row4 col2\" >0.00%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_88ac6_level0_row5\" class=\"row_heading level0 row5\" >SibSp</th>\n",
       "                        <td id=\"T_88ac6_row5_col0\" class=\"data row5 col0\" >0</td>\n",
       "                        <td id=\"T_88ac6_row5_col1\" class=\"data row5 col1\" >891</td>\n",
       "                        <td id=\"T_88ac6_row5_col2\" class=\"data row5 col2\" >0.00%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_88ac6_level0_row6\" class=\"row_heading level0 row6\" >Parch</th>\n",
       "                        <td id=\"T_88ac6_row6_col0\" class=\"data row6 col0\" >0</td>\n",
       "                        <td id=\"T_88ac6_row6_col1\" class=\"data row6 col1\" >891</td>\n",
       "                        <td id=\"T_88ac6_row6_col2\" class=\"data row6 col2\" >0.00%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_88ac6_level0_row7\" class=\"row_heading level0 row7\" >Fare</th>\n",
       "                        <td id=\"T_88ac6_row7_col0\" class=\"data row7 col0\" >0</td>\n",
       "                        <td id=\"T_88ac6_row7_col1\" class=\"data row7 col1\" >891</td>\n",
       "                        <td id=\"T_88ac6_row7_col2\" class=\"data row7 col2\" >0.00%</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1e7e126df48>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.stb.missing(style=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 11)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_irrelevant(df):\n",
    "    return df.drop(columns=['Name', 'Ticket', 'Cabin'])\n",
    "df_train = drop_irrelevant(df_train)\n",
    "X_test = drop_irrelevant(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get X_train and y_train\n",
    "y = df_train.Survived.copy()\n",
    "X = df_train.drop(columns='Survived').copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrive num_cols and cat_cols\n",
    "num_cols = list(X._get_numeric_data().columns)\n",
    "cat_cols = list(set(X.columns) - set(num_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import make_column_transformer, make_column_selector\n",
    "\n",
    "cat_pipe = make_pipeline(\n",
    "            (SimpleImputer(strategy='most_frequent')),\n",
    "            (OneHotEncoder(drop='first', handle_unknown='error'))\n",
    "            )\n",
    "num_pipe = make_pipeline(\n",
    "            (IterativeImputer()),\n",
    "            (StandardScaler())\n",
    "            )            \n",
    "preprocess_pipeline = make_column_transformer(\n",
    "            (cat_pipe, cat_cols),\n",
    "            (num_pipe, num_cols)\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor =  preprocess_pipeline.fit(X)\n",
    "X = preprocessor.transform(X)\n",
    "X_test = preprocessor.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first 5 features are selected: Index(['Sex', 'Age', 'SibSp', 'Embarked'], dtype='object')\n",
      "check ranking of features [5 4 1 1 1 2 3 1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from boruta import BorutaPy\n",
    "\n",
    "# define random forest classifier, with utilising all cores and\n",
    "# sampling in proportion to y labels\n",
    "rf = RandomForestClassifier(n_jobs=-1, class_weight='balanced', max_depth=5)\n",
    "\n",
    "# define Boruta feature selection method\n",
    "feat_selector = BorutaPy(rf, n_estimators='auto', verbose=0, random_state=1)\n",
    "\n",
    "# find all relevant features - 5 features should be selected\n",
    "feat_selector.fit(X, y)\n",
    "\n",
    "# check selected features - first 5 features are selected\n",
    "print(f'first 5 features are selected: {df_train.columns[feat_selector.support_]}')\n",
    "\n",
    "# check ranking of features\n",
    "print(f'check ranking of features {feat_selector.ranking_}')\n",
    "\n",
    "# call transform() on X to filter it down to selected features\n",
    "X = feat_selector.transform(X)\n",
    "X_test = feat_selector.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.15, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Oracle from existing project .\\untitled_project\\oracle.json\n",
      "INFO:tensorflow:Reloading Tuner from .\\untitled_project\\tuner0.json\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Credit source: \n",
    "    https://www.tensorflow.org/tutorials/keras/keras_tuner\n",
    "    https://github.com/keras-team/keras-tuner/blob/master/examples/cifar10.py\n",
    "'''\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Activation, Dense, Flatten, BatchNormalization, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Create the keras tuner model.\n",
    "def build_model(hp):\n",
    "    hp_drop_out = hp.Float('dropout', 0, 0.5, step=0.1)\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "    model = Sequential()\n",
    "    for i in range(hp.Int('num_layers', 2, 20)):\n",
    "        model.add(Dense(units=hp.Int('units_' + str(i), min_value=32, max_value=512, step=32), activation='relu'))\n",
    "#         model.add(BatchNormalization())\n",
    "        model.add(Dropout(hp_drop_out))\n",
    "#     model.add(Flatten())\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    opt = Adam(learning_rate=hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4]))\n",
    "    model.compile(optimizer=Adam(learning_rate=hp_learning_rate),\n",
    "                loss='binary_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "import kerastuner as kt\n",
    "\n",
    "tuner = kt.Hyperband(build_model,\n",
    "                     objective='val_accuracy', \n",
    "                     max_epochs=16,\n",
    "                     overwrite=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "es = EarlyStopping(monitor='val_accuracy', verbose=0, patience=10, min_delta=1e-3)\n",
    "tuner.search(X_train, y_train, epochs=64, batch_size=32, validation_data=(X_val, y_val), callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/64\n",
      "24/24 [==============================] - 2s 35ms/step - loss: 0.6464 - accuracy: 0.6289 - val_loss: 0.5463 - val_accuracy: 0.7612\n",
      "Epoch 2/64\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.4589 - accuracy: 0.8095 - val_loss: 0.5072 - val_accuracy: 0.7761\n",
      "Epoch 3/64\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.4647 - accuracy: 0.8023 - val_loss: 0.4598 - val_accuracy: 0.7910\n",
      "Epoch 4/64\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.4444 - accuracy: 0.8308 - val_loss: 0.4705 - val_accuracy: 0.7910\n",
      "Epoch 5/64\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.4650 - accuracy: 0.8126 - val_loss: 0.5124 - val_accuracy: 0.7985\n",
      "Epoch 6/64\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.4352 - accuracy: 0.8128 - val_loss: 0.4623 - val_accuracy: 0.7985\n",
      "Epoch 7/64\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.4362 - accuracy: 0.8135 - val_loss: 0.4599 - val_accuracy: 0.7836\n",
      "Epoch 8/64\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.4473 - accuracy: 0.8248 - val_loss: 0.4686 - val_accuracy: 0.8060\n",
      "Epoch 9/64\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.4279 - accuracy: 0.8224 - val_loss: 0.4500 - val_accuracy: 0.7910\n",
      "Epoch 10/64\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.3677 - accuracy: 0.8589 - val_loss: 0.4718 - val_accuracy: 0.8060\n",
      "Epoch 11/64\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.4350 - accuracy: 0.7897 - val_loss: 0.4838 - val_accuracy: 0.7836\n",
      "Epoch 12/64\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.3950 - accuracy: 0.8421 - val_loss: 0.4568 - val_accuracy: 0.7910\n",
      "Epoch 13/64\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.4137 - accuracy: 0.8246 - val_loss: 0.4526 - val_accuracy: 0.7910\n",
      "Epoch 14/64\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.4171 - accuracy: 0.8244 - val_loss: 0.4642 - val_accuracy: 0.7836\n",
      "Epoch 15/64\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.4059 - accuracy: 0.8484 - val_loss: 0.4482 - val_accuracy: 0.7985\n",
      "Epoch 16/64\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.3990 - accuracy: 0.8359 - val_loss: 0.4603 - val_accuracy: 0.8134\n",
      "Epoch 17/64\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.3501 - accuracy: 0.8487 - val_loss: 0.4560 - val_accuracy: 0.7985\n",
      "Epoch 18/64\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.3978 - accuracy: 0.8461 - val_loss: 0.4352 - val_accuracy: 0.8209\n",
      "Epoch 19/64\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.3860 - accuracy: 0.8417 - val_loss: 0.4759 - val_accuracy: 0.8134\n",
      "Epoch 20/64\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.4119 - accuracy: 0.8372 - val_loss: 0.4747 - val_accuracy: 0.8060\n",
      "Epoch 21/64\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.4168 - accuracy: 0.8284 - val_loss: 0.4854 - val_accuracy: 0.7985\n",
      "Epoch 22/64\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.3894 - accuracy: 0.8330 - val_loss: 0.4834 - val_accuracy: 0.7985\n",
      "Epoch 23/64\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.4046 - accuracy: 0.8367 - val_loss: 0.5059 - val_accuracy: 0.7836\n",
      "Epoch 24/64\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.3716 - accuracy: 0.8399 - val_loss: 0.4542 - val_accuracy: 0.8060\n",
      "Epoch 25/64\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.3610 - accuracy: 0.8523 - val_loss: 0.4689 - val_accuracy: 0.8060\n",
      "Epoch 26/64\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.3748 - accuracy: 0.8390 - val_loss: 0.4543 - val_accuracy: 0.8060\n",
      "Epoch 27/64\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.3701 - accuracy: 0.8602 - val_loss: 0.4856 - val_accuracy: 0.7910\n",
      "Epoch 28/64\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.3863 - accuracy: 0.8393 - val_loss: 0.4706 - val_accuracy: 0.7985\n",
      "Epoch 29/64\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.3861 - accuracy: 0.8310 - val_loss: 0.4768 - val_accuracy: 0.7836\n",
      "Epoch 30/64\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.3729 - accuracy: 0.8481 - val_loss: 0.4833 - val_accuracy: 0.8209\n",
      "Epoch 31/64\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.4013 - accuracy: 0.8246 - val_loss: 0.4415 - val_accuracy: 0.8134\n",
      "Epoch 32/64\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.4043 - accuracy: 0.8385 - val_loss: 0.4702 - val_accuracy: 0.7761\n",
      "Epoch 33/64\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.4014 - accuracy: 0.8378 - val_loss: 0.4709 - val_accuracy: 0.8060\n",
      "Epoch 34/64\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.3822 - accuracy: 0.8496 - val_loss: 0.5567 - val_accuracy: 0.8209\n",
      "Epoch 35/64\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.4405 - accuracy: 0.8057 - val_loss: 0.4391 - val_accuracy: 0.8060\n",
      "Epoch 36/64\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.3904 - accuracy: 0.8213 - val_loss: 0.4560 - val_accuracy: 0.8358\n",
      "Epoch 37/64\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.3639 - accuracy: 0.8522 - val_loss: 0.4828 - val_accuracy: 0.8060\n",
      "Epoch 38/64\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.3823 - accuracy: 0.8318 - val_loss: 0.4864 - val_accuracy: 0.8284\n",
      "Epoch 39/64\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.3515 - accuracy: 0.8725 - val_loss: 0.4677 - val_accuracy: 0.7985\n",
      "Epoch 40/64\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.3734 - accuracy: 0.8326 - val_loss: 0.4558 - val_accuracy: 0.8284\n",
      "Epoch 41/64\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.3817 - accuracy: 0.8488 - val_loss: 0.4705 - val_accuracy: 0.8358\n",
      "Epoch 42/64\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.3722 - accuracy: 0.8339 - val_loss: 0.5409 - val_accuracy: 0.8209\n",
      "Epoch 43/64\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.3720 - accuracy: 0.8508 - val_loss: 0.5106 - val_accuracy: 0.8358\n",
      "Epoch 44/64\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.3795 - accuracy: 0.8305 - val_loss: 0.4930 - val_accuracy: 0.8209\n",
      "Epoch 45/64\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.3795 - accuracy: 0.8499 - val_loss: 0.5030 - val_accuracy: 0.8209\n",
      "Epoch 46/64\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.3460 - accuracy: 0.8647 - val_loss: 0.4690 - val_accuracy: 0.8284\n",
      "Epoch 47/64\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.3563 - accuracy: 0.8558 - val_loss: 0.4573 - val_accuracy: 0.8209\n",
      "Epoch 48/64\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.3737 - accuracy: 0.8468 - val_loss: 0.4864 - val_accuracy: 0.8209\n",
      "Epoch 49/64\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.3545 - accuracy: 0.8456 - val_loss: 0.4729 - val_accuracy: 0.8209\n",
      "Epoch 50/64\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.3847 - accuracy: 0.8299 - val_loss: 0.5365 - val_accuracy: 0.7761\n",
      "Epoch 51/64\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.3544 - accuracy: 0.8576 - val_loss: 0.5069 - val_accuracy: 0.8284\n",
      "Epoch 52/64\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.3626 - accuracy: 0.8582 - val_loss: 0.4972 - val_accuracy: 0.7985\n",
      "Epoch 53/64\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.3735 - accuracy: 0.8370 - val_loss: 0.4889 - val_accuracy: 0.8209\n",
      "Epoch 54/64\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.3914 - accuracy: 0.8362 - val_loss: 0.4680 - val_accuracy: 0.8134\n",
      "Epoch 55/64\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.3541 - accuracy: 0.8491 - val_loss: 0.4540 - val_accuracy: 0.8209\n",
      "Epoch 56/64\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.3656 - accuracy: 0.8504 - val_loss: 0.4417 - val_accuracy: 0.8209\n",
      "Epoch 57/64\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.3439 - accuracy: 0.8579 - val_loss: 0.4845 - val_accuracy: 0.8284\n",
      "Epoch 58/64\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.3674 - accuracy: 0.8456 - val_loss: 0.5001 - val_accuracy: 0.8060\n",
      "Epoch 59/64\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.3468 - accuracy: 0.8585 - val_loss: 0.4650 - val_accuracy: 0.8134\n",
      "Epoch 60/64\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.3674 - accuracy: 0.8388 - val_loss: 0.5617 - val_accuracy: 0.8209\n",
      "Epoch 61/64\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.3638 - accuracy: 0.8465 - val_loss: 0.4996 - val_accuracy: 0.8134\n",
      "Epoch 62/64\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.3304 - accuracy: 0.8696 - val_loss: 0.5477 - val_accuracy: 0.8060\n",
      "Epoch 63/64\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.3824 - accuracy: 0.8336 - val_loss: 0.5576 - val_accuracy: 0.8060\n",
      "Epoch 64/64\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.3434 - accuracy: 0.8569 - val_loss: 0.5358 - val_accuracy: 0.8209\n"
     ]
    }
   ],
   "source": [
    "# Get the optimal hyperparameters\n",
    "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "model = tuner.hypermodel.build(best_hps)\n",
    "history = model.fit(X_train, y_train, epochs=64, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best epoch: 36\n"
     ]
    }
   ],
   "source": [
    "val_acc_per_epoch = history.history['val_accuracy']\n",
    "best_epoch = val_acc_per_epoch.index(max(val_acc_per_epoch)) + 1\n",
    "print('Best epoch: %d' % (best_epoch,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/36\n",
      "24/24 [==============================] - 2s 8ms/step - loss: 0.6350 - accuracy: 0.6165\n",
      "Epoch 2/36\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.5094 - accuracy: 0.7818\n",
      "Epoch 3/36\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.5771 - accuracy: 0.7592\n",
      "Epoch 4/36\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.4491 - accuracy: 0.8054\n",
      "Epoch 5/36\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.4419 - accuracy: 0.8165\n",
      "Epoch 6/36\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.4694 - accuracy: 0.7942\n",
      "Epoch 7/36\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.3978 - accuracy: 0.8529\n",
      "Epoch 8/36\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.4342 - accuracy: 0.8129\n",
      "Epoch 9/36\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.4018 - accuracy: 0.8351\n",
      "Epoch 10/36\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.4228 - accuracy: 0.8249\n",
      "Epoch 11/36\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.3973 - accuracy: 0.8365\n",
      "Epoch 12/36\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.3870 - accuracy: 0.8507\n",
      "Epoch 13/36\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.4090 - accuracy: 0.8508\n",
      "Epoch 14/36\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.3922 - accuracy: 0.8319\n",
      "Epoch 15/36\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.3630 - accuracy: 0.8572\n",
      "Epoch 16/36\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.4320 - accuracy: 0.8211\n",
      "Epoch 17/36\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.4457 - accuracy: 0.8186\n",
      "Epoch 18/36\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.4053 - accuracy: 0.8382\n",
      "Epoch 19/36\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.3938 - accuracy: 0.8433\n",
      "Epoch 20/36\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.4111 - accuracy: 0.8320\n",
      "Epoch 21/36\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.4149 - accuracy: 0.8246\n",
      "Epoch 22/36\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.4022 - accuracy: 0.8219\n",
      "Epoch 23/36\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.4181 - accuracy: 0.8311\n",
      "Epoch 24/36\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.3933 - accuracy: 0.8399\n",
      "Epoch 25/36\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.3903 - accuracy: 0.8309\n",
      "Epoch 26/36\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.4504 - accuracy: 0.7994\n",
      "Epoch 27/36\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.3712 - accuracy: 0.8431\n",
      "Epoch 28/36\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.3712 - accuracy: 0.8732\n",
      "Epoch 29/36\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.4007 - accuracy: 0.8334\n",
      "Epoch 30/36\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.3570 - accuracy: 0.8480\n",
      "Epoch 31/36\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.3863 - accuracy: 0.8434\n",
      "Epoch 32/36\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.4475 - accuracy: 0.8153\n",
      "Epoch 33/36\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.4068 - accuracy: 0.8170\n",
      "Epoch 34/36\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.3949 - accuracy: 0.8423\n",
      "Epoch 35/36\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.3641 - accuracy: 0.8548\n",
      "Epoch 36/36\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.3611 - accuracy: 0.8416\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1e7dac00748>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Re-instantiate the hypermodel and train it with the optimal number of epochs from above.\n",
    "hypermodel = tuner.hypermodel.build(best_hps)\n",
    "# Retrain the model\n",
    "hypermodel.fit(X_train, y_train, epochs=best_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5271 - accuracy: 0.8060\n",
      "[test loss, test accuracy]: [0.5270797610282898, 0.8059701323509216]\n"
     ]
    }
   ],
   "source": [
    "eval_result = hypermodel.evaluate(X_val, y_val)\n",
    "print(\"[test loss, test accuracy]:\", eval_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/36\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 0.4019 - accuracy: 0.8283\n",
      "Epoch 2/36\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.3847 - accuracy: 0.8373\n",
      "Epoch 3/36\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.3891 - accuracy: 0.8395\n",
      "Epoch 4/36\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 0.4206 - accuracy: 0.8159\n",
      "Epoch 5/36\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 0.4103 - accuracy: 0.8137\n",
      "Epoch 6/36\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.4017 - accuracy: 0.8294\n",
      "Epoch 7/36\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 0.3905 - accuracy: 0.8384\n",
      "Epoch 8/36\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 0.3827 - accuracy: 0.8440\n",
      "Epoch 9/36\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.3892 - accuracy: 0.8260\n",
      "Epoch 10/36\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 0.4140 - accuracy: 0.8126\n",
      "Epoch 11/36\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.4041 - accuracy: 0.8272\n",
      "Epoch 12/36\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.3918 - accuracy: 0.8148\n",
      "Epoch 13/36\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 0.3984 - accuracy: 0.8272\n",
      "Epoch 14/36\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.3898 - accuracy: 0.8305\n",
      "Epoch 15/36\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 0.3906 - accuracy: 0.8339\n",
      "Epoch 16/36\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 0.3851 - accuracy: 0.8316\n",
      "Epoch 17/36\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 0.3964 - accuracy: 0.8328\n",
      "Epoch 18/36\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.3685 - accuracy: 0.8519\n",
      "Epoch 19/36\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.3842 - accuracy: 0.8474\n",
      "Epoch 20/36\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 0.3723 - accuracy: 0.8384\n",
      "Epoch 21/36\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.3985 - accuracy: 0.8395\n",
      "Epoch 22/36\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 0.3849 - accuracy: 0.8339\n",
      "Epoch 23/36\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 0.3835 - accuracy: 0.8294\n",
      "Epoch 24/36\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.3792 - accuracy: 0.8485\n",
      "Epoch 25/36\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 0.3784 - accuracy: 0.8373\n",
      "Epoch 26/36\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 0.3672 - accuracy: 0.8361\n",
      "Epoch 27/36\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 0.3595 - accuracy: 0.8418\n",
      "Epoch 28/36\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 0.3839 - accuracy: 0.8429\n",
      "Epoch 29/36\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.3877 - accuracy: 0.8373\n",
      "Epoch 30/36\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 0.3722 - accuracy: 0.8429\n",
      "Epoch 31/36\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.3585 - accuracy: 0.8485\n",
      "Epoch 32/36\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 0.3645 - accuracy: 0.8406\n",
      "Epoch 33/36\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 0.3660 - accuracy: 0.8361\n",
      "Epoch 34/36\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 0.3618 - accuracy: 0.8429\n",
      "Epoch 35/36\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.3671 - accuracy: 0.8440\n",
      "Epoch 36/36\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.3608 - accuracy: 0.8395\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1e7e033b288>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrain the model\n",
    "hypermodel.fit(X, y, epochs=best_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.models import save_model\n",
    "# hypermodel.save('best_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    C:\\Users\\dtngh\\miniconda3\\envs\\gputest\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1478 predict_function  *\n        return step_function(self, iterator)\n    C:\\Users\\dtngh\\miniconda3\\envs\\gputest\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1468 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\Users\\dtngh\\miniconda3\\envs\\gputest\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\dtngh\\miniconda3\\envs\\gputest\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\dtngh\\miniconda3\\envs\\gputest\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\dtngh\\miniconda3\\envs\\gputest\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1461 run_step  **\n        outputs = model.predict_step(data)\n    C:\\Users\\dtngh\\miniconda3\\envs\\gputest\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1434 predict_step\n        return self(x, training=False)\n    C:\\Users\\dtngh\\miniconda3\\envs\\gputest\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:998 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    C:\\Users\\dtngh\\miniconda3\\envs\\gputest\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\input_spec.py:259 assert_input_compatibility\n        ' but received input with shape ' + display_shape(x.shape))\n\n    ValueError: Input 0 of layer sequential is incompatible with the layer: expected axis -1 of input shape to have value 4 but received input with shape (None, 8)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-97a987b53b7a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# from keras.models import load_model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# hypermodel = load_model('best_model.h5')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhypermodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\gputest\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1627\u001b[0m           \u001b[1;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1628\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1629\u001b[1;33m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1630\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1631\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\gputest\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xla\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\gputest\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    869\u001b[0m       \u001b[1;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    870\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 871\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    872\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    873\u001b[0m       \u001b[1;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\gputest\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[1;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[0;32m    724\u001b[0m     self._concrete_stateful_fn = (\n\u001b[0;32m    725\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[1;32m--> 726\u001b[1;33m             *args, **kwds))\n\u001b[0m\u001b[0;32m    727\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    728\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\gputest\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2967\u001b[0m       \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2968\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2969\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2970\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2971\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\gputest\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3359\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3360\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3361\u001b[1;33m           \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3362\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3363\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\gputest\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3204\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3205\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3206\u001b[1;33m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[0;32m   3207\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3208\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\gputest\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    989\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 990\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    991\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    992\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\gputest\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    632\u001b[0m             \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    633\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 634\u001b[1;33m           \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    635\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\gputest\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    975\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    976\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 977\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    978\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    979\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    C:\\Users\\dtngh\\miniconda3\\envs\\gputest\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1478 predict_function  *\n        return step_function(self, iterator)\n    C:\\Users\\dtngh\\miniconda3\\envs\\gputest\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1468 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\Users\\dtngh\\miniconda3\\envs\\gputest\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\dtngh\\miniconda3\\envs\\gputest\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\dtngh\\miniconda3\\envs\\gputest\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\dtngh\\miniconda3\\envs\\gputest\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1461 run_step  **\n        outputs = model.predict_step(data)\n    C:\\Users\\dtngh\\miniconda3\\envs\\gputest\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1434 predict_step\n        return self(x, training=False)\n    C:\\Users\\dtngh\\miniconda3\\envs\\gputest\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:998 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    C:\\Users\\dtngh\\miniconda3\\envs\\gputest\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\input_spec.py:259 assert_input_compatibility\n        ' but received input with shape ' + display_shape(x.shape))\n\n    ValueError: Input 0 of layer sequential is incompatible with the layer: expected axis -1 of input shape to have value 4 but received input with shape (None, 8)\n"
     ]
    }
   ],
   "source": [
    "# Load the model and predict\n",
    "# from keras.models import load_model\n",
    "# hypermodel = load_model('best_model.h5')\n",
    "y_pred = hypermodel.predict(X_test)\n",
    "y_pred = y_pred.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pd.DataFrame(y_pred, columns=['Survived'], index=test.index)\n",
    "# saving the dataframe \n",
    "y_pred.to_csv('Predictions.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import winsound\n",
    "duration = 100  # milliseconds\n",
    "freq = 3000  # Hz\n",
    "winsound.Beep(freq, duration)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
