{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data from csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sidetable\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "df = pd.read_csv('data.csv')\n",
    "df.columns = df.columns.str.lower()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary columns and rows having missing / null values\n",
    "columns_to_drop = [1, 3, 4, 5, 8, 9, 18, 19, 20, 21, 22, 23, 24, 25, 26, 87]\n",
    "df.drop(labels=df.columns[columns_to_drop], axis=1, inplace=True)\n",
    "\n",
    "# Turn columns to lower case\n",
    "df.columns = df.columns.str.lower().str.replace(' ', '_')\n",
    "df.set_index('id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove currency symbols in Wage and Value columns, turn them into numeric type, and change the column names\n",
    "df['wage'] = np.where(df['wage'].str[-1].isin('M K'.split()), df['wage'].str[1:-1], np.nan)\n",
    "df['value'] = np.where(df['value'].str[-1].isin('M K'.split()), df['value'].str[1:-1], np.nan)\n",
    "df['wage'] = df['wage'].astype(dtype='float')\n",
    "df['value'] = df['value'].astype(dtype='float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Convert work_rate into numeric type using the following map:\n",
    "        Low = 1 point, Medium = 2 points, High = 3 points    \n",
    "'''\n",
    "def work_rate(x):\n",
    "    if x in ['Low/ Low']:\n",
    "        return 2\n",
    "    elif x in ['Low/ Medium', 'Medium/ Low']:\n",
    "        return 3\n",
    "    elif x in ['Low/ High', 'Medium/ Medium', 'High/ Low']:\n",
    "        return 4\n",
    "    elif x in ['High/ Medium', 'Medium/ High']:\n",
    "        return 5\n",
    "    elif x in ['High/ High']:\n",
    "        return 6\n",
    "\n",
    "df['work_rate'] = df['work_rate'].apply(work_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is to remove the plus sign and add the two numbers together in columns ['ls': 'rb']\n",
    "def clean_plus_sign(x):\n",
    "    if isinstance(x, str):\n",
    "        x = x.split('+')\n",
    "        x = list(map(int, x))\n",
    "        return sum(x)\n",
    "    \n",
    "for i in df.loc[:,'ls': 'rb'].columns:\n",
    "    df[i] = df[i].apply(clean_plus_sign)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert these columns to float since Keras does not support int type\n",
    "for col in df.select_dtypes(include='int64').columns:\n",
    "    df[col] = df[col].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns='value')\n",
    "y = df.value.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrive num_cols and cat_cols\n",
    "num_cols = list(X._get_numeric_data().columns) # Another way: X.select_dtypes(include='number').columns\n",
    "cat_cols = list(set(X.columns) - set(num_cols)) # Another way: X.select_dtypes(exclude='number').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_cols = X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer, KNNImputer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import make_column_transformer, make_column_selector\n",
    "\n",
    "cat_pipe = make_pipeline(\n",
    "            (SimpleImputer(strategy='most_frequent')),\n",
    "            (OneHotEncoder(drop='first'))\n",
    "            )\n",
    "num_pipe = make_pipeline(\n",
    "            (KNNImputer()),\n",
    "            (StandardScaler())\n",
    "            )            \n",
    "preprocess_pipeline = make_column_transformer(\n",
    "            (cat_pipe, cat_cols),\n",
    "            (num_pipe, num_cols)\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = preprocess_pipeline.fit(X)\n",
    "X = processor.transform(X)\n",
    "X = pd.DataFrame(data=X, columns=my_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Oracle from existing project .\\untitled_project\\oracle.json\n",
      "INFO:tensorflow:Reloading Tuner from .\\untitled_project\\tuner0.json\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Credit source: \n",
    "    https://www.tensorflow.org/tutorials/keras/keras_tuner\n",
    "    https://github.com/keras-team/keras-tuner/blob/master/examples/cifar10.py\n",
    "'''\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Activation, Dense, Flatten, BatchNormalization, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Create the keras tuner model.\n",
    "def build_model(hp):\n",
    "    hp_drop_out = hp.Float('dropout', 0, 0.5, step=0.1)\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "    model = Sequential()\n",
    "    for i in range(hp.Int('num_layers', 2, 20)):\n",
    "        model.add(Dense(units=hp.Int('units_' + str(i), min_value=32, max_value=512, step=32), activation=tf.nn.leaky_relu, kernel_regularizer=keras.regularizers.l1_l2(l1=1e-5, l2=1e-4)))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(hp_drop_out))\n",
    "    model.add(Dense(1, activation='linear', kernel_regularizer='l2'))\n",
    "    opt = Adam(learning_rate=hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4]))\n",
    "    model.compile(optimizer=Adam(learning_rate=hp_learning_rate),\n",
    "                loss='mse',\n",
    "                metrics=['mse'])\n",
    "    return model\n",
    "\n",
    "import kerastuner as kt\n",
    "\n",
    "tuner = kt.Hyperband(build_model,\n",
    "                     objective='val_mse', \n",
    "                     max_epochs=16,\n",
    "                     overwrite=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "es = EarlyStopping(monitor='mse', verbose=0, patience=10, min_delta=1e-3)\n",
    "tuner.search(X_train, y_train, epochs=64, batch_size=128, validation_data=(X_val, y_val), callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/64\n",
      "513/513 [==============================] - 7s 8ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 2/64\n",
      "513/513 [==============================] - 4s 7ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 3/64\n",
      "513/513 [==============================] - 4s 7ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 4/64\n",
      "513/513 [==============================] - 4s 7ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 5/64\n",
      "513/513 [==============================] - 4s 7ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 6/64\n",
      "513/513 [==============================] - 4s 7ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 7/64\n",
      "513/513 [==============================] - 4s 7ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 8/64\n",
      "513/513 [==============================] - 4s 7ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 9/64\n",
      "513/513 [==============================] - 4s 7ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 10/64\n",
      "513/513 [==============================] - 4s 7ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 11/64\n",
      "513/513 [==============================] - 4s 7ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 12/64\n",
      "513/513 [==============================] - 4s 7ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 13/64\n",
      "513/513 [==============================] - 4s 7ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 14/64\n",
      "513/513 [==============================] - 4s 7ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 15/64\n",
      "513/513 [==============================] - ETA: 0s - loss: nan - mse: na - 4s 7ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 16/64\n",
      "513/513 [==============================] - 4s 7ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 17/64\n",
      "513/513 [==============================] - 4s 7ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 18/64\n",
      "513/513 [==============================] - 4s 7ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 19/64\n",
      "513/513 [==============================] - 4s 7ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 20/64\n",
      "513/513 [==============================] - 4s 7ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 21/64\n",
      "513/513 [==============================] - 4s 7ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 22/64\n",
      "513/513 [==============================] - 4s 7ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 23/64\n",
      "513/513 [==============================] - 4s 7ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 24/64\n",
      "513/513 [==============================] - 4s 7ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 25/64\n",
      "513/513 [==============================] - 4s 7ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 26/64\n",
      "513/513 [==============================] - 4s 7ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 27/64\n",
      "513/513 [==============================] - 4s 7ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 28/64\n",
      "513/513 [==============================] - 4s 7ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 29/64\n",
      "513/513 [==============================] - 4s 7ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 30/64\n",
      "513/513 [==============================] - 4s 7ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 31/64\n",
      "513/513 [==============================] - 4s 7ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 32/64\n",
      "513/513 [==============================] - 4s 7ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 33/64\n",
      "513/513 [==============================] - 4s 7ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 34/64\n",
      "513/513 [==============================] - 4s 7ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 35/64\n",
      "513/513 [==============================] - 4s 7ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 36/64\n",
      "513/513 [==============================] - 4s 7ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 37/64\n",
      "513/513 [==============================] - 4s 7ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 38/64\n",
      "513/513 [==============================] - 4s 7ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 39/64\n",
      "513/513 [==============================] - 4s 7ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 40/64\n",
      "513/513 [==============================] - 4s 7ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 41/64\n",
      "513/513 [==============================] - 4s 7ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 42/64\n",
      "513/513 [==============================] - 4s 7ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 43/64\n",
      "513/513 [==============================] - 4s 7ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 44/64\n",
      "513/513 [==============================] - 4s 7ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 45/64\n",
      "513/513 [==============================] - 4s 7ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 46/64\n",
      "513/513 [==============================] - 4s 7ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 47/64\n",
      "513/513 [==============================] - 4s 7ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 48/64\n",
      "513/513 [==============================] - 4s 7ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 49/64\n",
      "513/513 [==============================] - 4s 7ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 50/64\n",
      "513/513 [==============================] - 4s 7ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 51/64\n",
      "513/513 [==============================] - 4s 7ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 52/64\n",
      "513/513 [==============================] - 4s 7ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 53/64\n",
      "513/513 [==============================] - 4s 7ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 54/64\n",
      "513/513 [==============================] - 4s 7ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 55/64\n",
      "513/513 [==============================] - 4s 7ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 56/64\n",
      "513/513 [==============================] - 4s 7ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 57/64\n",
      "513/513 [==============================] - 4s 7ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 58/64\n",
      "513/513 [==============================] - 3s 7ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 59/64\n",
      "513/513 [==============================] - 4s 7ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 60/64\n",
      "513/513 [==============================] - 4s 7ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 61/64\n",
      "513/513 [==============================] - 4s 7ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 62/64\n",
      "513/513 [==============================] - 4s 7ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 63/64\n",
      "513/513 [==============================] - 3s 7ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 64/64\n",
      "513/513 [==============================] - 4s 7ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n"
     ]
    }
   ],
   "source": [
    "# Get the optimal hyperparameters\n",
    "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "model = tuner.hypermodel.build(best_hps)\n",
    "history = model.fit(X_train, y_train, epochs=64, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best epoch: 1\n"
     ]
    }
   ],
   "source": [
    "val_acc_per_epoch = history.history['val_mse']\n",
    "best_epoch = val_acc_per_epoch.index(max(val_acc_per_epoch)) + 1\n",
    "print('Best epoch: %d' % (best_epoch,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "513/513 [==============================] - 6s 7ms/step - loss: nan - mse: nan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2691d8bf088>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Re-instantiate the hypermodel and train it with the optimal number of epochs from above.\n",
    "hypermodel = tuner.hypermodel.build(best_hps)\n",
    "# Retrain the model\n",
    "hypermodel.fit(X_train, y_train, epochs=best_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "[test loss, test accuracy]: [nan, nan]\n"
     ]
    }
   ],
   "source": [
    "eval_result = hypermodel.evaluate(X_val, y_val)\n",
    "print(\"[test loss, test accuracy]:\", eval_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "513/513 [==============================] - 4s 7ms/step - loss: nan - mse: nanA: 0s - loss: nan - m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2692a25e908>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrain the model\n",
    "hypermodel.fit(X_train, y_train, epochs=best_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.models import save_model\n",
    "# hypermodel.save('best_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model and predict\n",
    "# from keras.models import load_model\n",
    "# hypermodel = load_model('best_model.h5')\n",
    "y_pred = hypermodel.predict(X_val)\n",
    "y_pred = y_pred.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pd.DataFrame(y_pred, columns=['value'], index=X_val.index)\n",
    "# saving the dataframe \n",
    "y_pred.to_csv('Predictions.csv') "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import winsound\n",
    "duration = 100  # milliseconds\n",
    "freq = 3000  # Hz\n",
    "winsound.Beep(freq, duration)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
