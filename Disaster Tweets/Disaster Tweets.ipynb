{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "suspended-fourth",
   "metadata": {},
   "source": [
    "### This is from a Kaggle competition: https://www.kaggle.com/c/nlp-getting-started/data?select=train.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "british-execution",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_train = pd.read_csv('train.csv')\n",
    "df_test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "facial-hands",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "sublime-wiring",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "logical-alarm",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_3ce2bb54_6efc_11eb_a420_9848271e970b\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >missing</th>        <th class=\"col_heading level0 col1\" >total</th>        <th class=\"col_heading level0 col2\" >percent</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_3ce2bb54_6efc_11eb_a420_9848271e970blevel0_row0\" class=\"row_heading level0 row0\" >keyword</th>\n",
       "                        <td id=\"T_3ce2bb54_6efc_11eb_a420_9848271e970brow0_col0\" class=\"data row0 col0\" >10</td>\n",
       "                        <td id=\"T_3ce2bb54_6efc_11eb_a420_9848271e970brow0_col1\" class=\"data row0 col1\" >10</td>\n",
       "                        <td id=\"T_3ce2bb54_6efc_11eb_a420_9848271e970brow0_col2\" class=\"data row0 col2\" >100.00%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_3ce2bb54_6efc_11eb_a420_9848271e970blevel0_row1\" class=\"row_heading level0 row1\" >location</th>\n",
       "                        <td id=\"T_3ce2bb54_6efc_11eb_a420_9848271e970brow1_col0\" class=\"data row1 col0\" >10</td>\n",
       "                        <td id=\"T_3ce2bb54_6efc_11eb_a420_9848271e970brow1_col1\" class=\"data row1 col1\" >10</td>\n",
       "                        <td id=\"T_3ce2bb54_6efc_11eb_a420_9848271e970brow1_col2\" class=\"data row1 col2\" >100.00%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_3ce2bb54_6efc_11eb_a420_9848271e970blevel0_row2\" class=\"row_heading level0 row2\" >id</th>\n",
       "                        <td id=\"T_3ce2bb54_6efc_11eb_a420_9848271e970brow2_col0\" class=\"data row2 col0\" >0</td>\n",
       "                        <td id=\"T_3ce2bb54_6efc_11eb_a420_9848271e970brow2_col1\" class=\"data row2 col1\" >10</td>\n",
       "                        <td id=\"T_3ce2bb54_6efc_11eb_a420_9848271e970brow2_col2\" class=\"data row2 col2\" >0.00%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_3ce2bb54_6efc_11eb_a420_9848271e970blevel0_row3\" class=\"row_heading level0 row3\" >text</th>\n",
       "                        <td id=\"T_3ce2bb54_6efc_11eb_a420_9848271e970brow3_col0\" class=\"data row3 col0\" >0</td>\n",
       "                        <td id=\"T_3ce2bb54_6efc_11eb_a420_9848271e970brow3_col1\" class=\"data row3 col1\" >10</td>\n",
       "                        <td id=\"T_3ce2bb54_6efc_11eb_a420_9848271e970brow3_col2\" class=\"data row3 col2\" >0.00%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_3ce2bb54_6efc_11eb_a420_9848271e970blevel0_row4\" class=\"row_heading level0 row4\" >target</th>\n",
       "                        <td id=\"T_3ce2bb54_6efc_11eb_a420_9848271e970brow4_col0\" class=\"data row4 col0\" >0</td>\n",
       "                        <td id=\"T_3ce2bb54_6efc_11eb_a420_9848271e970brow4_col1\" class=\"data row4 col1\" >10</td>\n",
       "                        <td id=\"T_3ce2bb54_6efc_11eb_a420_9848271e970brow4_col2\" class=\"data row4 col2\" >0.00%</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2009dc43708>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sidetable\n",
    "df_train.stb.missing(style=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "passing-strike",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(max(df_train.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "located-harmony",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing import sequence\n",
    "import numpy as np\n",
    "def get_pad_sq(df):\n",
    "    text = np.array(df.text)\n",
    "    tokenizer = Tokenizer(num_words=len(df.text.unique()))\n",
    "    tokenizer.fit_on_texts(text)\n",
    "    sequences = tokenizer.texts_to_sequences(text)\n",
    "    # Find the max length of rows in sequences\n",
    "    max_length = 0\n",
    "    for sentence in sequences:\n",
    "        max_length = max(max_length, len(sentence))\n",
    "    df = sequence.pad_sequences(sequences, maxlen=max_length)\n",
    "    return (df, max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "unauthorized-energy",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_id = df_test.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "understood-poland",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, _ = get_pad_sq(df_train)\n",
    "test, max_review_length = get_pad_sq(df_test)\n",
    "train_target = np.array(df_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "studied-stanford",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(train, train_target, stratify=train_target, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "copyrighted-eight",
   "metadata": {},
   "source": [
    "Credit : https://medium.com/@mrunal68/text-sentiments-classification-with-cnn-and-lstm-f92652bc29fd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "numerous-wellington",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Credit source: https://github.com/lukenew2/hyper_parameter_optimization/blob/master/hyper_parameter_optimization.ipynb\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers import Dense,Conv1D,MaxPooling1D\n",
    "from tensorflow.keras import regularizers\n",
    "from keras.layers import LSTM,Dropout\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "def build_model(input_length, dropout2_rate=0.5):\n",
    "    # create the model\n",
    "    embedding_vector_length = 128\n",
    "    top_words = 10000\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(top_words, embedding_vector_length, input_length=input_length, name='embed_1'))\n",
    "    model.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu', name='conv1d_1'))\n",
    "    model.add(MaxPooling1D(pool_size=2, name='maxpool1d_1'))\n",
    "    model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2, name='lstm_1'))\n",
    "    model.add(Dense(1, activation='sigmoid', kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4), name='dense_1'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "#     checkpoint = ModelCheckpoint('best_model.h5', monitor='val_accuracy',verbose=0, save_best_only=True)\n",
    "#     es = EarlyStopping(monitor='val_accuracy', verbose=0, patience=1)\n",
    "#     callbacks_list = [checkpoint, es]\n",
    "#     model.fit(X_train, y_train, epochs=4000, batch_size=32,verbose = 1, callbacks = callbacks_list, validation_data=(X_val,y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "quarterly-awareness",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "keras_clf = keras.wrappers.scikit_learn.KerasClassifier(build_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:gputest] *",
   "language": "python",
   "name": "conda-env-gputest-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
