{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "prec = pd.read_csv(\"Daily Precipitation.csv\")\n",
    "soil = pd.read_csv(\"Daily Soil Moisture.csv\")\n",
    "ed = pd.read_csv(\"Eight Day NDVI.csv\")\n",
    "prodq = pd.read_csv(\"Production Quantity.csv\")\n",
    "test = pd.read_csv(\"predicted_production_qty.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_date(*data, date_col=[\"start_date\"]):\n",
    "    \"\"\"This function cleans and parses date columns to the datetime type\"\"\"\n",
    "    for datum in data:\n",
    "        # Drop column \"end_date\" since it does not match with production quantity dataset\n",
    "        datum.drop(columns=\"end_date\", inplace=True)\n",
    "        for col in date_col:\n",
    "            # Keep the first 8 charcters of col value\n",
    "            datum[col] = datum[col].str.replace(\"-\", \"\").str[:8]\n",
    "            # Parse col to datetime type\n",
    "            datum[col] = pd.to_datetime(datum[col], format=\"%Y%m%d\")\n",
    "\n",
    "\n",
    "clean_date(prec, soil, ed, prodq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In ed, the ndvi score is measured every 8 days. Thus, I will add more dates to fill in the gap between the start_date and end_date (7 more dates) and adjust the score in the dates by a linear difference between the previous and the current date by the formula \n",
    "$$\n",
    "ndvi_{t+1} = ndvi_{t} + \\frac{ndvi_{t+8} - ndvi_{t}} {t + 8 - t} * (t + 1 - t)\n",
    "$$\n",
    "<br>\n",
    "For example, the ndvi on start_date of 2014-01-01 and 2014-01-09 are 0.701431 and 0.745149. Then, the ndvi on the start_date of 2014-01-04 is<br>\n",
    "0.701431 + (0.745149 - 0.701431) / 8 * 3<br>\n",
    "This method is inspired by back propagation in Deep Learning\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ed below is a dataframe object that has all start date from the oldest to latest, of which ndvi values are imputed by the formula explained above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def unique_date(df, date_col):\n",
    "#     \"\"\"This function returns a list of dates that were between newest and oldest dates in date_col values\"\"\"\n",
    "#     dates = pd.date_range(start=min(df[date_col]), end=max(df[date_col])).to_list()\n",
    "#     for date in dates:\n",
    "#         if date in df[date_col].values:\n",
    "#             dates.remove(date)\n",
    "#     return dates\n",
    "\n",
    "\n",
    "# def closest_date(date, df, date_col):\n",
    "#     \"\"\"This function returns the index of the closest date in df[date_col] that was before the date\"\"\"\n",
    "#     index = df[date_col].searchsorted(date)\n",
    "#     return index\n",
    "\n",
    "\n",
    "# def impute_ndvi(date, df, index, date_col):\n",
    "#     \"\"\"This function applies the formula above. Also, it returns the value of region_id\"\"\"\n",
    "#     pre_nvdi_value = df.iloc[index, -2]\n",
    "#     if index + 1 < len(df):\n",
    "#         post_nvdi_value = df.iloc[index + 1, -2]\n",
    "#     else:\n",
    "#         post_nvdi_value = pre_nvdi_value\n",
    "#     # Time difference between t and t-1 in terms of days\n",
    "#     time_delta = (df.loc[index, date_col] - date).days\n",
    "#     result = pre_nvdi_value + (post_nvdi_value - pre_nvdi_value) * time_delta / 8\n",
    "#     return result, df.loc[index, \"region_id\"]\n",
    "\n",
    "\n",
    "# ed_dates = unique_date(ed, \"start_date\")\n",
    "# new = pd.DataFrame()\n",
    "# # Add rows to the new DataFrame of which dates ed does not have\n",
    "# for date in ed_dates:\n",
    "#     index = closest_date(date, ed, \"start_date\")\n",
    "#     new = new.append(\n",
    "#         {\n",
    "#             \"start_date\": date,\n",
    "#             \"ndvi\": impute_ndvi(date, ed, index, \"start_date\")[0],\n",
    "#             \"region_id\": impute_ndvi(date, ed, index, \"start_date\")[1],\n",
    "#         },\n",
    "#         ignore_index=True,\n",
    "#     )\n",
    "\n",
    "# # Fulfill dates in ed with ndvi being the imputed values\n",
    "# ed = pd.concat([ed, new], join=\"inner\")\n",
    "# ed.to_csv('ed.csv', index=False)\n",
    "ed = pd.read_csv('ed.csv', parse_dates=['start_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge prec, soil, and ed to columns that have the same values of start_date and region_id\n",
    "merged_data = prec.merge(soil).merge(ed)\n",
    "merged_data.set_index('start_date', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The grouped_merged dataset has a row representing a whole month. Thus, I take the average of all days in a month of precip, smos, and ndvi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the merged data by start_date year, start_date month, and region_id\n",
    "grouped_merged = merged_data.groupby([pd.Grouper(freq='MS'), 'region_id']).mean()\n",
    "# I grouped this is to prepare to merge with production quantity since each start_date row represents a whole month\n",
    "grouped_merged.reset_index(inplace=True)\n",
    "train = grouped_merged.merge(prodq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since the crop is seasonal, month but year plays more important role in predicting, I convert start_date to month name\n",
    "def date_to_month(df, date_col):\n",
    "    df['month'] = df[date_col].dt.month_name()\n",
    "    df.drop(columns=[date_col], inplace=True)\n",
    "\n",
    "# One hot month and region_id\n",
    "def oh(df):\n",
    "    df = pd.get_dummies(df, drop_first=True, columns=['region_id', 'month'])\n",
    "    return df\n",
    "\n",
    "date_to_month(train, 'start_date')\n",
    "original_dates = test.iloc[:, :2].copy()\n",
    "clean_date(test)\n",
    "# Since this is a prediction for 12 months of 2021 in different regions, I clean the start_date column to month\n",
    "date_to_month(test, 'start_date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The predicted values are the average of the same months, same region in all years\n",
    "predicted = train.groupby(['month', 'region_id'])['prod'].mean()\n",
    "predicted = predicted.to_frame().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_date(df):\n",
    "    '''This function converts the month column back to the cleaned format'''\n",
    "    df['year'] = 2021\n",
    "    df['start_date'] = pd.to_datetime(df['year'].astype(str)  + df['month'], format='%Y%B')\n",
    "    df.drop(columns=['month', 'year'], inplace=True)\n",
    "\n",
    "to_date(predicted)\n",
    "to_date(test)\n",
    "test.drop(columns=['prod'], inplace=True)\n",
    "predicted = predicted.merge(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the predicted values by region, followed by date\n",
    "predicted = predicted.sort_values(['region_id', 'start_date']).drop(columns=['start_date'])\n",
    "# Convert the date to the original format\n",
    "predicted = pd.concat([predicted, original_dates], axis=1)\n",
    "# Reorder columns\n",
    "predicted = predicted[['start_date', 'end_date', 'prod', 'region_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted.to_csv('dtnghia1987@gmail.com.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2f8d4f4cc8fa12dbb26313d8b3e110534f25fd535deed971b5eaf97b1f1a75b3"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
